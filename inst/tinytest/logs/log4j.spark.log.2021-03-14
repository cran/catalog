21/03/14 14:32:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 14:32:48 INFO SparkContext: Running Spark version 2.4.3
21/03/14 14:32:48 INFO SparkContext: Submitted application: sparklyr
21/03/14 14:32:48 INFO SecurityManager: Changing view acls to: nathan
21/03/14 14:32:48 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 14:32:48 INFO SecurityManager: Changing view acls groups to: 
21/03/14 14:32:48 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 14:32:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 14:32:48 INFO Utils: Successfully started service 'sparkDriver' on port 56928.
21/03/14 14:32:48 INFO SparkEnv: Registering MapOutputTracker
21/03/14 14:32:48 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 14:32:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 14:32:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 14:32:48 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-abc968dd-da92-4dc1-9aa8-ee34a38c065e
21/03/14 14:32:48 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 14:32:48 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 14:32:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 14:32:49 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 14:32:49 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:56928/jars/sparklyr-2.4-2.11.jar with timestamp 1615728769131
21/03/14 14:32:49 INFO Executor: Starting executor ID driver on host localhost
21/03/14 14:32:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56929.
21/03/14 14:32:49 INFO NettyBlockTransferService: Server created on localhost:56929
21/03/14 14:32:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 14:32:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 56929, None)
21/03/14 14:32:49 INFO BlockManagerMasterEndpoint: Registering block manager localhost:56929 with 912.3 MB RAM, BlockManagerId(driver, localhost, 56929, None)
21/03/14 14:32:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 56929, None)
21/03/14 14:32:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 56929, None)
21/03/14 14:32:49 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 14:32:49 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 14:32:49 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 14:32:50 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 14:32:54 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 14:32:55 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 14:32:55 INFO ObjectStore: ObjectStore, initialize called
21/03/14 14:32:55 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 14:32:55 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 14:32:57 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 14:32:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:32:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:32:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:32:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:32:59 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 14:32:59 INFO ObjectStore: Initialized ObjectStore
21/03/14 14:32:59 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 14:32:59 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 14:32:59 INFO HiveMetaStore: Added admin role in metastore
21/03/14 14:32:59 INFO HiveMetaStore: Added public role in metastore
21/03/14 14:32:59 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 14:33:00 INFO HiveMetaStore: 0: get_all_databases
21/03/14 14:33:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 14:33:00 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:33:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:33:00 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:33:00 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/1713eef1-8d41-4498-a148-731435ed1a70_resources
21/03/14 14:33:00 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/1713eef1-8d41-4498-a148-731435ed1a70
21/03/14 14:33:00 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/1713eef1-8d41-4498-a148-731435ed1a70
21/03/14 14:33:00 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/1713eef1-8d41-4498-a148-731435ed1a70/_tmp_space.db
21/03/14 14:33:00 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 14:33:00 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:33:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:33:00 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 14:33:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 14:33:00 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 14:33:00 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:33:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:33:00 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:33:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:33:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 14:33:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 14:33:01 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 14:33:01 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/03/14 14:33:01 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/03/14 14:33:01 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:33:01 INFO DAGScheduler: Missing parents: List()
21/03/14 14:33:01 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/03/14 14:33:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/03/14 14:33:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/03/14 14:33:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56929 (size: 3.4 KB, free: 912.3 MB)
21/03/14 14:33:01 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 14:33:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 14:33:01 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 14:33:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/03/14 14:33:01 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 14:33:01 INFO Executor: Fetching spark://localhost:56928/jars/sparklyr-2.4-2.11.jar with timestamp 1615728769131
21/03/14 14:33:01 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:56928 after 29 ms (0 ms spent in bootstraps)
21/03/14 14:33:01 INFO Utils: Fetching spark://localhost:56928/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-40e128da-2ac2-44e7-a094-6fd1bdcf17fc/userFiles-7875356e-594a-404c-94b6-c2eecd4c8633/fetchFileTemp1098279703009645139.tmp
21/03/14 14:33:01 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-40e128da-2ac2-44e7-a094-6fd1bdcf17fc/userFiles-7875356e-594a-404c-94b6-c2eecd4c8633/sparklyr-2.4-2.11.jar to class loader
21/03/14 14:33:02 INFO CodeGenerator: Code generated in 323.644419 ms
21/03/14 14:33:02 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
21/03/14 14:33:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 936 ms on localhost (executor driver) (1/1)
21/03/14 14:33:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 14:33:02 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 1.329 s
21/03/14 14:33:02 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 1.411194 s
21/03/14 14:33:02 INFO ContextCleaner: Cleaned accumulator 0
21/03/14 14:33:02 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:56929 in memory (size: 3.4 KB, free: 912.3 MB)
21/03/14 14:33:03 INFO CodeGenerator: Code generated in 23.643992 ms
21/03/14 14:33:03 INFO CodeGenerator: Code generated in 26.445357 ms
21/03/14 14:33:03 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:33:03 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:33:03 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 14:33:03 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:33:03 INFO DAGScheduler: Missing parents: List()
21/03/14 14:33:03 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/03/14 14:33:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 14:33:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 14:33:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:56929 (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:33:03 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 14:33:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:33:03 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 14:33:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:33:03 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 14:33:03 INFO CodeGenerator: Code generated in 11.658618 ms
21/03/14 14:33:03 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 14:33:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 40 ms on localhost (executor driver) (1/1)
21/03/14 14:33:03 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 14:33:03 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.050 s
21/03/14 14:33:03 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.056067 s
21/03/14 14:33:03 INFO CodeGenerator: Code generated in 20.415842 ms
21/03/14 14:33:03 INFO CodeGenerator: Code generated in 16.287652 ms
21/03/14 14:33:03 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:33:03 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/03/14 14:33:03 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 14:33:03 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 14:33:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 14:33:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 14:33:03 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/03/14 14:33:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/03/14 14:33:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/03/14 14:33:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:56929 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:33:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 14:33:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:33:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 14:33:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:33:04 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 14:33:04 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 14:33:04 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 73 ms on localhost (executor driver) (1/1)
21/03/14 14:33:04 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 14:33:04 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.093 s
21/03/14 14:33:04 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:33:04 INFO DAGScheduler: running: Set()
21/03/14 14:33:04 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 14:33:04 INFO DAGScheduler: failed: Set()
21/03/14 14:33:04 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/03/14 14:33:04 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:33:04 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:33:04 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:56929 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:33:04 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 14:33:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:33:04 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 14:33:04 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:33:04 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 14:33:04 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:33:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
21/03/14 14:33:04 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1825 bytes result sent to driver
21/03/14 14:33:04 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 82 ms on localhost (executor driver) (1/1)
21/03/14 14:33:04 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 14:33:04 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.096 s
21/03/14 14:33:04 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.223759 s
21/03/14 14:33:04 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:33:04 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:33:04 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/03/14 14:33:04 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:33:04 INFO DAGScheduler: Missing parents: List()
21/03/14 14:33:04 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135), which has no missing parents
21/03/14 14:33:04 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 14:33:04 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 14:33:04 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:56929 (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:33:04 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 14:33:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:33:04 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 14:33:04 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:33:04 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 14:33:04 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/03/14 14:33:04 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on localhost (executor driver) (1/1)
21/03/14 14:33:04 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 14:33:04 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.017 s
21/03/14 14:33:04 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.020570 s
21/03/14 14:33:04 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:33:04 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:135)
21/03/14 14:33:04 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/14 14:33:04 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/03/14 14:33:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/03/14 14:33:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/03/14 14:33:04 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/03/14 14:33:04 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/03/14 14:33:04 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/03/14 14:33:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:56929 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:33:04 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 14:33:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:33:04 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 14:33:04 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:33:04 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 14:33:04 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/03/14 14:33:04 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 11 ms on localhost (executor driver) (1/1)
21/03/14 14:33:04 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 14:33:04 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.021 s
21/03/14 14:33:04 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:33:04 INFO DAGScheduler: running: Set()
21/03/14 14:33:04 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/03/14 14:33:04 INFO DAGScheduler: failed: Set()
21/03/14 14:33:04 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/03/14 14:33:04 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:33:04 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:33:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:56929 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:33:04 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 14:33:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:33:04 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 14:33:04 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:33:04 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 14:33:04 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:33:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:33:04 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/03/14 14:33:04 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 9 ms on localhost (executor driver) (1/1)
21/03/14 14:33:04 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 14:33:04 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.018 s
21/03/14 14:33:04 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.044806 s
21/03/14 14:33:05 INFO CodeGenerator: Code generated in 42.378082 ms
21/03/14 14:33:05 INFO CodeGenerator: Code generated in 19.767132 ms
21/03/14 14:33:05 INFO CodeGenerator: Code generated in 15.720212 ms
21/03/14 14:33:05 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:33:05 INFO DAGScheduler: Registering RDD 28 (count at utils.scala:135)
21/03/14 14:33:05 INFO DAGScheduler: Got job 5 (count at utils.scala:135) with 1 output partitions
21/03/14 14:33:05 INFO DAGScheduler: Final stage: ResultStage 8 (count at utils.scala:135)
21/03/14 14:33:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
21/03/14 14:33:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
21/03/14 14:33:05 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135), which has no missing parents
21/03/14 14:33:05 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:33:05 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:33:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:56929 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:33:05 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 14:33:05 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/03/14 14:33:05 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
21/03/14 14:33:05 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8034 bytes)
21/03/14 14:33:05 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 8, localhost, executor driver, partition 1, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:33:05 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 9, localhost, executor driver, partition 2, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:33:05 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 10, localhost, executor driver, partition 3, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:33:05 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 14:33:05 INFO Executor: Running task 1.0 in stage 7.0 (TID 8)
21/03/14 14:33:05 INFO Executor: Running task 2.0 in stage 7.0 (TID 9)
21/03/14 14:33:05 INFO Executor: Running task 3.0 in stage 7.0 (TID 10)
21/03/14 14:33:05 INFO Executor: Finished task 1.0 in stage 7.0 (TID 8). 1499 bytes result sent to driver
21/03/14 14:33:05 INFO Executor: Finished task 3.0 in stage 7.0 (TID 10). 1499 bytes result sent to driver
21/03/14 14:33:05 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1499 bytes result sent to driver
21/03/14 14:33:05 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 8) in 14 ms on localhost (executor driver) (1/4)
21/03/14 14:33:05 INFO Executor: Finished task 2.0 in stage 7.0 (TID 9). 1499 bytes result sent to driver
21/03/14 14:33:05 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 18 ms on localhost (executor driver) (2/4)
21/03/14 14:33:05 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 10) in 15 ms on localhost (executor driver) (3/4)
21/03/14 14:33:05 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 9) in 16 ms on localhost (executor driver) (4/4)
21/03/14 14:33:05 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 14:33:05 INFO DAGScheduler: ShuffleMapStage 7 (count at utils.scala:135) finished in 0.028 s
21/03/14 14:33:05 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:33:05 INFO DAGScheduler: running: Set()
21/03/14 14:33:05 INFO DAGScheduler: waiting: Set(ResultStage 8)
21/03/14 14:33:05 INFO DAGScheduler: failed: Set()
21/03/14 14:33:05 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135), which has no missing parents
21/03/14 14:33:05 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:33:05 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:33:05 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:56929 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:33:05 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 14:33:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:33:05 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 14:33:05 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:33:05 INFO Executor: Running task 0.0 in stage 8.0 (TID 11)
21/03/14 14:33:05 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
21/03/14 14:33:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:33:05 INFO Executor: Finished task 0.0 in stage 8.0 (TID 11). 1825 bytes result sent to driver
21/03/14 14:33:05 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 11) in 10 ms on localhost (executor driver) (1/1)
21/03/14 14:33:05 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 14:33:05 INFO DAGScheduler: ResultStage 8 (count at utils.scala:135) finished in 0.021 s
21/03/14 14:33:05 INFO DAGScheduler: Job 5 finished: count at utils.scala:135, took 0.054111 s
21/03/14 14:33:05 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:33:05 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:33:06 INFO HiveMetaStore: 0: get_database: fake_database
21/03/14 14:33:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: fake_database	
21/03/14 14:33:06 WARN ObjectStore: Failed to get database fake_database, returning NoSuchObjectException
21/03/14 14:33:06 INFO HiveMetaStore: 0: get_databases: *
21/03/14 14:33:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_databases: *	
21/03/14 14:33:06 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:33:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:33:06 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:33:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:33:06 INFO CodeGenerator: Code generated in 33.17625 ms
21/03/14 14:33:06 INFO CodeGenerator: Code generated in 16.109499 ms
21/03/14 14:33:06 INFO CodeGenerator: Code generated in 21.764174 ms
21/03/14 14:33:06 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:33:06 INFO DAGScheduler: Registering RDD 35 (count at utils.scala:135)
21/03/14 14:33:06 INFO DAGScheduler: Got job 6 (count at utils.scala:135) with 1 output partitions
21/03/14 14:33:06 INFO DAGScheduler: Final stage: ResultStage 10 (count at utils.scala:135)
21/03/14 14:33:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
21/03/14 14:33:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
21/03/14 14:33:06 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[35] at count at utils.scala:135), which has no missing parents
21/03/14 14:33:06 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:33:06 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:33:06 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:56929 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:33:06 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 14:33:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[35] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:33:06 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 14:33:06 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 14:33:06 INFO Executor: Running task 0.0 in stage 9.0 (TID 12)
21/03/14 14:33:06 INFO Executor: Finished task 0.0 in stage 9.0 (TID 12). 1499 bytes result sent to driver
21/03/14 14:33:06 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 12) in 9 ms on localhost (executor driver) (1/1)
21/03/14 14:33:06 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 14:33:06 INFO DAGScheduler: ShuffleMapStage 9 (count at utils.scala:135) finished in 0.020 s
21/03/14 14:33:06 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:33:06 INFO DAGScheduler: running: Set()
21/03/14 14:33:06 INFO DAGScheduler: waiting: Set(ResultStage 10)
21/03/14 14:33:06 INFO DAGScheduler: failed: Set()
21/03/14 14:33:06 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[38] at count at utils.scala:135), which has no missing parents
21/03/14 14:33:06 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 231
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 95
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 171
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 159
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 257
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 197
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 269
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 170
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 77
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 117
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 182
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 244
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 265
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 260
21/03/14 14:33:06 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 272
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 99
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 107
21/03/14 14:33:06 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:56929 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:33:06 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 14:33:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:33:06 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/03/14 14:33:06 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:33:06 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
21/03/14 14:33:06 INFO ContextCleaner: Cleaned shuffle 0
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 190
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 188
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 267
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 130
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 247
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 26
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 64
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 174
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 230
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 184
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 101
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 172
21/03/14 14:33:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:33:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 70
21/03/14 14:33:06 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:56929 in memory (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:33:06 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 1782 bytes result sent to driver
21/03/14 14:33:06 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 6 ms on localhost (executor driver) (1/1)
21/03/14 14:33:06 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 237
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 82
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 65
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 161
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 35
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 123
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 195
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 137
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 92
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 149
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 86
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 206
21/03/14 14:33:06 INFO DAGScheduler: ResultStage 10 (count at utils.scala:135) finished in 0.029 s
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 145
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 125
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 216
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 250
21/03/14 14:33:06 INFO DAGScheduler: Job 6 finished: count at utils.scala:135, took 0.052764 s
21/03/14 14:33:06 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:56929 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:33:06 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:56929 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 229
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 177
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 75
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 248
21/03/14 14:33:06 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:56929 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 91
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 97
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 151
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 85
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 122
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 94
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 32
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 181
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 87
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 31
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 224
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 222
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 261
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 163
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 217
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 103
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 214
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 100
21/03/14 14:33:06 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:56929 in memory (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 166
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 233
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 232
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 180
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 251
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 192
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 106
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 211
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 141
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 264
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 71
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 155
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 242
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 119
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 88
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 139
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 196
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 256
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 135
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 164
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 209
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 14:33:06 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:56929 in memory (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 154
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 183
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 126
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 148
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 194
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 169
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 127
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 76
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 144
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 223
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 243
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 254
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 114
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 278
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 96
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 90
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 116
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 109
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 133
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 220
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 236
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 199
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 138
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 238
21/03/14 14:33:06 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:56929 in memory (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 113
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 33
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 266
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 228
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 36
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 128
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 121
21/03/14 14:33:06 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:56929 in memory (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 146
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 200
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 234
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 140
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 29
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 165
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 115
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 147
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 110
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 93
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 263
21/03/14 14:33:06 INFO ContextCleaner: Cleaned shuffle 1
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 227
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 201
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 167
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 79
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 102
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 198
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 89
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 212
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 270
21/03/14 14:33:06 INFO ContextCleaner: Cleaned shuffle 2
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 30
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 240
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 241
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 153
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 124
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 112
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 193
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 84
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 186
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 215
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 104
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 219
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 178
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 235
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 108
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 142
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 131
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 259
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 156
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 176
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 252
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 225
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 67
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 157
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 187
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 203
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 162
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 160
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 28
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 208
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 204
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 152
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 226
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 210
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 143
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 202
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 78
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 268
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 81
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 34
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 68
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 205
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 213
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 74
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 245
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 72
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 185
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 80
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 246
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 150
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 271
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 221
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 158
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 275
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 120
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 134
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 132
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 27
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 73
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 105
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 276
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 111
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 136
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 273
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 66
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 173
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 253
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 191
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 175
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 98
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 207
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 255
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 274
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 239
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 218
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 37
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 168
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 189
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 129
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 69
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 83
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 179
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 258
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 262
21/03/14 14:33:06 INFO ContextCleaner: Cleaned accumulator 249
21/03/14 14:33:06 INFO HiveMetaStore: 0: create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})
21/03/14 14:33:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})	
21/03/14 14:33:06 WARN ObjectStore: Failed to get database catalog_test_database_db, returning NoSuchObjectException
21/03/14 14:33:06 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:33:06 INFO CodeGenerator: Code generated in 8.529658 ms
21/03/14 14:33:06 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:33:06 INFO DAGScheduler: Registering RDD 42 (count at utils.scala:135)
21/03/14 14:33:06 INFO DAGScheduler: Got job 7 (count at utils.scala:135) with 1 output partitions
21/03/14 14:33:06 INFO DAGScheduler: Final stage: ResultStage 12 (count at utils.scala:135)
21/03/14 14:33:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
21/03/14 14:33:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
21/03/14 14:33:06 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[42] at count at utils.scala:135), which has no missing parents
21/03/14 14:33:06 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 14:33:06 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 14:33:06 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:56929 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:33:06 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
21/03/14 14:33:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[42] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:33:06 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/03/14 14:33:06 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 14:33:06 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
21/03/14 14:33:06 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 1499 bytes result sent to driver
21/03/14 14:33:06 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 11 ms on localhost (executor driver) (1/1)
21/03/14 14:33:06 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/03/14 14:33:06 INFO DAGScheduler: ShuffleMapStage 11 (count at utils.scala:135) finished in 0.019 s
21/03/14 14:33:06 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:33:06 INFO DAGScheduler: running: Set()
21/03/14 14:33:06 INFO DAGScheduler: waiting: Set(ResultStage 12)
21/03/14 14:33:06 INFO DAGScheduler: failed: Set()
21/03/14 14:33:06 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[45] at count at utils.scala:135), which has no missing parents
21/03/14 14:33:06 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:33:06 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:33:06 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:56929 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:33:06 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 14:33:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[45] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:33:06 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/03/14 14:33:06 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 15, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:33:06 INFO Executor: Running task 0.0 in stage 12.0 (TID 15)
21/03/14 14:33:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:33:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:33:06 INFO Executor: Finished task 0.0 in stage 12.0 (TID 15). 1775 bytes result sent to driver
21/03/14 14:33:06 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 15) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:33:06 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/03/14 14:33:06 INFO DAGScheduler: ResultStage 12 (count at utils.scala:135) finished in 0.016 s
21/03/14 14:33:06 INFO DAGScheduler: Job 7 finished: count at utils.scala:135, took 0.044238 s
21/03/14 14:33:07 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:33:07 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:33:07 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:33:07 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:33:07 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:33:07 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:33:07 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:33:07 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:33:07 INFO HiveMetaStore: 0: drop_database: catalog_test_database_db
21/03/14 14:33:07 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=drop_database: catalog_test_database_db	
21/03/14 14:33:07 INFO HiveMetaStore: 0: get_all_tables: db=catalog_test_database_db
21/03/14 14:33:07 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_tables: db=catalog_test_database_db	
21/03/14 14:33:07 INFO HiveMetaStore: 0: get_functions: db=catalog_test_database_db pat=*
21/03/14 14:33:07 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=catalog_test_database_db pat=*	
21/03/14 14:33:07 INFO ObjectStore: Dropping database catalog_test_database_db along with all tables
21/03/14 14:33:07 INFO hivemetastoressimpl: deleting  file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:33:07 INFO deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
21/03/14 14:33:07 INFO TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
21/03/14 14:33:07 INFO hivemetastoressimpl: Deleted the diretory file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:33:07 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:33:07 INFO DAGScheduler: Registering RDD 49 (count at utils.scala:135)
21/03/14 14:33:07 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/03/14 14:33:07 INFO DAGScheduler: Final stage: ResultStage 14 (count at utils.scala:135)
21/03/14 14:33:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/03/14 14:33:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/03/14 14:33:07 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[49] at count at utils.scala:135), which has no missing parents
21/03/14 14:33:07 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:33:07 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:33:07 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:56929 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:33:07 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 14:33:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[49] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:33:07 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/03/14 14:33:07 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 14:33:07 INFO Executor: Running task 0.0 in stage 13.0 (TID 16)
21/03/14 14:33:07 INFO Executor: Finished task 0.0 in stage 13.0 (TID 16). 1542 bytes result sent to driver
21/03/14 14:33:07 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 16) in 11 ms on localhost (executor driver) (1/1)
21/03/14 14:33:07 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/03/14 14:33:07 INFO DAGScheduler: ShuffleMapStage 13 (count at utils.scala:135) finished in 0.018 s
21/03/14 14:33:07 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:33:07 INFO DAGScheduler: running: Set()
21/03/14 14:33:07 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/03/14 14:33:07 INFO DAGScheduler: failed: Set()
21/03/14 14:33:07 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[52] at count at utils.scala:135), which has no missing parents
21/03/14 14:33:07 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:33:07 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:33:07 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:56929 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:33:07 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
21/03/14 14:33:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[52] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:33:07 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/03/14 14:33:07 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 17, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:33:07 INFO Executor: Running task 0.0 in stage 14.0 (TID 17)
21/03/14 14:33:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:33:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:33:07 INFO Executor: Finished task 0.0 in stage 14.0 (TID 17). 1775 bytes result sent to driver
21/03/14 14:33:07 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 17) in 8 ms on localhost (executor driver) (1/1)
21/03/14 14:33:07 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/03/14 14:33:07 INFO DAGScheduler: ResultStage 14 (count at utils.scala:135) finished in 0.014 s
21/03/14 14:33:07 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.035983 s
21/03/14 14:33:07 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:33:07 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:33:07 WARN ObjectStore: Failed to get database catalog_test_database_db, returning NoSuchObjectException
21/03/14 14:33:38 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 14:33:38 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 14:33:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 14:33:38 INFO MemoryStore: MemoryStore cleared
21/03/14 14:33:38 INFO BlockManager: BlockManager stopped
21/03/14 14:33:38 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 14:33:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 14:33:39 INFO SparkContext: Successfully stopped SparkContext
21/03/14 14:33:39 INFO ShutdownHookManager: Shutdown hook called
21/03/14 14:33:39 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-40e128da-2ac2-44e7-a094-6fd1bdcf17fc
21/03/14 14:33:39 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-8d1ff849-5544-4539-b547-eee9f9c1301d
21/03/14 14:33:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 14:33:48 INFO SparkContext: Running Spark version 2.4.3
21/03/14 14:33:48 INFO SparkContext: Submitted application: sparklyr
21/03/14 14:33:48 INFO SecurityManager: Changing view acls to: nathan
21/03/14 14:33:48 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 14:33:48 INFO SecurityManager: Changing view acls groups to: 
21/03/14 14:33:48 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 14:33:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 14:33:48 INFO Utils: Successfully started service 'sparkDriver' on port 57176.
21/03/14 14:33:48 INFO SparkEnv: Registering MapOutputTracker
21/03/14 14:33:48 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 14:33:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 14:33:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 14:33:48 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-13b60a85-8ee9-4e51-8421-f6419e57bf6a
21/03/14 14:33:48 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 14:33:48 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 14:33:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 14:33:48 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 14:33:48 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:57176/jars/sparklyr-2.4-2.11.jar with timestamp 1615728828960
21/03/14 14:33:49 INFO Executor: Starting executor ID driver on host localhost
21/03/14 14:33:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57177.
21/03/14 14:33:49 INFO NettyBlockTransferService: Server created on localhost:57177
21/03/14 14:33:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 14:33:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 57177, None)
21/03/14 14:33:49 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57177 with 912.3 MB RAM, BlockManagerId(driver, localhost, 57177, None)
21/03/14 14:33:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 57177, None)
21/03/14 14:33:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 57177, None)
21/03/14 14:33:49 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 14:33:49 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 14:33:49 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 14:33:50 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 14:33:53 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 14:33:53 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 14:33:54 INFO ObjectStore: ObjectStore, initialize called
21/03/14 14:33:54 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 14:33:54 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 14:33:55 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 14:33:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:33:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:33:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:33:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:33:58 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 14:33:58 INFO ObjectStore: Initialized ObjectStore
21/03/14 14:33:58 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 14:33:58 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 14:33:58 INFO HiveMetaStore: Added admin role in metastore
21/03/14 14:33:58 INFO HiveMetaStore: Added public role in metastore
21/03/14 14:33:58 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 14:33:58 INFO HiveMetaStore: 0: get_all_databases
21/03/14 14:33:58 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 14:33:58 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:33:58 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:33:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:33:58 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/01c1a2dc-9dff-49ee-ae1f-5e246a7eafed_resources
21/03/14 14:33:58 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/01c1a2dc-9dff-49ee-ae1f-5e246a7eafed
21/03/14 14:33:58 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/01c1a2dc-9dff-49ee-ae1f-5e246a7eafed
21/03/14 14:33:58 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/01c1a2dc-9dff-49ee-ae1f-5e246a7eafed/_tmp_space.db
21/03/14 14:33:58 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 14:33:58 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:33:58 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:33:58 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 14:33:58 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 14:33:58 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 14:33:58 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:33:58 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:33:58 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:33:58 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:33:59 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 14:33:59 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 14:33:59 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 14:33:59 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/03/14 14:33:59 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/03/14 14:33:59 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:33:59 INFO DAGScheduler: Missing parents: List()
21/03/14 14:33:59 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/03/14 14:33:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/03/14 14:33:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/03/14 14:33:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57177 (size: 3.4 KB, free: 912.3 MB)
21/03/14 14:33:59 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 14:34:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 14:34:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 14:34:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/03/14 14:34:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 14:34:00 INFO Executor: Fetching spark://localhost:57176/jars/sparklyr-2.4-2.11.jar with timestamp 1615728828960
21/03/14 14:34:00 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:57176 after 23 ms (0 ms spent in bootstraps)
21/03/14 14:34:00 INFO Utils: Fetching spark://localhost:57176/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-e63d91e3-a3e9-4cf7-99c1-7dd11043745a/userFiles-a4912366-40f8-4851-abdb-286af0b00732/fetchFileTemp7031024251612583482.tmp
21/03/14 14:34:00 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-e63d91e3-a3e9-4cf7-99c1-7dd11043745a/userFiles-a4912366-40f8-4851-abdb-286af0b00732/sparklyr-2.4-2.11.jar to class loader
21/03/14 14:34:00 INFO CodeGenerator: Code generated in 226.341483 ms
21/03/14 14:34:00 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
21/03/14 14:34:00 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 639 ms on localhost (executor driver) (1/1)
21/03/14 14:34:00 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 14:34:00 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 0.972 s
21/03/14 14:34:00 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 1.060291 s
21/03/14 14:34:00 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:57177 in memory (size: 3.4 KB, free: 912.3 MB)
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 14
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 12
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 9
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 25
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 19
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 22
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 11
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 13
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 5
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 17
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 1
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 16
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 4
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 8
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 21
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 7
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 0
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 2
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 10
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 3
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 24
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 20
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 23
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 6
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 15
21/03/14 14:34:00 INFO ContextCleaner: Cleaned accumulator 18
21/03/14 14:34:01 INFO CodeGenerator: Code generated in 19.409071 ms
21/03/14 14:34:01 INFO CodeGenerator: Code generated in 24.607726 ms
21/03/14 14:34:01 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:34:01 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:34:01 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 14:34:01 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:34:01 INFO DAGScheduler: Missing parents: List()
21/03/14 14:34:01 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/03/14 14:34:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 14:34:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 14:34:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:57177 (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:34:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 14:34:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:34:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 14:34:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:34:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 14:34:01 INFO CodeGenerator: Code generated in 10.623064 ms
21/03/14 14:34:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 14:34:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on localhost (executor driver) (1/1)
21/03/14 14:34:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 14:34:01 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.046 s
21/03/14 14:34:01 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.049484 s
21/03/14 14:34:01 INFO CodeGenerator: Code generated in 14.235453 ms
21/03/14 14:34:01 INFO CodeGenerator: Code generated in 14.272701 ms
21/03/14 14:34:01 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:34:01 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/03/14 14:34:01 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 14:34:01 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 14:34:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 14:34:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 14:34:01 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/03/14 14:34:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/03/14 14:34:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/03/14 14:34:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:57177 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:34:01 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 14:34:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:34:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 14:34:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:34:01 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 14:34:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 14:34:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 62 ms on localhost (executor driver) (1/1)
21/03/14 14:34:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 14:34:02 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.079 s
21/03/14 14:34:02 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:34:02 INFO DAGScheduler: running: Set()
21/03/14 14:34:02 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 14:34:02 INFO DAGScheduler: failed: Set()
21/03/14 14:34:02 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/03/14 14:34:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:34:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:34:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:57177 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:34:02 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 14:34:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:34:02 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 14:34:02 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:34:02 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 14:34:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:34:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
21/03/14 14:34:02 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 14:34:02 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 59 ms on localhost (executor driver) (1/1)
21/03/14 14:34:02 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 14:34:02 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.070 s
21/03/14 14:34:02 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.181601 s
21/03/14 14:34:02 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:34:02 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:34:02 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/03/14 14:34:02 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:34:02 INFO DAGScheduler: Missing parents: List()
21/03/14 14:34:02 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135), which has no missing parents
21/03/14 14:34:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 14:34:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 14:34:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:57177 (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:34:02 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 14:34:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:34:02 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 14:34:02 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:34:02 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 14:34:02 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/03/14 14:34:02 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on localhost (executor driver) (1/1)
21/03/14 14:34:02 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 14:34:02 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.017 s
21/03/14 14:34:02 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.020819 s
21/03/14 14:34:02 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:34:02 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:135)
21/03/14 14:34:02 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/14 14:34:02 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/03/14 14:34:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/03/14 14:34:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/03/14 14:34:02 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/03/14 14:34:02 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/03/14 14:34:02 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/03/14 14:34:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:57177 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:34:02 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 14:34:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:34:02 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 14:34:02 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:34:02 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 14:34:02 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1542 bytes result sent to driver
21/03/14 14:34:02 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 11 ms on localhost (executor driver) (1/1)
21/03/14 14:34:02 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 14:34:02 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.019 s
21/03/14 14:34:02 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:34:02 INFO DAGScheduler: running: Set()
21/03/14 14:34:02 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/03/14 14:34:02 INFO DAGScheduler: failed: Set()
21/03/14 14:34:02 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/03/14 14:34:02 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:34:02 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:34:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:57177 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:34:02 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 14:34:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:34:02 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 14:34:02 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:34:02 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 14:34:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:34:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:34:02 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/03/14 14:34:02 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 11 ms on localhost (executor driver) (1/1)
21/03/14 14:34:02 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 14:34:02 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.021 s
21/03/14 14:34:02 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.046969 s
21/03/14 14:34:03 INFO CodeGenerator: Code generated in 40.524001 ms
21/03/14 14:34:03 INFO CodeGenerator: Code generated in 103.993599 ms
21/03/14 14:34:03 INFO CodeGenerator: Code generated in 25.048234 ms
21/03/14 14:34:03 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:34:03 INFO DAGScheduler: Registering RDD 28 (count at utils.scala:135)
21/03/14 14:34:03 INFO DAGScheduler: Got job 5 (count at utils.scala:135) with 1 output partitions
21/03/14 14:34:03 INFO DAGScheduler: Final stage: ResultStage 8 (count at utils.scala:135)
21/03/14 14:34:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
21/03/14 14:34:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
21/03/14 14:34:03 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135), which has no missing parents
21/03/14 14:34:03 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 197
21/03/14 14:34:03 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:34:03 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:57177 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:34:03 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 14:34:03 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:57177 in memory (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:34:03 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/03/14 14:34:03 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 125
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 85
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 115
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 124
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 154
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 36
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 94
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 111
21/03/14 14:34:03 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8034 bytes)
21/03/14 14:34:03 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 8, localhost, executor driver, partition 1, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:34:03 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 9, localhost, executor driver, partition 2, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:34:03 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 10, localhost, executor driver, partition 3, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:34:03 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 14:34:03 INFO Executor: Running task 1.0 in stage 7.0 (TID 8)
21/03/14 14:34:03 INFO Executor: Running task 2.0 in stage 7.0 (TID 9)
21/03/14 14:34:03 INFO Executor: Running task 3.0 in stage 7.0 (TID 10)
21/03/14 14:34:03 INFO ContextCleaner: Cleaned shuffle 1
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 30
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 72
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 127
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 103
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 100
21/03/14 14:34:03 INFO ContextCleaner: Cleaned shuffle 0
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 208
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 139
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 200
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 164
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 37
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 173
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 117
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 184
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 98
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 34
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 191
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 119
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 136
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 26
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 165
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 83
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 99
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 203
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 204
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 105
21/03/14 14:34:03 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:57177 in memory (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 90
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 93
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 146
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 142
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 187
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 71
21/03/14 14:34:03 INFO Executor: Finished task 3.0 in stage 7.0 (TID 10). 1499 bytes result sent to driver
21/03/14 14:34:03 INFO Executor: Finished task 2.0 in stage 7.0 (TID 9). 1499 bytes result sent to driver
21/03/14 14:34:03 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:57177 in memory (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:34:03 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1499 bytes result sent to driver
21/03/14 14:34:03 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 10) in 17 ms on localhost (executor driver) (1/4)
21/03/14 14:34:03 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 9) in 18 ms on localhost (executor driver) (2/4)
21/03/14 14:34:03 INFO Executor: Finished task 1.0 in stage 7.0 (TID 8). 1499 bytes result sent to driver
21/03/14 14:34:03 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 21 ms on localhost (executor driver) (3/4)
21/03/14 14:34:03 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 8) in 19 ms on localhost (executor driver) (4/4)
21/03/14 14:34:03 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 175
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 113
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 110
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 102
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 77
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 82
21/03/14 14:34:03 INFO DAGScheduler: ShuffleMapStage 7 (count at utils.scala:135) finished in 0.044 s
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 32
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 202
21/03/14 14:34:03 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 195
21/03/14 14:34:03 INFO DAGScheduler: running: Set()
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 14:34:03 INFO DAGScheduler: waiting: Set(ResultStage 8)
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 70
21/03/14 14:34:03 INFO DAGScheduler: failed: Set()
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 176
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 126
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 209
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 73
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 167
21/03/14 14:34:03 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135), which has no missing parents
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 206
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 114
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 80
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 181
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 148
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 170
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 86
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 123
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 131
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 28
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 157
21/03/14 14:34:03 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:34:03 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:57177 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 121
21/03/14 14:34:03 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 212
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 179
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 174
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 133
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 74
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 107
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 68
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 168
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 140
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 194
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 84
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 150
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 95
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 92
21/03/14 14:34:03 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:57177 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 190
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 27
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 109
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 210
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 149
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 185
21/03/14 14:34:03 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 201
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 207
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 97
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 81
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 66
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 67
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 177
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 76
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 172
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 106
21/03/14 14:34:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 89
21/03/14 14:34:03 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 159
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 186
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 162
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 96
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 166
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 196
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 130
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 199
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 188
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 108
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 161
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 151
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 112
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 156
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 163
21/03/14 14:34:03 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 152
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 158
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 132
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 69
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 171
21/03/14 14:34:03 INFO Executor: Running task 0.0 in stage 8.0 (TID 11)
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 65
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 101
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 155
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 180
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 147
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 33
21/03/14 14:34:03 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:57177 in memory (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:34:03 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
21/03/14 14:34:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 160
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 120
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 182
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 88
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 78
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 31
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 144
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 198
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 137
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 153
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 169
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 64
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 145
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 91
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 134
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 183
21/03/14 14:34:03 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:57177 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:34:03 INFO Executor: Finished task 0.0 in stage 8.0 (TID 11). 1782 bytes result sent to driver
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 178
21/03/14 14:34:03 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 11) in 10 ms on localhost (executor driver) (1/1)
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 87
21/03/14 14:34:03 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 122
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 138
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 143
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 116
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 79
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 189
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 29
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 193
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 192
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 129
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 205
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 128
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 104
21/03/14 14:34:03 INFO DAGScheduler: ResultStage 8 (count at utils.scala:135) finished in 0.018 s
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 135
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 141
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 35
21/03/14 14:34:03 INFO ContextCleaner: Cleaned accumulator 75
21/03/14 14:34:03 INFO DAGScheduler: Job 5 finished: count at utils.scala:135, took 0.068347 s
21/03/14 14:34:03 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:34:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:34:03 INFO HiveMetaStore: 0: get_database: fake_database
21/03/14 14:34:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: fake_database	
21/03/14 14:34:03 WARN ObjectStore: Failed to get database fake_database, returning NoSuchObjectException
21/03/14 14:34:03 INFO HiveMetaStore: 0: get_databases: *
21/03/14 14:34:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_databases: *	
21/03/14 14:34:03 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:34:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:34:03 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:34:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:34:03 INFO CodeGenerator: Code generated in 26.440669 ms
21/03/14 14:34:04 INFO CodeGenerator: Code generated in 11.093239 ms
21/03/14 14:34:04 INFO CodeGenerator: Code generated in 9.590413 ms
21/03/14 14:34:04 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:34:04 INFO DAGScheduler: Registering RDD 35 (count at utils.scala:135)
21/03/14 14:34:04 INFO DAGScheduler: Got job 6 (count at utils.scala:135) with 1 output partitions
21/03/14 14:34:04 INFO DAGScheduler: Final stage: ResultStage 10 (count at utils.scala:135)
21/03/14 14:34:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
21/03/14 14:34:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
21/03/14 14:34:04 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[35] at count at utils.scala:135), which has no missing parents
21/03/14 14:34:04 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 14:34:04 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 14:34:04 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:57177 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:34:04 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 14:34:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[35] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:34:04 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 14:34:04 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 14:34:04 INFO Executor: Running task 0.0 in stage 9.0 (TID 12)
21/03/14 14:34:04 INFO Executor: Finished task 0.0 in stage 9.0 (TID 12). 1499 bytes result sent to driver
21/03/14 14:34:04 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 12) in 9 ms on localhost (executor driver) (1/1)
21/03/14 14:34:04 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 14:34:04 INFO DAGScheduler: ShuffleMapStage 9 (count at utils.scala:135) finished in 0.016 s
21/03/14 14:34:04 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:34:04 INFO DAGScheduler: running: Set()
21/03/14 14:34:04 INFO DAGScheduler: waiting: Set(ResultStage 10)
21/03/14 14:34:04 INFO DAGScheduler: failed: Set()
21/03/14 14:34:04 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[38] at count at utils.scala:135), which has no missing parents
21/03/14 14:34:04 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:34:04 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:34:04 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:57177 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:34:04 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 14:34:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:34:04 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/03/14 14:34:04 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:34:04 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
21/03/14 14:34:04 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:34:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:34:04 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 1782 bytes result sent to driver
21/03/14 14:34:04 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:34:04 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/03/14 14:34:04 INFO DAGScheduler: ResultStage 10 (count at utils.scala:135) finished in 0.014 s
21/03/14 14:34:04 INFO DAGScheduler: Job 6 finished: count at utils.scala:135, took 0.035682 s
21/03/14 14:34:04 INFO HiveMetaStore: 0: create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})
21/03/14 14:34:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})	
21/03/14 14:34:04 WARN ObjectStore: Failed to get database catalog_test_database_db, returning NoSuchObjectException
21/03/14 14:34:04 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:34:04 INFO CodeGenerator: Code generated in 9.331215 ms
21/03/14 14:34:04 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:34:04 INFO DAGScheduler: Registering RDD 42 (count at utils.scala:135)
21/03/14 14:34:04 INFO DAGScheduler: Got job 7 (count at utils.scala:135) with 1 output partitions
21/03/14 14:34:04 INFO DAGScheduler: Final stage: ResultStage 12 (count at utils.scala:135)
21/03/14 14:34:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
21/03/14 14:34:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
21/03/14 14:34:04 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[42] at count at utils.scala:135), which has no missing parents
21/03/14 14:34:04 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:34:04 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:34:04 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:57177 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:34:04 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
21/03/14 14:34:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[42] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:34:04 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/03/14 14:34:04 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 14:34:04 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
21/03/14 14:34:04 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 1499 bytes result sent to driver
21/03/14 14:34:04 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 11 ms on localhost (executor driver) (1/1)
21/03/14 14:34:04 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/03/14 14:34:04 INFO DAGScheduler: ShuffleMapStage 11 (count at utils.scala:135) finished in 0.019 s
21/03/14 14:34:04 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:34:04 INFO DAGScheduler: running: Set()
21/03/14 14:34:04 INFO DAGScheduler: waiting: Set(ResultStage 12)
21/03/14 14:34:04 INFO DAGScheduler: failed: Set()
21/03/14 14:34:04 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[45] at count at utils.scala:135), which has no missing parents
21/03/14 14:34:04 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:34:04 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:34:04 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:57177 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:34:04 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 14:34:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[45] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:34:04 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/03/14 14:34:04 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 15, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:34:04 INFO Executor: Running task 0.0 in stage 12.0 (TID 15)
21/03/14 14:34:04 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:34:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:34:04 INFO Executor: Finished task 0.0 in stage 12.0 (TID 15). 1775 bytes result sent to driver
21/03/14 14:34:04 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 15) in 9 ms on localhost (executor driver) (1/1)
21/03/14 14:34:04 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/03/14 14:34:04 INFO DAGScheduler: ResultStage 12 (count at utils.scala:135) finished in 0.018 s
21/03/14 14:34:04 INFO DAGScheduler: Job 7 finished: count at utils.scala:135, took 0.041142 s
21/03/14 14:34:04 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:34:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:34:04 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:34:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:34:04 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:34:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:34:04 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:34:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:34:04 INFO HiveMetaStore: 0: drop_database: catalog_test_database_db
21/03/14 14:34:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=drop_database: catalog_test_database_db	
21/03/14 14:34:04 INFO HiveMetaStore: 0: get_all_tables: db=catalog_test_database_db
21/03/14 14:34:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_tables: db=catalog_test_database_db	
21/03/14 14:34:04 INFO HiveMetaStore: 0: get_functions: db=catalog_test_database_db pat=*
21/03/14 14:34:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=catalog_test_database_db pat=*	
21/03/14 14:34:04 INFO ObjectStore: Dropping database catalog_test_database_db along with all tables
21/03/14 14:34:04 INFO hivemetastoressimpl: deleting  file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:34:04 INFO deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
21/03/14 14:34:04 INFO TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
21/03/14 14:34:04 INFO hivemetastoressimpl: Deleted the diretory file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:34:04 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:34:04 INFO DAGScheduler: Registering RDD 49 (count at utils.scala:135)
21/03/14 14:34:04 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/03/14 14:34:04 INFO DAGScheduler: Final stage: ResultStage 14 (count at utils.scala:135)
21/03/14 14:34:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/03/14 14:34:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/03/14 14:34:04 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[49] at count at utils.scala:135), which has no missing parents
21/03/14 14:34:04 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:34:04 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:34:04 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:57177 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:34:04 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 14:34:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[49] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:34:04 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/03/14 14:34:04 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 14:34:04 INFO Executor: Running task 0.0 in stage 13.0 (TID 16)
21/03/14 14:34:04 INFO Executor: Finished task 0.0 in stage 13.0 (TID 16). 1499 bytes result sent to driver
21/03/14 14:34:04 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 16) in 10 ms on localhost (executor driver) (1/1)
21/03/14 14:34:04 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/03/14 14:34:04 INFO DAGScheduler: ShuffleMapStage 13 (count at utils.scala:135) finished in 0.016 s
21/03/14 14:34:04 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:34:04 INFO DAGScheduler: running: Set()
21/03/14 14:34:04 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/03/14 14:34:04 INFO DAGScheduler: failed: Set()
21/03/14 14:34:04 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[52] at count at utils.scala:135), which has no missing parents
21/03/14 14:34:04 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:34:04 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:34:04 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:57177 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:34:04 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
21/03/14 14:34:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[52] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:34:04 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/03/14 14:34:04 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 17, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:34:04 INFO Executor: Running task 0.0 in stage 14.0 (TID 17)
21/03/14 14:34:04 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:34:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:34:04 INFO Executor: Finished task 0.0 in stage 14.0 (TID 17). 1775 bytes result sent to driver
21/03/14 14:34:04 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 17) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:34:04 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/03/14 14:34:04 INFO DAGScheduler: ResultStage 14 (count at utils.scala:135) finished in 0.014 s
21/03/14 14:34:04 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.036014 s
21/03/14 14:34:05 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:34:05 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:34:05 WARN ObjectStore: Failed to get database catalog_test_database_db, returning NoSuchObjectException
21/03/14 14:35:28 INFO HiveMetaStore: 0: get_databases: *
21/03/14 14:35:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_databases: *	
21/03/14 14:35:28 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:35:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:35:28 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:35:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:35:28 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:35:28 INFO DAGScheduler: Registering RDD 56 (count at utils.scala:135)
21/03/14 14:35:28 INFO DAGScheduler: Got job 9 (count at utils.scala:135) with 1 output partitions
21/03/14 14:35:28 INFO DAGScheduler: Final stage: ResultStage 16 (count at utils.scala:135)
21/03/14 14:35:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
21/03/14 14:35:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
21/03/14 14:35:28 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[56] at count at utils.scala:135), which has no missing parents
21/03/14 14:35:28 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:35:28 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:35:28 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:57177 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:35:28 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1161
21/03/14 14:35:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[56] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:35:28 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/03/14 14:35:28 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 14:35:28 INFO Executor: Running task 0.0 in stage 15.0 (TID 18)
21/03/14 14:35:28 INFO Executor: Finished task 0.0 in stage 15.0 (TID 18). 1499 bytes result sent to driver
21/03/14 14:35:28 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 18) in 9 ms on localhost (executor driver) (1/1)
21/03/14 14:35:28 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/03/14 14:35:28 INFO DAGScheduler: ShuffleMapStage 15 (count at utils.scala:135) finished in 0.017 s
21/03/14 14:35:28 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:35:28 INFO DAGScheduler: running: Set()
21/03/14 14:35:28 INFO DAGScheduler: waiting: Set(ResultStage 16)
21/03/14 14:35:28 INFO DAGScheduler: failed: Set()
21/03/14 14:35:28 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[59] at count at utils.scala:135), which has no missing parents
21/03/14 14:35:28 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:35:28 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:35:28 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:57177 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:35:28 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1161
21/03/14 14:35:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[59] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:35:28 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/03/14 14:35:28 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 19, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:35:28 INFO Executor: Running task 0.0 in stage 16.0 (TID 19)
21/03/14 14:35:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:35:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:35:28 INFO Executor: Finished task 0.0 in stage 16.0 (TID 19). 1782 bytes result sent to driver
21/03/14 14:35:28 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 19) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:35:28 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/03/14 14:35:28 INFO DAGScheduler: ResultStage 16 (count at utils.scala:135) finished in 0.014 s
21/03/14 14:35:28 INFO DAGScheduler: Job 9 finished: count at utils.scala:135, took 0.036269 s
21/03/14 14:35:52 INFO HiveMetaStore: 0: get_database: catalog_
21/03/14 14:35:52 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_	
21/03/14 14:35:52 WARN ObjectStore: Failed to get database catalog_, returning NoSuchObjectException
21/03/14 14:36:00 INFO HiveMetaStore: 0: get_database: catalog_
21/03/14 14:36:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_	
21/03/14 14:36:00 WARN ObjectStore: Failed to get database catalog_, returning NoSuchObjectException
21/03/14 14:36:29 INFO HiveMetaStore: 0: create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})
21/03/14 14:36:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})	
21/03/14 14:36:29 WARN ObjectStore: Failed to get database catalog_test_database_db, returning NoSuchObjectException
21/03/14 14:36:29 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:36:30 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:36:30 INFO DAGScheduler: Registering RDD 63 (count at utils.scala:135)
21/03/14 14:36:30 INFO DAGScheduler: Got job 10 (count at utils.scala:135) with 1 output partitions
21/03/14 14:36:30 INFO DAGScheduler: Final stage: ResultStage 18 (count at utils.scala:135)
21/03/14 14:36:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
21/03/14 14:36:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
21/03/14 14:36:30 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[63] at count at utils.scala:135), which has no missing parents
21/03/14 14:36:30 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:36:30 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:36:30 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:57177 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:36:30 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1161
21/03/14 14:36:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[63] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:36:30 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/03/14 14:36:30 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 14:36:30 INFO Executor: Running task 0.0 in stage 17.0 (TID 20)
21/03/14 14:36:30 INFO Executor: Finished task 0.0 in stage 17.0 (TID 20). 1499 bytes result sent to driver
21/03/14 14:36:30 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 20) in 9 ms on localhost (executor driver) (1/1)
21/03/14 14:36:30 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/03/14 14:36:30 INFO DAGScheduler: ShuffleMapStage 17 (count at utils.scala:135) finished in 0.017 s
21/03/14 14:36:30 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:36:30 INFO DAGScheduler: running: Set()
21/03/14 14:36:30 INFO DAGScheduler: waiting: Set(ResultStage 18)
21/03/14 14:36:30 INFO DAGScheduler: failed: Set()
21/03/14 14:36:30 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[66] at count at utils.scala:135), which has no missing parents
21/03/14 14:36:30 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:36:30 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:36:30 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:57177 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:36:30 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1161
21/03/14 14:36:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[66] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:36:30 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/03/14 14:36:30 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 21, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:36:30 INFO Executor: Running task 0.0 in stage 18.0 (TID 21)
21/03/14 14:36:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:36:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:36:30 INFO Executor: Finished task 0.0 in stage 18.0 (TID 21). 1775 bytes result sent to driver
21/03/14 14:36:30 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 21) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:36:30 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/03/14 14:36:30 INFO DAGScheduler: ResultStage 18 (count at utils.scala:135) finished in 0.014 s
21/03/14 14:36:30 INFO DAGScheduler: Job 10 finished: count at utils.scala:135, took 0.039501 s
21/03/14 14:36:35 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:36:35 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:36:35 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:36:35 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:36:35 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:36:35 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:36:38 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:36:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:36:38 INFO HiveMetaStore: 0: drop_database: catalog_test_database_db
21/03/14 14:36:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=drop_database: catalog_test_database_db	
21/03/14 14:36:38 INFO HiveMetaStore: 0: get_all_tables: db=catalog_test_database_db
21/03/14 14:36:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_tables: db=catalog_test_database_db	
21/03/14 14:36:38 INFO HiveMetaStore: 0: get_functions: db=catalog_test_database_db pat=*
21/03/14 14:36:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=catalog_test_database_db pat=*	
21/03/14 14:36:38 INFO ObjectStore: Dropping database catalog_test_database_db along with all tables
21/03/14 14:36:38 INFO hivemetastoressimpl: deleting  file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:36:38 INFO TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
21/03/14 14:36:38 INFO hivemetastoressimpl: Deleted the diretory file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:36:38 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:36:38 INFO DAGScheduler: Registering RDD 70 (count at utils.scala:135)
21/03/14 14:36:38 INFO DAGScheduler: Got job 11 (count at utils.scala:135) with 1 output partitions
21/03/14 14:36:38 INFO DAGScheduler: Final stage: ResultStage 20 (count at utils.scala:135)
21/03/14 14:36:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
21/03/14 14:36:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
21/03/14 14:36:38 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[70] at count at utils.scala:135), which has no missing parents
21/03/14 14:36:38 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:36:38 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:36:38 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:57177 (size: 4.2 KB, free: 912.2 MB)
21/03/14 14:36:38 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1161
21/03/14 14:36:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[70] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:36:38 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/03/14 14:36:38 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 14:36:38 INFO Executor: Running task 0.0 in stage 19.0 (TID 22)
21/03/14 14:36:38 INFO Executor: Finished task 0.0 in stage 19.0 (TID 22). 1499 bytes result sent to driver
21/03/14 14:36:38 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 22) in 8 ms on localhost (executor driver) (1/1)
21/03/14 14:36:38 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/03/14 14:36:38 INFO DAGScheduler: ShuffleMapStage 19 (count at utils.scala:135) finished in 0.018 s
21/03/14 14:36:38 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:36:38 INFO DAGScheduler: running: Set()
21/03/14 14:36:38 INFO DAGScheduler: waiting: Set(ResultStage 20)
21/03/14 14:36:38 INFO DAGScheduler: failed: Set()
21/03/14 14:36:38 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[73] at count at utils.scala:135), which has no missing parents
21/03/14 14:36:38 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.1 KB, free 912.1 MB)
21/03/14 14:36:38 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.1 MB)
21/03/14 14:36:38 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:57177 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:36:38 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1161
21/03/14 14:36:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[73] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:36:38 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/03/14 14:36:38 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 23, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:36:38 INFO Executor: Running task 0.0 in stage 20.0 (TID 23)
21/03/14 14:36:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:36:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:36:38 INFO Executor: Finished task 0.0 in stage 20.0 (TID 23). 1775 bytes result sent to driver
21/03/14 14:36:38 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 23) in 5 ms on localhost (executor driver) (1/1)
21/03/14 14:36:38 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/03/14 14:36:38 INFO DAGScheduler: ResultStage 20 (count at utils.scala:135) finished in 0.012 s
21/03/14 14:36:38 INFO DAGScheduler: Job 11 finished: count at utils.scala:135, took 0.033707 s
21/03/14 14:36:43 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 14:36:43 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 14:36:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 14:36:43 INFO MemoryStore: MemoryStore cleared
21/03/14 14:36:43 INFO BlockManager: BlockManager stopped
21/03/14 14:36:43 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 14:36:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 14:36:43 INFO SparkContext: Successfully stopped SparkContext
21/03/14 14:36:43 INFO ShutdownHookManager: Shutdown hook called
21/03/14 14:36:43 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-75e7f47f-a1d9-469b-80a7-f973fef54696
21/03/14 14:36:43 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-e63d91e3-a3e9-4cf7-99c1-7dd11043745a
21/03/14 14:37:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 14:37:02 INFO SparkContext: Running Spark version 2.4.3
21/03/14 14:37:02 INFO SparkContext: Submitted application: sparklyr
21/03/14 14:37:02 INFO SecurityManager: Changing view acls to: nathan
21/03/14 14:37:02 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 14:37:02 INFO SecurityManager: Changing view acls groups to: 
21/03/14 14:37:02 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 14:37:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 14:37:02 INFO Utils: Successfully started service 'sparkDriver' on port 57466.
21/03/14 14:37:02 INFO SparkEnv: Registering MapOutputTracker
21/03/14 14:37:02 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 14:37:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 14:37:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 14:37:02 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-b57d0511-81c7-4d48-be7d-9562e4a547ce
21/03/14 14:37:02 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 14:37:02 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 14:37:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 14:37:02 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 14:37:02 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:57466/jars/sparklyr-2.4-2.11.jar with timestamp 1615729022913
21/03/14 14:37:02 INFO Executor: Starting executor ID driver on host localhost
21/03/14 14:37:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57468.
21/03/14 14:37:03 INFO NettyBlockTransferService: Server created on localhost:57468
21/03/14 14:37:03 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 14:37:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 57468, None)
21/03/14 14:37:03 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57468 with 912.3 MB RAM, BlockManagerId(driver, localhost, 57468, None)
21/03/14 14:37:03 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 57468, None)
21/03/14 14:37:03 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 57468, None)
21/03/14 14:37:03 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 14:37:03 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 14:37:03 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 14:37:03 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 14:37:05 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 14:37:06 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 14:37:06 INFO ObjectStore: ObjectStore, initialize called
21/03/14 14:37:06 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 14:37:06 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 14:37:08 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 14:37:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:37:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:37:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:37:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:37:09 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 14:37:09 INFO ObjectStore: Initialized ObjectStore
21/03/14 14:37:09 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 14:37:10 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 14:37:10 INFO HiveMetaStore: Added admin role in metastore
21/03/14 14:37:10 INFO HiveMetaStore: Added public role in metastore
21/03/14 14:37:10 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 14:37:10 INFO HiveMetaStore: 0: get_all_databases
21/03/14 14:37:10 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 14:37:10 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:37:10 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:37:10 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:37:10 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/8c250997-ab0c-4d37-b62d-e43414eda45f_resources
21/03/14 14:37:10 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/8c250997-ab0c-4d37-b62d-e43414eda45f
21/03/14 14:37:10 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/8c250997-ab0c-4d37-b62d-e43414eda45f
21/03/14 14:37:10 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/8c250997-ab0c-4d37-b62d-e43414eda45f/_tmp_space.db
21/03/14 14:37:10 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 14:37:10 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:37:10 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:37:10 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 14:37:10 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 14:37:10 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 14:37:10 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:37:10 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:37:10 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:37:10 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:37:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 14:37:10 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 14:37:10 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 14:37:10 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/03/14 14:37:10 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/03/14 14:37:10 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:37:10 INFO DAGScheduler: Missing parents: List()
21/03/14 14:37:10 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/03/14 14:37:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/03/14 14:37:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/03/14 14:37:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57468 (size: 3.4 KB, free: 912.3 MB)
21/03/14 14:37:11 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 14:37:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 14:37:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 14:37:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/03/14 14:37:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 14:37:11 INFO Executor: Fetching spark://localhost:57466/jars/sparklyr-2.4-2.11.jar with timestamp 1615729022913
21/03/14 14:37:11 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:57466 after 20 ms (0 ms spent in bootstraps)
21/03/14 14:37:11 INFO Utils: Fetching spark://localhost:57466/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-afb5cc86-0e60-463e-8769-feba4525ce59/userFiles-1858243c-b36c-4b42-bf7f-78af99c1df7b/fetchFileTemp6855846114511917087.tmp
21/03/14 14:37:11 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-afb5cc86-0e60-463e-8769-feba4525ce59/userFiles-1858243c-b36c-4b42-bf7f-78af99c1df7b/sparklyr-2.4-2.11.jar to class loader
21/03/14 14:37:11 INFO CodeGenerator: Code generated in 198.929281 ms
21/03/14 14:37:11 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
21/03/14 14:37:11 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 555 ms on localhost (executor driver) (1/1)
21/03/14 14:37:11 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 14:37:11 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 0.897 s
21/03/14 14:37:11 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 0.951067 s
21/03/14 14:37:11 INFO ContextCleaner: Cleaned accumulator 15
21/03/14 14:37:11 INFO ContextCleaner: Cleaned accumulator 22
21/03/14 14:37:11 INFO ContextCleaner: Cleaned accumulator 2
21/03/14 14:37:11 INFO ContextCleaner: Cleaned accumulator 24
21/03/14 14:37:11 INFO ContextCleaner: Cleaned accumulator 3
21/03/14 14:37:12 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:57468 in memory (size: 3.4 KB, free: 912.3 MB)
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 16
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 7
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 9
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 4
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 1
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 6
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 21
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 8
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 23
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 19
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 25
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 12
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 18
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 17
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 0
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 5
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 11
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 10
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 20
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 14
21/03/14 14:37:12 INFO ContextCleaner: Cleaned accumulator 13
21/03/14 14:37:12 INFO CodeGenerator: Code generated in 17.169695 ms
21/03/14 14:37:12 INFO CodeGenerator: Code generated in 16.644105 ms
21/03/14 14:37:12 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:37:12 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:37:12 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 14:37:12 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:37:12 INFO DAGScheduler: Missing parents: List()
21/03/14 14:37:12 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/03/14 14:37:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 14:37:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 14:37:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:57468 (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:37:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 14:37:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:37:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 14:37:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:37:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 14:37:12 INFO CodeGenerator: Code generated in 6.944108 ms
21/03/14 14:37:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 14:37:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 25 ms on localhost (executor driver) (1/1)
21/03/14 14:37:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 14:37:12 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.032 s
21/03/14 14:37:12 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.035681 s
21/03/14 14:37:12 INFO CodeGenerator: Code generated in 13.821399 ms
21/03/14 14:37:12 INFO CodeGenerator: Code generated in 9.748328 ms
21/03/14 14:37:12 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:37:12 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/03/14 14:37:12 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 14:37:12 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 14:37:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 14:37:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 14:37:12 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/03/14 14:37:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/03/14 14:37:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/03/14 14:37:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:57468 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:37:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 14:37:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:37:12 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 14:37:12 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:37:12 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 14:37:12 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 14:37:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 43 ms on localhost (executor driver) (1/1)
21/03/14 14:37:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 14:37:12 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.056 s
21/03/14 14:37:12 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:37:12 INFO DAGScheduler: running: Set()
21/03/14 14:37:12 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 14:37:12 INFO DAGScheduler: failed: Set()
21/03/14 14:37:12 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/03/14 14:37:12 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:37:12 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:37:12 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:57468 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:37:12 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 14:37:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:37:12 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 14:37:12 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:37:12 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 14:37:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:37:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
21/03/14 14:37:12 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 14:37:12 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 46 ms on localhost (executor driver) (1/1)
21/03/14 14:37:12 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 14:37:12 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.057 s
21/03/14 14:37:12 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.134779 s
21/03/14 14:37:13 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:37:13 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:37:13 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/03/14 14:37:13 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:37:13 INFO DAGScheduler: Missing parents: List()
21/03/14 14:37:13 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135), which has no missing parents
21/03/14 14:37:13 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 14:37:13 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 14:37:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:57468 (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:37:13 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 14:37:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:37:13 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 14:37:13 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:37:13 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 14:37:13 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/03/14 14:37:13 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
21/03/14 14:37:13 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 14:37:13 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.013 s
21/03/14 14:37:13 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.016435 s
21/03/14 14:37:13 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:37:13 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:135)
21/03/14 14:37:13 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/14 14:37:13 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/03/14 14:37:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/03/14 14:37:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/03/14 14:37:13 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/03/14 14:37:13 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/03/14 14:37:13 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/03/14 14:37:13 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:57468 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:37:13 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 14:37:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:37:13 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 14:37:13 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:37:13 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 14:37:13 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/03/14 14:37:13 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 9 ms on localhost (executor driver) (1/1)
21/03/14 14:37:13 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 14:37:13 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.016 s
21/03/14 14:37:13 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:37:13 INFO DAGScheduler: running: Set()
21/03/14 14:37:13 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/03/14 14:37:13 INFO DAGScheduler: failed: Set()
21/03/14 14:37:13 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/03/14 14:37:13 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:37:13 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:37:13 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:57468 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:37:13 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 14:37:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:37:13 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 14:37:13 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:37:13 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 14:37:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:37:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:37:13 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/03/14 14:37:13 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 6 ms on localhost (executor driver) (1/1)
21/03/14 14:37:13 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 14:37:13 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.012 s
21/03/14 14:37:13 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.031550 s
21/03/14 14:37:13 INFO CodeGenerator: Code generated in 30.449658 ms
21/03/14 14:37:13 INFO CodeGenerator: Code generated in 12.811469 ms
21/03/14 14:37:13 INFO CodeGenerator: Code generated in 14.838723 ms
21/03/14 14:37:13 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:37:13 INFO DAGScheduler: Registering RDD 28 (count at utils.scala:135)
21/03/14 14:37:13 INFO DAGScheduler: Got job 5 (count at utils.scala:135) with 1 output partitions
21/03/14 14:37:13 INFO DAGScheduler: Final stage: ResultStage 8 (count at utils.scala:135)
21/03/14 14:37:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
21/03/14 14:37:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
21/03/14 14:37:13 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135), which has no missing parents
21/03/14 14:37:13 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:37:13 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:37:13 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:57468 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:37:13 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 14:37:13 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/03/14 14:37:13 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
21/03/14 14:37:13 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8034 bytes)
21/03/14 14:37:13 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 8, localhost, executor driver, partition 1, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:37:13 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 9, localhost, executor driver, partition 2, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:37:13 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 10, localhost, executor driver, partition 3, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:37:13 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 14:37:13 INFO Executor: Running task 1.0 in stage 7.0 (TID 8)
21/03/14 14:37:13 INFO Executor: Running task 2.0 in stage 7.0 (TID 9)
21/03/14 14:37:13 INFO Executor: Running task 3.0 in stage 7.0 (TID 10)
21/03/14 14:37:13 INFO Executor: Finished task 1.0 in stage 7.0 (TID 8). 1499 bytes result sent to driver
21/03/14 14:37:13 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1499 bytes result sent to driver
21/03/14 14:37:13 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 8) in 12 ms on localhost (executor driver) (1/4)
21/03/14 14:37:13 INFO Executor: Finished task 3.0 in stage 7.0 (TID 10). 1499 bytes result sent to driver
21/03/14 14:37:13 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 13 ms on localhost (executor driver) (2/4)
21/03/14 14:37:13 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 10) in 13 ms on localhost (executor driver) (3/4)
21/03/14 14:37:13 INFO Executor: Finished task 2.0 in stage 7.0 (TID 9). 1499 bytes result sent to driver
21/03/14 14:37:13 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 9) in 20 ms on localhost (executor driver) (4/4)
21/03/14 14:37:13 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 14:37:13 INFO DAGScheduler: ShuffleMapStage 7 (count at utils.scala:135) finished in 0.030 s
21/03/14 14:37:13 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:37:13 INFO DAGScheduler: running: Set()
21/03/14 14:37:13 INFO DAGScheduler: waiting: Set(ResultStage 8)
21/03/14 14:37:13 INFO DAGScheduler: failed: Set()
21/03/14 14:37:13 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135), which has no missing parents
21/03/14 14:37:13 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:37:13 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:37:13 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:57468 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:37:13 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 14:37:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:37:13 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 14:37:13 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:37:13 INFO Executor: Running task 0.0 in stage 8.0 (TID 11)
21/03/14 14:37:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
21/03/14 14:37:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:37:13 INFO Executor: Finished task 0.0 in stage 8.0 (TID 11). 1782 bytes result sent to driver
21/03/14 14:37:13 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 11) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:37:13 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 14:37:13 INFO DAGScheduler: ResultStage 8 (count at utils.scala:135) finished in 0.015 s
21/03/14 14:37:13 INFO DAGScheduler: Job 5 finished: count at utils.scala:135, took 0.049178 s
21/03/14 14:37:14 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:37:14 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:37:14 INFO HiveMetaStore: 0: get_database: fake_database
21/03/14 14:37:14 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: fake_database	
21/03/14 14:37:14 WARN ObjectStore: Failed to get database fake_database, returning NoSuchObjectException
21/03/14 14:37:14 INFO HiveMetaStore: 0: get_databases: *
21/03/14 14:37:14 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_databases: *	
21/03/14 14:37:14 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:37:14 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:37:14 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:37:14 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:37:14 INFO CodeGenerator: Code generated in 33.552302 ms
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 27
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 208
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 264
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 69
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 142
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 74
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 220
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 125
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 75
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 139
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 229
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 78
21/03/14 14:37:14 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:57468 in memory (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 64
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 87
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 113
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 174
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 150
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 102
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 91
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 73
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 132
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 245
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 37
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 222
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 190
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 238
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 233
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 121
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 191
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 252
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 172
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 83
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 184
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 221
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 193
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 234
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 145
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 14:37:14 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:57468 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 95
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 153
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 271
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 119
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 181
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 240
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 257
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 134
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 109
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 198
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 242
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 82
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 241
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 136
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 147
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 230
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 237
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 93
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 203
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 259
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 129
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 131
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 196
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 247
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 235
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 239
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 135
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 218
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 160
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 148
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 263
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 120
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 104
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 123
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 170
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 209
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 96
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 152
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 204
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 156
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 26
21/03/14 14:37:14 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:57468 in memory (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 108
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 98
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 194
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 146
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 162
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 223
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 260
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 86
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 226
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 80
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 274
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 128
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 168
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 99
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 176
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 65
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 34
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 251
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 159
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 171
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 266
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 219
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 161
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 228
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 248
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 30
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 68
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 212
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 115
21/03/14 14:37:14 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:57468 in memory (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 265
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 186
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 89
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 157
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 244
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 88
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 29
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 116
21/03/14 14:37:14 INFO ContextCleaner: Cleaned shuffle 0
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 255
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 180
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 66
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 192
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 205
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 126
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 200
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 254
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 249
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 185
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 81
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 243
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 85
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 195
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 143
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 76
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 94
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 201
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 236
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 114
21/03/14 14:37:14 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:57468 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 110
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 270
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 71
21/03/14 14:37:14 INFO CodeGenerator: Code generated in 16.980255 ms
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 32
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 79
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 232
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 175
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 268
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 227
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 137
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 144
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 231
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 206
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 262
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 122
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 253
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 28
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 133
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 269
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 215
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 250
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 130
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 167
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 273
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 165
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 154
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 70
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 183
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 112
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 36
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 276
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 31
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 199
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 138
21/03/14 14:37:14 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:57468 in memory (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 97
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 225
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 189
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 213
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 272
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 105
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 106
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 261
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 141
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 258
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 158
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 77
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 178
21/03/14 14:37:14 INFO ContextCleaner: Cleaned shuffle 1
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 149
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 217
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 166
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 197
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 207
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 177
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 35
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 101
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 67
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 100
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 202
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 187
21/03/14 14:37:14 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:57468 in memory (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 117
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 179
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 33
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 163
21/03/14 14:37:14 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:57468 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 90
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 210
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 169
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 84
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 224
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 127
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 111
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 216
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 124
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 173
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 211
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 256
21/03/14 14:37:14 INFO ContextCleaner: Cleaned shuffle 2
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 155
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 164
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 92
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 103
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 214
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 107
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 151
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 140
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 182
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 246
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 72
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 275
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 188
21/03/14 14:37:14 INFO ContextCleaner: Cleaned accumulator 267
21/03/14 14:37:14 INFO CodeGenerator: Code generated in 17.039141 ms
21/03/14 14:37:14 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:37:14 INFO DAGScheduler: Registering RDD 35 (count at utils.scala:135)
21/03/14 14:37:14 INFO DAGScheduler: Got job 6 (count at utils.scala:135) with 1 output partitions
21/03/14 14:37:14 INFO DAGScheduler: Final stage: ResultStage 10 (count at utils.scala:135)
21/03/14 14:37:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
21/03/14 14:37:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
21/03/14 14:37:14 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[35] at count at utils.scala:135), which has no missing parents
21/03/14 14:37:14 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 14:37:14 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 14:37:14 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:57468 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:37:14 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 14:37:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[35] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:37:14 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 14:37:14 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 14:37:14 INFO Executor: Running task 0.0 in stage 9.0 (TID 12)
21/03/14 14:37:14 INFO Executor: Finished task 0.0 in stage 9.0 (TID 12). 1499 bytes result sent to driver
21/03/14 14:37:14 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 12) in 10 ms on localhost (executor driver) (1/1)
21/03/14 14:37:14 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 14:37:14 INFO DAGScheduler: ShuffleMapStage 9 (count at utils.scala:135) finished in 0.017 s
21/03/14 14:37:14 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:37:14 INFO DAGScheduler: running: Set()
21/03/14 14:37:14 INFO DAGScheduler: waiting: Set(ResultStage 10)
21/03/14 14:37:14 INFO DAGScheduler: failed: Set()
21/03/14 14:37:14 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[38] at count at utils.scala:135), which has no missing parents
21/03/14 14:37:14 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:37:14 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:37:14 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:57468 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:37:14 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 14:37:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:37:14 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/03/14 14:37:14 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:37:14 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
21/03/14 14:37:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:37:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:37:14 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 1782 bytes result sent to driver
21/03/14 14:37:14 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:37:14 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/03/14 14:37:14 INFO DAGScheduler: ResultStage 10 (count at utils.scala:135) finished in 0.014 s
21/03/14 14:37:14 INFO DAGScheduler: Job 6 finished: count at utils.scala:135, took 0.035064 s
21/03/14 14:37:14 INFO HiveMetaStore: 0: create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})
21/03/14 14:37:14 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})	
21/03/14 14:37:14 WARN ObjectStore: Failed to get database catalog_test_database_db, returning NoSuchObjectException
21/03/14 14:37:14 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:37:14 INFO CodeGenerator: Code generated in 7.097811 ms
21/03/14 14:37:14 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:37:14 INFO DAGScheduler: Registering RDD 42 (count at utils.scala:135)
21/03/14 14:37:14 INFO DAGScheduler: Got job 7 (count at utils.scala:135) with 1 output partitions
21/03/14 14:37:14 INFO DAGScheduler: Final stage: ResultStage 12 (count at utils.scala:135)
21/03/14 14:37:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
21/03/14 14:37:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
21/03/14 14:37:14 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[42] at count at utils.scala:135), which has no missing parents
21/03/14 14:37:14 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 14:37:14 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 14:37:14 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:57468 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:37:14 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
21/03/14 14:37:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[42] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:37:14 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/03/14 14:37:14 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 14:37:14 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
21/03/14 14:37:14 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 1499 bytes result sent to driver
21/03/14 14:37:14 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 8 ms on localhost (executor driver) (1/1)
21/03/14 14:37:14 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/03/14 14:37:14 INFO DAGScheduler: ShuffleMapStage 11 (count at utils.scala:135) finished in 0.015 s
21/03/14 14:37:14 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:37:14 INFO DAGScheduler: running: Set()
21/03/14 14:37:14 INFO DAGScheduler: waiting: Set(ResultStage 12)
21/03/14 14:37:14 INFO DAGScheduler: failed: Set()
21/03/14 14:37:14 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[45] at count at utils.scala:135), which has no missing parents
21/03/14 14:37:14 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:37:14 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:37:14 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:57468 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:37:14 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 14:37:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[45] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:37:14 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/03/14 14:37:14 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 15, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:37:14 INFO Executor: Running task 0.0 in stage 12.0 (TID 15)
21/03/14 14:37:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:37:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:37:14 INFO Executor: Finished task 0.0 in stage 12.0 (TID 15). 1775 bytes result sent to driver
21/03/14 14:37:14 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 15) in 8 ms on localhost (executor driver) (1/1)
21/03/14 14:37:14 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/03/14 14:37:14 INFO DAGScheduler: ResultStage 12 (count at utils.scala:135) finished in 0.013 s
21/03/14 14:37:14 INFO DAGScheduler: Job 7 finished: count at utils.scala:135, took 0.032882 s
21/03/14 14:37:14 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:37:14 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:37:14 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:37:14 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:37:14 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:37:14 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:37:14 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:37:14 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:37:14 INFO HiveMetaStore: 0: drop_database: catalog_test_database_db
21/03/14 14:37:14 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=drop_database: catalog_test_database_db	
21/03/14 14:37:14 INFO HiveMetaStore: 0: get_all_tables: db=catalog_test_database_db
21/03/14 14:37:14 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_tables: db=catalog_test_database_db	
21/03/14 14:37:14 INFO HiveMetaStore: 0: get_functions: db=catalog_test_database_db pat=*
21/03/14 14:37:14 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=catalog_test_database_db pat=*	
21/03/14 14:37:14 INFO ObjectStore: Dropping database catalog_test_database_db along with all tables
21/03/14 14:37:14 INFO hivemetastoressimpl: deleting  file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:37:14 INFO deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
21/03/14 14:37:14 INFO TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
21/03/14 14:37:14 INFO hivemetastoressimpl: Deleted the diretory file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:37:14 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:37:14 INFO DAGScheduler: Registering RDD 49 (count at utils.scala:135)
21/03/14 14:37:14 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/03/14 14:37:14 INFO DAGScheduler: Final stage: ResultStage 14 (count at utils.scala:135)
21/03/14 14:37:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/03/14 14:37:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/03/14 14:37:14 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[49] at count at utils.scala:135), which has no missing parents
21/03/14 14:37:14 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:37:14 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:37:14 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:57468 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:37:14 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 14:37:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[49] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:37:14 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/03/14 14:37:14 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 14:37:14 INFO Executor: Running task 0.0 in stage 13.0 (TID 16)
21/03/14 14:37:14 INFO Executor: Finished task 0.0 in stage 13.0 (TID 16). 1499 bytes result sent to driver
21/03/14 14:37:14 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 16) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:37:14 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/03/14 14:37:14 INFO DAGScheduler: ShuffleMapStage 13 (count at utils.scala:135) finished in 0.015 s
21/03/14 14:37:14 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:37:14 INFO DAGScheduler: running: Set()
21/03/14 14:37:14 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/03/14 14:37:14 INFO DAGScheduler: failed: Set()
21/03/14 14:37:14 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[52] at count at utils.scala:135), which has no missing parents
21/03/14 14:37:14 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:37:14 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:37:14 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:57468 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:37:14 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
21/03/14 14:37:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[52] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:37:14 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/03/14 14:37:14 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 17, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:37:14 INFO Executor: Running task 0.0 in stage 14.0 (TID 17)
21/03/14 14:37:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:37:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:37:15 INFO Executor: Finished task 0.0 in stage 14.0 (TID 17). 1775 bytes result sent to driver
21/03/14 14:37:15 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 17) in 5 ms on localhost (executor driver) (1/1)
21/03/14 14:37:15 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/03/14 14:37:15 INFO DAGScheduler: ResultStage 14 (count at utils.scala:135) finished in 0.012 s
21/03/14 14:37:15 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.030785 s
21/03/14 14:37:15 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:37:15 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:37:15 WARN ObjectStore: Failed to get database catalog_test_database_db, returning NoSuchObjectException
21/03/14 14:38:14 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 14:38:14 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 14:38:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 14:38:14 INFO MemoryStore: MemoryStore cleared
21/03/14 14:38:14 INFO BlockManager: BlockManager stopped
21/03/14 14:38:14 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 14:38:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 14:38:14 INFO SparkContext: Successfully stopped SparkContext
21/03/14 14:38:14 INFO ShutdownHookManager: Shutdown hook called
21/03/14 14:38:14 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-afb5cc86-0e60-463e-8769-feba4525ce59
21/03/14 14:38:14 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-044d0c99-743e-4a7f-905f-2f65d4f8f923
21/03/14 14:38:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 14:38:29 INFO SparkContext: Running Spark version 2.4.3
21/03/14 14:38:29 INFO SparkContext: Submitted application: sparklyr
21/03/14 14:38:29 INFO SecurityManager: Changing view acls to: nathan
21/03/14 14:38:29 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 14:38:29 INFO SecurityManager: Changing view acls groups to: 
21/03/14 14:38:29 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 14:38:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 14:38:30 INFO Utils: Successfully started service 'sparkDriver' on port 57726.
21/03/14 14:38:30 INFO SparkEnv: Registering MapOutputTracker
21/03/14 14:38:30 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 14:38:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 14:38:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 14:38:30 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-1a9133c3-e19f-4b03-827b-b14fbcad1a8b
21/03/14 14:38:30 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 14:38:30 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 14:38:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 14:38:30 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 14:38:30 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:57726/jars/sparklyr-2.4-2.11.jar with timestamp 1615729110561
21/03/14 14:38:30 INFO Executor: Starting executor ID driver on host localhost
21/03/14 14:38:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57727.
21/03/14 14:38:30 INFO NettyBlockTransferService: Server created on localhost:57727
21/03/14 14:38:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 14:38:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 57727, None)
21/03/14 14:38:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57727 with 912.3 MB RAM, BlockManagerId(driver, localhost, 57727, None)
21/03/14 14:38:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 57727, None)
21/03/14 14:38:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 57727, None)
21/03/14 14:38:31 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 14:38:31 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 14:38:31 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 14:38:31 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 14:38:34 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 14:38:35 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 14:38:35 INFO ObjectStore: ObjectStore, initialize called
21/03/14 14:38:35 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 14:38:35 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 14:38:37 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 14:38:38 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:38:38 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:38:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:38:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:38:39 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 14:38:39 INFO ObjectStore: Initialized ObjectStore
21/03/14 14:38:40 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 14:38:40 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 14:38:40 INFO HiveMetaStore: Added admin role in metastore
21/03/14 14:38:40 INFO HiveMetaStore: Added public role in metastore
21/03/14 14:38:40 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 14:38:40 INFO HiveMetaStore: 0: get_all_databases
21/03/14 14:38:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 14:38:40 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:38:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:38:40 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:38:40 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/aa374ed7-e3e3-473f-b03f-4ac516f2d49a_resources
21/03/14 14:38:40 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/aa374ed7-e3e3-473f-b03f-4ac516f2d49a
21/03/14 14:38:40 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/aa374ed7-e3e3-473f-b03f-4ac516f2d49a
21/03/14 14:38:40 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/aa374ed7-e3e3-473f-b03f-4ac516f2d49a/_tmp_space.db
21/03/14 14:38:40 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 14:38:40 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:40 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 14:38:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 14:38:40 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 14:38:40 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:40 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:40 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 14:38:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 14:38:41 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 14:38:41 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/03/14 14:38:41 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/03/14 14:38:41 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:38:41 INFO DAGScheduler: Missing parents: List()
21/03/14 14:38:41 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/03/14 14:38:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/03/14 14:38:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/03/14 14:38:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57727 (size: 3.4 KB, free: 912.3 MB)
21/03/14 14:38:42 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 14:38:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/03/14 14:38:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 14:38:42 INFO Executor: Fetching spark://localhost:57726/jars/sparklyr-2.4-2.11.jar with timestamp 1615729110561
21/03/14 14:38:42 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:57726 after 30 ms (0 ms spent in bootstraps)
21/03/14 14:38:42 INFO Utils: Fetching spark://localhost:57726/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-bf0b0b41-2f09-4c98-9c8a-5eb01c61b00b/userFiles-227adf23-a0c5-4b31-a4c6-5ce7a40c40ce/fetchFileTemp3945948806223002515.tmp
21/03/14 14:38:42 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-bf0b0b41-2f09-4c98-9c8a-5eb01c61b00b/userFiles-227adf23-a0c5-4b31-a4c6-5ce7a40c40ce/sparklyr-2.4-2.11.jar to class loader
21/03/14 14:38:42 INFO CodeGenerator: Code generated in 399.522663 ms
21/03/14 14:38:43 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
21/03/14 14:38:43 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 895 ms on localhost (executor driver) (1/1)
21/03/14 14:38:43 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 14:38:43 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 1.364 s
21/03/14 14:38:43 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 1.447945 s
21/03/14 14:38:43 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:57727 in memory (size: 3.4 KB, free: 912.3 MB)
21/03/14 14:38:43 INFO ContextCleaner: Cleaned accumulator 0
21/03/14 14:38:44 INFO CodeGenerator: Code generated in 25.694355 ms
21/03/14 14:38:44 INFO CodeGenerator: Code generated in 27.011218 ms
21/03/14 14:38:44 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:38:44 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:38:44 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 14:38:44 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:38:44 INFO DAGScheduler: Missing parents: List()
21/03/14 14:38:44 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/03/14 14:38:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 14:38:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 14:38:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:57727 (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:38:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:44 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 14:38:44 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:38:44 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 14:38:44 INFO CodeGenerator: Code generated in 10.183171 ms
21/03/14 14:38:44 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 14:38:44 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on localhost (executor driver) (1/1)
21/03/14 14:38:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 14:38:44 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.047 s
21/03/14 14:38:44 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.053794 s
21/03/14 14:38:44 INFO CodeGenerator: Code generated in 19.361006 ms
21/03/14 14:38:44 INFO CodeGenerator: Code generated in 14.295041 ms
21/03/14 14:38:44 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:38:44 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/03/14 14:38:44 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 14:38:44 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 14:38:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 14:38:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 14:38:44 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/03/14 14:38:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/03/14 14:38:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/03/14 14:38:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:57727 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:38:44 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:44 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 14:38:44 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:38:44 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 14:38:44 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 14:38:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 67 ms on localhost (executor driver) (1/1)
21/03/14 14:38:44 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 14:38:44 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.088 s
21/03/14 14:38:44 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:38:44 INFO DAGScheduler: running: Set()
21/03/14 14:38:44 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 14:38:44 INFO DAGScheduler: failed: Set()
21/03/14 14:38:44 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/03/14 14:38:44 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:38:44 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:38:44 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:57727 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:38:44 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:44 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 14:38:44 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:38:44 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 14:38:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:38:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
21/03/14 14:38:44 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 14:38:44 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 62 ms on localhost (executor driver) (1/1)
21/03/14 14:38:44 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 14:38:44 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.074 s
21/03/14 14:38:44 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.197757 s
21/03/14 14:38:45 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:38:45 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:38:45 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/03/14 14:38:45 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:38:45 INFO DAGScheduler: Missing parents: List()
21/03/14 14:38:45 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135), which has no missing parents
21/03/14 14:38:45 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 14:38:45 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 14:38:45 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:57727 (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:38:45 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:45 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 14:38:45 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:38:45 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 14:38:45 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/03/14 14:38:45 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:38:45 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 14:38:45 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.017 s
21/03/14 14:38:45 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.019420 s
21/03/14 14:38:45 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:38:45 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:135)
21/03/14 14:38:45 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/14 14:38:45 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/03/14 14:38:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/03/14 14:38:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/03/14 14:38:45 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/03/14 14:38:45 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/03/14 14:38:45 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/03/14 14:38:45 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:57727 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:38:45 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:45 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 14:38:45 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:38:45 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 14:38:45 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/03/14 14:38:45 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 11 ms on localhost (executor driver) (1/1)
21/03/14 14:38:45 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 14:38:45 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.022 s
21/03/14 14:38:45 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:38:45 INFO DAGScheduler: running: Set()
21/03/14 14:38:45 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/03/14 14:38:45 INFO DAGScheduler: failed: Set()
21/03/14 14:38:45 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/03/14 14:38:45 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:38:45 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:38:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:57727 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:38:45 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:45 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 14:38:45 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:38:45 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 14:38:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:38:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:38:45 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/03/14 14:38:45 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:38:45 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 14:38:45 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.016 s
21/03/14 14:38:45 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.044165 s
21/03/14 14:38:45 INFO CodeGenerator: Code generated in 35.283813 ms
21/03/14 14:38:45 INFO CodeGenerator: Code generated in 14.814569 ms
21/03/14 14:38:45 INFO CodeGenerator: Code generated in 12.309761 ms
21/03/14 14:38:45 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:38:45 INFO DAGScheduler: Registering RDD 28 (count at utils.scala:135)
21/03/14 14:38:45 INFO DAGScheduler: Got job 5 (count at utils.scala:135) with 1 output partitions
21/03/14 14:38:45 INFO DAGScheduler: Final stage: ResultStage 8 (count at utils.scala:135)
21/03/14 14:38:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
21/03/14 14:38:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
21/03/14 14:38:45 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135), which has no missing parents
21/03/14 14:38:45 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:38:45 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:38:45 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:57727 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:38:45 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:45 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/03/14 14:38:45 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
21/03/14 14:38:45 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8034 bytes)
21/03/14 14:38:45 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 8, localhost, executor driver, partition 1, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:38:45 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 9, localhost, executor driver, partition 2, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:38:45 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 10, localhost, executor driver, partition 3, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:38:45 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 14:38:45 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1499 bytes result sent to driver
21/03/14 14:38:45 INFO Executor: Running task 1.0 in stage 7.0 (TID 8)
21/03/14 14:38:45 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 14 ms on localhost (executor driver) (1/4)
21/03/14 14:38:45 INFO Executor: Running task 2.0 in stage 7.0 (TID 9)
21/03/14 14:38:45 INFO Executor: Running task 3.0 in stage 7.0 (TID 10)
21/03/14 14:38:45 INFO Executor: Finished task 1.0 in stage 7.0 (TID 8). 1499 bytes result sent to driver
21/03/14 14:38:45 INFO Executor: Finished task 3.0 in stage 7.0 (TID 10). 1499 bytes result sent to driver
21/03/14 14:38:45 INFO Executor: Finished task 2.0 in stage 7.0 (TID 9). 1499 bytes result sent to driver
21/03/14 14:38:45 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 8) in 26 ms on localhost (executor driver) (2/4)
21/03/14 14:38:45 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 10) in 27 ms on localhost (executor driver) (3/4)
21/03/14 14:38:45 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 9) in 28 ms on localhost (executor driver) (4/4)
21/03/14 14:38:45 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 14:38:45 INFO DAGScheduler: ShuffleMapStage 7 (count at utils.scala:135) finished in 0.044 s
21/03/14 14:38:45 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:38:45 INFO DAGScheduler: running: Set()
21/03/14 14:38:45 INFO DAGScheduler: waiting: Set(ResultStage 8)
21/03/14 14:38:45 INFO DAGScheduler: failed: Set()
21/03/14 14:38:45 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135), which has no missing parents
21/03/14 14:38:45 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:38:45 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:38:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:57727 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:38:45 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:45 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 14:38:45 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:38:45 INFO Executor: Running task 0.0 in stage 8.0 (TID 11)
21/03/14 14:38:45 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
21/03/14 14:38:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:38:45 INFO Executor: Finished task 0.0 in stage 8.0 (TID 11). 1825 bytes result sent to driver
21/03/14 14:38:45 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 11) in 10 ms on localhost (executor driver) (1/1)
21/03/14 14:38:45 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 14:38:45 INFO DAGScheduler: ResultStage 8 (count at utils.scala:135) finished in 0.019 s
21/03/14 14:38:45 INFO DAGScheduler: Job 5 finished: count at utils.scala:135, took 0.069931 s
21/03/14 14:38:46 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:46 INFO HiveMetaStore: 0: get_database: fake_database
21/03/14 14:38:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: fake_database	
21/03/14 14:38:46 WARN ObjectStore: Failed to get database fake_database, returning NoSuchObjectException
21/03/14 14:38:46 INFO HiveMetaStore: 0: get_databases: *
21/03/14 14:38:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_databases: *	
21/03/14 14:38:46 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:46 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:46 INFO CodeGenerator: Code generated in 25.491015 ms
21/03/14 14:38:46 INFO CodeGenerator: Code generated in 13.874493 ms
21/03/14 14:38:46 INFO CodeGenerator: Code generated in 10.803655 ms
21/03/14 14:38:46 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:38:46 INFO DAGScheduler: Registering RDD 35 (count at utils.scala:135)
21/03/14 14:38:46 INFO DAGScheduler: Got job 6 (count at utils.scala:135) with 1 output partitions
21/03/14 14:38:46 INFO DAGScheduler: Final stage: ResultStage 10 (count at utils.scala:135)
21/03/14 14:38:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
21/03/14 14:38:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
21/03/14 14:38:46 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[35] at count at utils.scala:135), which has no missing parents
21/03/14 14:38:46 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:38:46 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:38:46 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:57727 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:38:46 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[35] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:46 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 14:38:46 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 14:38:46 INFO Executor: Running task 0.0 in stage 9.0 (TID 12)
21/03/14 14:38:46 INFO Executor: Finished task 0.0 in stage 9.0 (TID 12). 1499 bytes result sent to driver
21/03/14 14:38:46 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 12) in 8 ms on localhost (executor driver) (1/1)
21/03/14 14:38:46 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 14:38:46 INFO DAGScheduler: ShuffleMapStage 9 (count at utils.scala:135) finished in 0.017 s
21/03/14 14:38:46 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:38:46 INFO DAGScheduler: running: Set()
21/03/14 14:38:46 INFO DAGScheduler: waiting: Set(ResultStage 10)
21/03/14 14:38:46 INFO DAGScheduler: failed: Set()
21/03/14 14:38:46 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[38] at count at utils.scala:135), which has no missing parents
21/03/14 14:38:46 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:38:46 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:38:46 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:57727 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:38:46 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:46 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/03/14 14:38:46 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:38:46 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
21/03/14 14:38:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:38:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:38:46 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 1782 bytes result sent to driver
21/03/14 14:38:46 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:38:46 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/03/14 14:38:46 INFO DAGScheduler: ResultStage 10 (count at utils.scala:135) finished in 0.014 s
21/03/14 14:38:46 INFO DAGScheduler: Job 6 finished: count at utils.scala:135, took 0.036169 s
21/03/14 14:38:46 INFO HiveMetaStore: 0: create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})
21/03/14 14:38:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})	
21/03/14 14:38:46 WARN ObjectStore: Failed to get database catalog_test_database_db, returning NoSuchObjectException
21/03/14 14:38:46 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:38:46 INFO CodeGenerator: Code generated in 13.047062 ms
21/03/14 14:38:46 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:38:46 INFO DAGScheduler: Registering RDD 42 (count at utils.scala:135)
21/03/14 14:38:46 INFO DAGScheduler: Got job 7 (count at utils.scala:135) with 1 output partitions
21/03/14 14:38:46 INFO DAGScheduler: Final stage: ResultStage 12 (count at utils.scala:135)
21/03/14 14:38:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
21/03/14 14:38:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
21/03/14 14:38:46 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[42] at count at utils.scala:135), which has no missing parents
21/03/14 14:38:46 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:38:46 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:38:46 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:57727 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:38:46 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[42] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:46 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/03/14 14:38:46 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 14:38:46 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
21/03/14 14:38:46 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 1499 bytes result sent to driver
21/03/14 14:38:46 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 10 ms on localhost (executor driver) (1/1)
21/03/14 14:38:46 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/03/14 14:38:46 INFO DAGScheduler: ShuffleMapStage 11 (count at utils.scala:135) finished in 0.021 s
21/03/14 14:38:46 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:38:46 INFO DAGScheduler: running: Set()
21/03/14 14:38:46 INFO DAGScheduler: waiting: Set(ResultStage 12)
21/03/14 14:38:46 INFO DAGScheduler: failed: Set()
21/03/14 14:38:46 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[45] at count at utils.scala:135), which has no missing parents
21/03/14 14:38:46 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:38:46 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:38:46 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:57727 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:38:46 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[45] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:46 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/03/14 14:38:46 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 15, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:38:46 INFO Executor: Running task 0.0 in stage 12.0 (TID 15)
21/03/14 14:38:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:38:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:38:46 INFO Executor: Finished task 0.0 in stage 12.0 (TID 15). 1818 bytes result sent to driver
21/03/14 14:38:46 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 15) in 9 ms on localhost (executor driver) (1/1)
21/03/14 14:38:46 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/03/14 14:38:46 INFO DAGScheduler: ResultStage 12 (count at utils.scala:135) finished in 0.019 s
21/03/14 14:38:46 INFO DAGScheduler: Job 7 finished: count at utils.scala:135, took 0.045476 s
21/03/14 14:38:46 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:38:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:38:46 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:38:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:38:46 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:38:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:38:46 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:46 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:46 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:46 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:38:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:38:46 INFO HiveMetaStore: 0: drop_database: catalog_test_database_db
21/03/14 14:38:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=drop_database: catalog_test_database_db	
21/03/14 14:38:46 INFO HiveMetaStore: 0: get_all_tables: db=catalog_test_database_db
21/03/14 14:38:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_tables: db=catalog_test_database_db	
21/03/14 14:38:46 INFO HiveMetaStore: 0: get_functions: db=catalog_test_database_db pat=*
21/03/14 14:38:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=catalog_test_database_db pat=*	
21/03/14 14:38:46 INFO ObjectStore: Dropping database catalog_test_database_db along with all tables
21/03/14 14:38:47 INFO hivemetastoressimpl: deleting  file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:38:47 INFO deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
21/03/14 14:38:47 INFO TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
21/03/14 14:38:47 INFO hivemetastoressimpl: Deleted the diretory file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:38:47 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:38:47 INFO DAGScheduler: Registering RDD 49 (count at utils.scala:135)
21/03/14 14:38:47 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/03/14 14:38:47 INFO DAGScheduler: Final stage: ResultStage 14 (count at utils.scala:135)
21/03/14 14:38:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/03/14 14:38:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/03/14 14:38:47 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[49] at count at utils.scala:135), which has no missing parents
21/03/14 14:38:47 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:38:47 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 148
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 224
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 282
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 160
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 193
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 313
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 219
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 241
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 256
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 318
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 142
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 242
21/03/14 14:38:47 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:57727 (size: 4.2 KB, free: 912.2 MB)
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 298
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 197
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 284
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 380
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 305
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 239
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 208
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 248
21/03/14 14:38:47 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 100
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 270
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 249
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 71
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 255
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 278
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 378
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 114
21/03/14 14:38:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[49] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 101
21/03/14 14:38:47 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 191
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 138
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 119
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 288
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 376
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 70
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 335
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 96
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 28
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 246
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 357
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 314
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 113
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 162
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 165
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 345
21/03/14 14:38:47 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 14:38:47 INFO Executor: Running task 0.0 in stage 13.0 (TID 16)
21/03/14 14:38:47 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:57727 in memory (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:38:47 INFO Executor: Finished task 0.0 in stage 13.0 (TID 16). 1499 bytes result sent to driver
21/03/14 14:38:47 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 16) in 8 ms on localhost (executor driver) (1/1)
21/03/14 14:38:47 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/03/14 14:38:47 INFO ContextCleaner: Cleaned shuffle 0
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 132
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 377
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 83
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 173
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 14:38:47 INFO DAGScheduler: ShuffleMapStage 13 (count at utils.scala:135) finished in 0.028 s
21/03/14 14:38:47 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:38:47 INFO DAGScheduler: running: Set()
21/03/14 14:38:47 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/03/14 14:38:47 INFO DAGScheduler: failed: Set()
21/03/14 14:38:47 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[52] at count at utils.scala:135), which has no missing parents
21/03/14 14:38:47 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:57727 in memory (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:38:47 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 212
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 97
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 143
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 306
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 368
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 155
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 361
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 111
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 283
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 236
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 390
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 395
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 245
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 387
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 285
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 329
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 391
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 179
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 338
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 291
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 121
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 365
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 226
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 260
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 253
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 389
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 177
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 166
21/03/14 14:38:47 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 327
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 401
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 167
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 153
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 103
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 134
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 116
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 146
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 404
21/03/14 14:38:47 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:57727 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 194
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 341
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 403
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 369
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 77
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 344
21/03/14 14:38:47 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[52] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:47 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/03/14 14:38:47 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:57727 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:38:47 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 17, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:38:47 INFO Executor: Running task 0.0 in stage 14.0 (TID 17)
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 87
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 175
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 254
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 154
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 107
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 370
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 300
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 362
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 183
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 225
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 293
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 182
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 74
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 195
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 14:38:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:38:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:38:47 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:57727 in memory (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 360
21/03/14 14:38:47 INFO Executor: Finished task 0.0 in stage 14.0 (TID 17). 1775 bytes result sent to driver
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 279
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 34
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 64
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 214
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 227
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 286
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 315
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 122
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 171
21/03/14 14:38:47 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 17) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 27
21/03/14 14:38:47 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 265
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 267
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 348
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 405
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 334
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 356
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 263
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 407
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 76
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 217
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 333
21/03/14 14:38:47 INFO DAGScheduler: ResultStage 14 (count at utils.scala:135) finished in 0.013 s
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 363
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 400
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 198
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 309
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 323
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 367
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 129
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 140
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 36
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 220
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 35
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 302
21/03/14 14:38:47 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.046771 s
21/03/14 14:38:47 INFO ContextCleaner: Cleaned shuffle 4
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 213
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 203
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 243
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 317
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 251
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 402
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 32
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 86
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 292
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 30
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 346
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 372
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 252
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 322
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 186
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 81
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 271
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 223
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 231
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 233
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 247
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 164
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 321
21/03/14 14:38:47 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:57727 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 37
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 157
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 373
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 325
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 330
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 168
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 353
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 68
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 269
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 79
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 331
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 149
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 266
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 206
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 181
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 332
21/03/14 14:38:47 INFO ContextCleaner: Cleaned shuffle 2
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 110
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 244
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 199
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 232
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 268
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 117
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 273
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 141
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 392
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 374
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 312
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 65
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 393
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 88
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 133
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 89
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 108
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 347
21/03/14 14:38:47 INFO ContextCleaner: Cleaned shuffle 1
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 159
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 109
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 406
21/03/14 14:38:47 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:57727 in memory (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 185
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 299
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 94
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 187
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 131
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 189
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 261
21/03/14 14:38:47 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:57727 in memory (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 124
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 176
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 128
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 352
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 127
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 375
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 72
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 287
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 144
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 178
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 320
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 228
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 234
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 359
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 275
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 196
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 301
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 26
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 257
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 280
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 205
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 204
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 324
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 289
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 78
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 161
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 230
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 112
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 296
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 180
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 381
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 106
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 295
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 386
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 151
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 350
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 209
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 91
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 93
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 125
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 281
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 136
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 319
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 210
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 358
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 339
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 69
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 349
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 66
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 240
21/03/14 14:38:47 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:57727 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 264
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 152
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 410
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 336
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 207
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 31
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 202
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 307
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 126
21/03/14 14:38:47 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:57727 in memory (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 394
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 385
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 145
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 172
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 200
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 277
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 316
21/03/14 14:38:47 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:57727 in memory (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 388
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 258
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 340
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 192
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 98
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 190
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 326
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 184
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 274
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 294
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 366
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 364
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 80
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 82
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 188
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 238
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 371
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 328
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 84
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 304
21/03/14 14:38:47 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:57727 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 303
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 73
21/03/14 14:38:47 INFO ContextCleaner: Cleaned shuffle 3
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 408
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 137
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 104
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 259
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 384
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 102
21/03/14 14:38:47 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:57727 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 174
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 337
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 147
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 105
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 398
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 75
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 135
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 201
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 382
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 221
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 169
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 95
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 351
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 354
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 297
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 379
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 156
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 235
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 211
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 250
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 120
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 396
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 290
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 310
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 90
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 29
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 170
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 218
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 272
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 130
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 215
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 216
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 150
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 67
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 139
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 399
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 163
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 123
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 262
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 99
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 308
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 92
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 276
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 355
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 85
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 33
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 383
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 311
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 229
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 222
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 397
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 115
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 342
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 343
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 237
21/03/14 14:38:47 INFO ContextCleaner: Cleaned accumulator 158
21/03/14 14:38:47 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:47 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:47 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:47 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:47 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:47 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:47 INFO HiveMetaStore: 0: get_function: default.catalog_fake_function
21/03/14 14:38:47 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_function: default.catalog_fake_function	
21/03/14 14:38:47 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:47 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:47 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:47 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:47 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:47 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:47 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:38:47 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:38:47 INFO CodeGenerator: Code generated in 30.053154 ms
21/03/14 14:38:47 INFO CodeGenerator: Code generated in 10.191569 ms
21/03/14 14:38:47 INFO CodeGenerator: Code generated in 11.054106 ms
21/03/14 14:38:47 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:38:47 INFO DAGScheduler: Registering RDD 56 (count at utils.scala:135)
21/03/14 14:38:47 INFO DAGScheduler: Got job 9 (count at utils.scala:135) with 1 output partitions
21/03/14 14:38:47 INFO DAGScheduler: Final stage: ResultStage 16 (count at utils.scala:135)
21/03/14 14:38:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
21/03/14 14:38:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
21/03/14 14:38:47 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[56] at count at utils.scala:135), which has no missing parents
21/03/14 14:38:47 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 14:38:47 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 14:38:47 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:57727 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:38:47 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:47 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[56] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/03/14 14:38:47 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks
21/03/14 14:38:47 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 9258 bytes)
21/03/14 14:38:47 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 19, localhost, executor driver, partition 1, PROCESS_LOCAL, 9275 bytes)
21/03/14 14:38:47 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 20, localhost, executor driver, partition 2, PROCESS_LOCAL, 9258 bytes)
21/03/14 14:38:47 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 21, localhost, executor driver, partition 3, PROCESS_LOCAL, 9275 bytes)
21/03/14 14:38:47 INFO Executor: Running task 0.0 in stage 15.0 (TID 18)
21/03/14 14:38:47 INFO Executor: Running task 2.0 in stage 15.0 (TID 20)
21/03/14 14:38:47 INFO Executor: Running task 3.0 in stage 15.0 (TID 21)
21/03/14 14:38:47 INFO Executor: Running task 1.0 in stage 15.0 (TID 19)
21/03/14 14:38:47 INFO Executor: Finished task 0.0 in stage 15.0 (TID 18). 1499 bytes result sent to driver
21/03/14 14:38:47 INFO Executor: Finished task 2.0 in stage 15.0 (TID 20). 1499 bytes result sent to driver
21/03/14 14:38:47 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 18) in 12 ms on localhost (executor driver) (1/4)
21/03/14 14:38:47 INFO Executor: Finished task 1.0 in stage 15.0 (TID 19). 1499 bytes result sent to driver
21/03/14 14:38:47 INFO Executor: Finished task 3.0 in stage 15.0 (TID 21). 1499 bytes result sent to driver
21/03/14 14:38:47 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 20) in 13 ms on localhost (executor driver) (2/4)
21/03/14 14:38:47 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 19) in 14 ms on localhost (executor driver) (3/4)
21/03/14 14:38:47 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 21) in 13 ms on localhost (executor driver) (4/4)
21/03/14 14:38:47 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/03/14 14:38:47 INFO DAGScheduler: ShuffleMapStage 15 (count at utils.scala:135) finished in 0.024 s
21/03/14 14:38:47 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:38:47 INFO DAGScheduler: running: Set()
21/03/14 14:38:47 INFO DAGScheduler: waiting: Set(ResultStage 16)
21/03/14 14:38:47 INFO DAGScheduler: failed: Set()
21/03/14 14:38:47 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[59] at count at utils.scala:135), which has no missing parents
21/03/14 14:38:47 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:38:47 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:38:47 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:57727 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:38:47 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[59] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:47 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/03/14 14:38:47 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 22, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:38:47 INFO Executor: Running task 0.0 in stage 16.0 (TID 22)
21/03/14 14:38:47 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
21/03/14 14:38:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:38:47 INFO Executor: Finished task 0.0 in stage 16.0 (TID 22). 1782 bytes result sent to driver
21/03/14 14:38:47 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 22) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:38:47 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/03/14 14:38:47 INFO DAGScheduler: ResultStage 16 (count at utils.scala:135) finished in 0.014 s
21/03/14 14:38:47 INFO DAGScheduler: Job 9 finished: count at utils.scala:135, took 0.042867 s
21/03/14 14:38:48 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:38:48 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:38:48 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:38:48 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#304, None)) > 0)
21/03/14 14:38:48 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 14:38:48 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:38:48 INFO CodeGenerator: Code generated in 8.523113 ms
21/03/14 14:38:48 INFO CodeGenerator: Code generated in 14.583203 ms
21/03/14 14:38:48 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 284.3 KB, free 912.0 MB)
21/03/14 14:38:48 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 23.9 KB, free 912.0 MB)
21/03/14 14:38:48 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:57727 (size: 23.9 KB, free: 912.3 MB)
21/03/14 14:38:48 INFO SparkContext: Created broadcast 17 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 14:38:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:38:48 INFO SparkContext: Starting job: createTable at NativeMethodAccessorImpl.java:0
21/03/14 14:38:48 INFO DAGScheduler: Got job 10 (createTable at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:38:48 INFO DAGScheduler: Final stage: ResultStage 17 (createTable at NativeMethodAccessorImpl.java:0)
21/03/14 14:38:48 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:38:48 INFO DAGScheduler: Missing parents: List()
21/03/14 14:38:48 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[63] at createTable at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:38:48 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 8.8 KB, free 911.9 MB)
21/03/14 14:38:48 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.9 MB)
21/03/14 14:38:48 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:57727 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:38:48 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[63] at createTable at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:48 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/03/14 14:38:48 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 8362 bytes)
21/03/14 14:38:48 INFO Executor: Running task 0.0 in stage 17.0 (TID 23)
21/03/14 14:38:48 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpNtK1Rx/file14f014a7a2657, range: 0-1303, partition values: [empty row]
21/03/14 14:38:49 INFO CodeGenerator: Code generated in 8.841693 ms
21/03/14 14:38:49 INFO Executor: Finished task 0.0 in stage 17.0 (TID 23). 1372 bytes result sent to driver
21/03/14 14:38:49 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 23) in 78 ms on localhost (executor driver) (1/1)
21/03/14 14:38:49 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/03/14 14:38:49 INFO DAGScheduler: ResultStage 17 (createTable at NativeMethodAccessorImpl.java:0) finished in 0.090 s
21/03/14 14:38:49 INFO DAGScheduler: Job 10 finished: createTable at NativeMethodAccessorImpl.java:0, took 0.096489 s
21/03/14 14:38:49 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:38:49 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 14:38:49 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 14:38:49 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:38:49 INFO CodeGenerator: Code generated in 11.916215 ms
21/03/14 14:38:49 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 284.3 KB, free 911.7 MB)
21/03/14 14:38:49 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.6 MB)
21/03/14 14:38:49 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:57727 (size: 23.9 KB, free: 912.2 MB)
21/03/14 14:38:49 INFO SparkContext: Created broadcast 19 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 14:38:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:38:49 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:49 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:49 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:38:49 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:38:49 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:49 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:49 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:38:49 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:38:49 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `default`.`mtcars` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.
21/03/14 14:38:49 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:38:49 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:38:49 INFO HiveMetaStore: 0: create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615729128, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpNtK1Rx/file14f014a7a2657, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
21/03/14 14:38:49 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615729128, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpNtK1Rx/file14f014a7a2657, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
21/03/14 14:38:49 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__
21/03/14 14:38:50 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:38:50 INFO DAGScheduler: Got job 11 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:38:50 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:135)
21/03/14 14:38:50 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:38:50 INFO DAGScheduler: Missing parents: List()
21/03/14 14:38:50 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[72] at collect at utils.scala:135), which has no missing parents
21/03/14 14:38:50 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 6.5 KB, free 911.6 MB)
21/03/14 14:38:50 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.6 MB)
21/03/14 14:38:50 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:57727 (size: 3.3 KB, free: 912.2 MB)
21/03/14 14:38:50 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[72] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:50 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/03/14 14:38:50 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:38:50 INFO Executor: Running task 0.0 in stage 18.0 (TID 24)
21/03/14 14:38:50 INFO Executor: Finished task 0.0 in stage 18.0 (TID 24). 1286 bytes result sent to driver
21/03/14 14:38:50 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 24) in 6 ms on localhost (executor driver) (1/1)
21/03/14 14:38:50 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/03/14 14:38:50 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:135) finished in 0.012 s
21/03/14 14:38:50 INFO DAGScheduler: Job 11 finished: collect at utils.scala:135, took 0.015735 s
21/03/14 14:38:50 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:38:50 INFO DAGScheduler: Registering RDD 75 (count at utils.scala:135)
21/03/14 14:38:50 INFO DAGScheduler: Got job 12 (count at utils.scala:135) with 1 output partitions
21/03/14 14:38:50 INFO DAGScheduler: Final stage: ResultStage 20 (count at utils.scala:135)
21/03/14 14:38:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
21/03/14 14:38:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
21/03/14 14:38:50 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[75] at count at utils.scala:135), which has no missing parents
21/03/14 14:38:50 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 8.4 KB, free 911.6 MB)
21/03/14 14:38:50 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.6 MB)
21/03/14 14:38:50 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:57727 (size: 4.5 KB, free: 912.2 MB)
21/03/14 14:38:50 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[75] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:50 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/03/14 14:38:50 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:38:50 INFO Executor: Running task 0.0 in stage 19.0 (TID 25)
21/03/14 14:38:50 INFO Executor: Finished task 0.0 in stage 19.0 (TID 25). 1499 bytes result sent to driver
21/03/14 14:38:50 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 25) in 16 ms on localhost (executor driver) (1/1)
21/03/14 14:38:50 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/03/14 14:38:50 INFO DAGScheduler: ShuffleMapStage 19 (count at utils.scala:135) finished in 0.024 s
21/03/14 14:38:50 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:38:50 INFO DAGScheduler: running: Set()
21/03/14 14:38:50 INFO DAGScheduler: waiting: Set(ResultStage 20)
21/03/14 14:38:50 INFO DAGScheduler: failed: Set()
21/03/14 14:38:50 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[78] at count at utils.scala:135), which has no missing parents
21/03/14 14:38:50 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 14:38:50 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 14:38:50 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:57727 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:38:50 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[78] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:50 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/03/14 14:38:50 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 26, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:38:50 INFO Executor: Running task 0.0 in stage 20.0 (TID 26)
21/03/14 14:38:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:38:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:38:50 INFO Executor: Finished task 0.0 in stage 20.0 (TID 26). 1782 bytes result sent to driver
21/03/14 14:38:50 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 26) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:38:50 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/03/14 14:38:50 INFO DAGScheduler: ResultStage 20 (count at utils.scala:135) finished in 0.013 s
21/03/14 14:38:50 INFO DAGScheduler: Job 12 finished: count at utils.scala:135, took 0.041773 s
21/03/14 14:38:50 INFO CodeGenerator: Code generated in 17.296018 ms
21/03/14 14:38:50 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 14:38:50 INFO DAGScheduler: Registering RDD 84 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:38:50 INFO DAGScheduler: Got job 13 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:38:50 INFO DAGScheduler: Final stage: ResultStage 22 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:38:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
21/03/14 14:38:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
21/03/14 14:38:50 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[84] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:38:50 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 24.1 KB, free 911.6 MB)
21/03/14 14:38:50 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 10.6 KB, free 911.6 MB)
21/03/14 14:38:50 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:57727 (size: 10.6 KB, free: 912.2 MB)
21/03/14 14:38:50 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[84] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:50 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/03/14 14:38:50 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 11616 bytes)
21/03/14 14:38:50 INFO Executor: Running task 0.0 in stage 21.0 (TID 27)
21/03/14 14:38:50 INFO CodeGenerator: Code generated in 13.927987 ms
21/03/14 14:38:50 INFO MemoryStore: Block rdd_80_0 stored as values in memory (estimated size 4.2 KB, free 911.6 MB)
21/03/14 14:38:50 INFO BlockManagerInfo: Added rdd_80_0 in memory on localhost:57727 (size: 4.2 KB, free: 912.2 MB)
21/03/14 14:38:50 INFO CodeGenerator: Code generated in 4.37805 ms
21/03/14 14:38:50 INFO Executor: Finished task 0.0 in stage 21.0 (TID 27). 1975 bytes result sent to driver
21/03/14 14:38:50 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 27) in 139 ms on localhost (executor driver) (1/1)
21/03/14 14:38:50 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/03/14 14:38:50 INFO DAGScheduler: ShuffleMapStage 21 (count at NativeMethodAccessorImpl.java:0) finished in 0.151 s
21/03/14 14:38:50 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:38:50 INFO DAGScheduler: running: Set()
21/03/14 14:38:50 INFO DAGScheduler: waiting: Set(ResultStage 22)
21/03/14 14:38:50 INFO DAGScheduler: failed: Set()
21/03/14 14:38:50 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[87] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:38:50 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 14:38:50 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 14:38:50 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:57727 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:38:50 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[87] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:50 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/03/14 14:38:50 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 28, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:38:50 INFO Executor: Running task 0.0 in stage 22.0 (TID 28)
21/03/14 14:38:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:38:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:38:50 INFO Executor: Finished task 0.0 in stage 22.0 (TID 28). 1825 bytes result sent to driver
21/03/14 14:38:50 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 28) in 8 ms on localhost (executor driver) (1/1)
21/03/14 14:38:50 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/03/14 14:38:50 INFO DAGScheduler: ResultStage 22 (count at NativeMethodAccessorImpl.java:0) finished in 0.016 s
21/03/14 14:38:50 INFO DAGScheduler: Job 13 finished: count at NativeMethodAccessorImpl.java:0, took 0.174642 s
21/03/14 14:38:50 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:57727 in memory (size: 23.9 KB, free: 912.2 MB)
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 720
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 689
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 502
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 709
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 683
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 426
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 579
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 606
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 553
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 514
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 555
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 580
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 531
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 433
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 609
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 622
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 459
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 649
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 589
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 586
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 524
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 440
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 675
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 623
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 636
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 660
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 614
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 718
21/03/14 14:38:50 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:57727 in memory (size: 4.2 KB, free: 912.2 MB)
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 658
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 476
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 498
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 691
21/03/14 14:38:50 INFO BlockManagerInfo: Removed broadcast_22_piece0 on localhost:57727 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 595
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 638
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 425
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 512
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 672
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 453
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 594
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 722
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 697
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 684
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 509
21/03/14 14:38:50 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:57727 in memory (size: 4.2 KB, free: 912.2 MB)
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 701
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 617
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 688
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 533
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 469
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 444
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 612
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 546
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 464
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 644
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 666
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 703
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 446
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 465
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 489
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 668
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 551
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 523
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 598
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 625
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 563
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 471
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 503
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 632
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 418
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 626
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 548
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 411
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 423
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 457
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 635
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 450
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 472
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 678
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 696
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 631
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 733
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 467
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 600
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 562
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 645
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 620
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 726
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 522
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 610
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 724
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 648
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 517
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 518
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 681
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 409
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 602
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 713
21/03/14 14:38:50 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:57727 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 428
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 496
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 565
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 416
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 667
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 592
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 499
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 637
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 692
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 448
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 438
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 478
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 569
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 560
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 451
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 721
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 491
21/03/14 14:38:50 INFO BlockManagerInfo: Removed broadcast_23_piece0 on localhost:57727 in memory (size: 10.6 KB, free: 912.3 MB)
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 462
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 575
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 554
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 513
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 536
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 539
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 458
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 587
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 479
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 704
21/03/14 14:38:50 INFO ContextCleaner: Cleaned shuffle 8
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 673
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 557
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 596
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 443
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 621
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 435
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 712
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 657
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 695
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 429
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 488
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 487
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 629
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 578
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 490
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 630
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 601
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 581
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 654
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 730
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 661
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 655
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 634
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 542
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 628
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 656
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 543
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 485
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 728
21/03/14 14:38:50 INFO ContextCleaner: Cleaned shuffle 7
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 420
21/03/14 14:38:50 INFO ContextCleaner: Cleaned shuffle 5
21/03/14 14:38:50 INFO BlockManagerInfo: Removed broadcast_20_piece0 on localhost:57727 in memory (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 652
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 702
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 685
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 670
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 708
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 525
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 603
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 734
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 526
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 613
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 653
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 568
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 643
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 506
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 593
21/03/14 14:38:50 INFO BlockManagerInfo: Removed broadcast_21_piece0 on localhost:57727 in memory (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 504
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 619
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 441
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 567
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 588
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 541
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 715
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 725
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 699
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 599
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 482
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 520
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 646
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 680
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 558
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 481
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 605
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 664
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 414
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 470
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 687
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 497
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 711
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 647
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 412
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 456
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 449
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 454
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 483
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 455
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 694
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 732
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 468
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 439
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 717
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 480
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 590
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 607
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 641
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 727
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 574
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 515
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 618
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 417
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 437
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 538
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 719
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 710
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 535
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 415
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 460
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 690
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 604
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 676
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 463
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 442
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 519
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 419
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 627
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 583
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 424
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 521
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 486
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 559
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 445
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 537
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 534
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 716
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 698
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 573
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 662
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 550
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 640
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 571
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 706
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 714
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 723
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 615
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 663
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 430
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 665
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 511
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 527
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 500
21/03/14 14:38:50 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:57727 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 434
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 484
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 650
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 679
21/03/14 14:38:50 INFO BlockManagerInfo: Removed broadcast_18_piece0 on localhost:57727 in memory (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 501
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 566
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 651
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 552
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 633
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 642
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 677
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 576
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 507
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 540
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 671
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 422
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 474
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 436
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 466
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 510
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 564
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 529
21/03/14 14:38:50 INFO BlockManagerInfo: Removed broadcast_19_piece0 on localhost:57727 in memory (size: 23.9 KB, free: 912.3 MB)
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 452
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 477
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 427
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 421
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 674
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 532
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 556
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 582
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 475
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 530
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 611
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 461
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 561
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 608
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 493
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 516
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 547
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 572
21/03/14 14:38:50 INFO ContextCleaner: Cleaned shuffle 6
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 693
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 494
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 508
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 528
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 735
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 577
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 597
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 432
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 492
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 505
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 616
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 585
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 639
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 584
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 705
21/03/14 14:38:50 INFO BlockManagerInfo: Removed broadcast_24_piece0 on localhost:57727 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 729
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 544
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 473
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 624
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 731
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 659
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 736
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 545
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 591
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 682
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 413
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 570
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 495
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 431
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 700
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 549
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 707
21/03/14 14:38:50 INFO ContextCleaner: Cleaned accumulator 447
21/03/14 14:38:50 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 14:38:50 INFO DAGScheduler: Registering RDD 91 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:38:50 INFO DAGScheduler: Got job 14 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:38:50 INFO DAGScheduler: Final stage: ResultStage 24 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:38:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
21/03/14 14:38:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
21/03/14 14:38:50 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[91] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:38:50 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 24.1 KB, free 912.3 MB)
21/03/14 14:38:50 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 10.6 KB, free 912.3 MB)
21/03/14 14:38:50 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:57727 (size: 10.6 KB, free: 912.3 MB)
21/03/14 14:38:50 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[91] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:50 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/03/14 14:38:50 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 11616 bytes)
21/03/14 14:38:50 INFO Executor: Running task 0.0 in stage 23.0 (TID 29)
21/03/14 14:38:50 INFO BlockManager: Found block rdd_80_0 locally
21/03/14 14:38:50 INFO Executor: Finished task 0.0 in stage 23.0 (TID 29). 2061 bytes result sent to driver
21/03/14 14:38:50 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 29) in 12 ms on localhost (executor driver) (1/1)
21/03/14 14:38:50 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/03/14 14:38:50 INFO DAGScheduler: ShuffleMapStage 23 (count at NativeMethodAccessorImpl.java:0) finished in 0.023 s
21/03/14 14:38:50 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:38:50 INFO DAGScheduler: running: Set()
21/03/14 14:38:50 INFO DAGScheduler: waiting: Set(ResultStage 24)
21/03/14 14:38:50 INFO DAGScheduler: failed: Set()
21/03/14 14:38:50 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[94] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:38:50 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:38:50 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:38:50 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:57727 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:38:50 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[94] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:50 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
21/03/14 14:38:50 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 30, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:38:50 INFO Executor: Running task 0.0 in stage 24.0 (TID 30)
21/03/14 14:38:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:38:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:38:50 INFO Executor: Finished task 0.0 in stage 24.0 (TID 30). 1782 bytes result sent to driver
21/03/14 14:38:50 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 30) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:38:50 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/03/14 14:38:50 INFO DAGScheduler: ResultStage 24 (count at NativeMethodAccessorImpl.java:0) finished in 0.012 s
21/03/14 14:38:50 INFO DAGScheduler: Job 14 finished: count at NativeMethodAccessorImpl.java:0, took 0.042947 s
21/03/14 14:38:51 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 14:38:51 INFO DAGScheduler: Registering RDD 98 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:38:51 INFO DAGScheduler: Got job 15 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:38:51 INFO DAGScheduler: Final stage: ResultStage 26 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:38:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
21/03/14 14:38:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
21/03/14 14:38:51 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[98] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:38:51 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 24.1 KB, free 912.2 MB)
21/03/14 14:38:51 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 10.6 KB, free 912.2 MB)
21/03/14 14:38:51 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:57727 (size: 10.6 KB, free: 912.3 MB)
21/03/14 14:38:51 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[98] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:51 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/03/14 14:38:51 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 11616 bytes)
21/03/14 14:38:51 INFO Executor: Running task 0.0 in stage 25.0 (TID 31)
21/03/14 14:38:51 INFO BlockManager: Found block rdd_80_0 locally
21/03/14 14:38:51 INFO Executor: Finished task 0.0 in stage 25.0 (TID 31). 2061 bytes result sent to driver
21/03/14 14:38:51 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 31) in 12 ms on localhost (executor driver) (1/1)
21/03/14 14:38:51 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/03/14 14:38:51 INFO DAGScheduler: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0) finished in 0.019 s
21/03/14 14:38:51 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:38:51 INFO DAGScheduler: running: Set()
21/03/14 14:38:51 INFO DAGScheduler: waiting: Set(ResultStage 26)
21/03/14 14:38:51 INFO DAGScheduler: failed: Set()
21/03/14 14:38:51 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[101] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:38:51 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:38:51 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:38:51 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on localhost:57727 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:38:51 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1161
21/03/14 14:38:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[101] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:38:51 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/03/14 14:38:51 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 32, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:38:51 INFO Executor: Running task 0.0 in stage 26.0 (TID 32)
21/03/14 14:38:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:38:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:38:51 INFO Executor: Finished task 0.0 in stage 26.0 (TID 32). 1825 bytes result sent to driver
21/03/14 14:38:51 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 32) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:38:51 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/03/14 14:38:51 INFO DAGScheduler: ResultStage 26 (count at NativeMethodAccessorImpl.java:0) finished in 0.013 s
21/03/14 14:38:51 INFO DAGScheduler: Job 15 finished: count at NativeMethodAccessorImpl.java:0, took 0.037765 s
21/03/14 14:38:51 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:38:51 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:41:23 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 14:41:23 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 14:41:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 14:41:23 INFO MemoryStore: MemoryStore cleared
21/03/14 14:41:23 INFO BlockManager: BlockManager stopped
21/03/14 14:41:23 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 14:41:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 14:41:23 INFO SparkContext: Successfully stopped SparkContext
21/03/14 14:41:23 INFO ShutdownHookManager: Shutdown hook called
21/03/14 14:41:23 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-bf0b0b41-2f09-4c98-9c8a-5eb01c61b00b
21/03/14 14:41:24 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-639cb139-1dcb-4fa7-9402-3b778df32383
21/03/14 14:41:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 14:41:45 INFO SparkContext: Running Spark version 2.4.3
21/03/14 14:41:45 INFO SparkContext: Submitted application: sparklyr
21/03/14 14:41:45 INFO SecurityManager: Changing view acls to: nathan
21/03/14 14:41:45 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 14:41:45 INFO SecurityManager: Changing view acls groups to: 
21/03/14 14:41:45 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 14:41:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 14:41:45 INFO Utils: Successfully started service 'sparkDriver' on port 58284.
21/03/14 14:41:45 INFO SparkEnv: Registering MapOutputTracker
21/03/14 14:41:45 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 14:41:45 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 14:41:45 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 14:41:45 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-1416e247-8749-490c-b584-4fcc6803b214
21/03/14 14:41:45 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 14:41:46 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 14:41:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 14:41:46 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 14:41:46 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:58284/jars/sparklyr-2.4-2.11.jar with timestamp 1615729306357
21/03/14 14:41:46 INFO Executor: Starting executor ID driver on host localhost
21/03/14 14:41:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58285.
21/03/14 14:41:46 INFO NettyBlockTransferService: Server created on localhost:58285
21/03/14 14:41:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 14:41:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 58285, None)
21/03/14 14:41:46 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58285 with 912.3 MB RAM, BlockManagerId(driver, localhost, 58285, None)
21/03/14 14:41:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 58285, None)
21/03/14 14:41:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 58285, None)
21/03/14 14:41:46 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 14:41:47 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 14:41:47 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 14:41:47 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 14:41:51 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 14:41:52 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 14:41:52 INFO ObjectStore: ObjectStore, initialize called
21/03/14 14:41:52 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 14:41:52 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 14:41:54 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 14:41:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:41:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:41:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:41:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:41:57 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 14:41:57 INFO ObjectStore: Initialized ObjectStore
21/03/14 14:41:57 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 14:41:57 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 14:41:57 INFO HiveMetaStore: Added admin role in metastore
21/03/14 14:41:57 INFO HiveMetaStore: Added public role in metastore
21/03/14 14:41:57 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 14:41:58 INFO HiveMetaStore: 0: get_all_databases
21/03/14 14:41:58 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 14:41:58 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:41:58 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:41:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:41:58 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/02abe2cd-a0c3-48bb-8dfd-2ac49ce467a3_resources
21/03/14 14:41:58 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/02abe2cd-a0c3-48bb-8dfd-2ac49ce467a3
21/03/14 14:41:58 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/02abe2cd-a0c3-48bb-8dfd-2ac49ce467a3
21/03/14 14:41:58 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/02abe2cd-a0c3-48bb-8dfd-2ac49ce467a3/_tmp_space.db
21/03/14 14:41:58 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 14:41:58 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:41:58 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:41:58 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 14:41:58 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 14:41:58 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 14:41:58 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:41:58 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:41:58 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:41:58 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:41:58 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 14:41:58 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 14:41:59 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 14:41:59 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/03/14 14:41:59 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/03/14 14:41:59 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:41:59 INFO DAGScheduler: Missing parents: List()
21/03/14 14:41:59 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/03/14 14:41:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/03/14 14:41:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/03/14 14:41:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58285 (size: 3.4 KB, free: 912.3 MB)
21/03/14 14:41:59 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 14:41:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 14:41:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 14:41:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/03/14 14:41:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 14:41:59 INFO Executor: Fetching spark://localhost:58284/jars/sparklyr-2.4-2.11.jar with timestamp 1615729306357
21/03/14 14:41:59 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:58284 after 30 ms (0 ms spent in bootstraps)
21/03/14 14:41:59 INFO Utils: Fetching spark://localhost:58284/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-1b5b16d9-fe65-4535-b67f-cd03ed236c32/userFiles-14c44942-451d-4e90-8d32-9592cf7e7558/fetchFileTemp5299456785877519511.tmp
21/03/14 14:41:59 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-1b5b16d9-fe65-4535-b67f-cd03ed236c32/userFiles-14c44942-451d-4e90-8d32-9592cf7e7558/sparklyr-2.4-2.11.jar to class loader
21/03/14 14:42:00 INFO CodeGenerator: Code generated in 323.267489 ms
21/03/14 14:42:00 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
21/03/14 14:42:00 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 882 ms on localhost (executor driver) (1/1)
21/03/14 14:42:00 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 14:42:00 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 1.296 s
21/03/14 14:42:00 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 1.373732 s
21/03/14 14:42:00 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:58285 in memory (size: 3.4 KB, free: 912.3 MB)
21/03/14 14:42:01 INFO CodeGenerator: Code generated in 19.959126 ms
21/03/14 14:42:01 INFO CodeGenerator: Code generated in 20.86072 ms
21/03/14 14:42:01 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:42:01 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:42:01 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 14:42:01 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:42:01 INFO DAGScheduler: Missing parents: List()
21/03/14 14:42:01 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/03/14 14:42:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 14:42:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 14:42:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58285 (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:42:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 14:42:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:42:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 14:42:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:42:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 14:42:01 INFO CodeGenerator: Code generated in 9.049026 ms
21/03/14 14:42:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 14:42:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 32 ms on localhost (executor driver) (1/1)
21/03/14 14:42:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 14:42:01 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.042 s
21/03/14 14:42:01 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.046078 s
21/03/14 14:42:01 INFO CodeGenerator: Code generated in 19.121924 ms
21/03/14 14:42:01 INFO CodeGenerator: Code generated in 14.598462 ms
21/03/14 14:42:01 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:42:01 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/03/14 14:42:01 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 14:42:01 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 14:42:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 14:42:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 14:42:01 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/03/14 14:42:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/03/14 14:42:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/03/14 14:42:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58285 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:42:01 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 14:42:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:42:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 14:42:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:42:01 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 14:42:01 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 14:42:01 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 56 ms on localhost (executor driver) (1/1)
21/03/14 14:42:01 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 14:42:01 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.073 s
21/03/14 14:42:01 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:42:01 INFO DAGScheduler: running: Set()
21/03/14 14:42:01 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 14:42:01 INFO DAGScheduler: failed: Set()
21/03/14 14:42:01 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/03/14 14:42:01 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:42:01 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:42:01 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:58285 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:42:01 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 14:42:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:42:01 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 14:42:01 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:42:01 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 14:42:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:42:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
21/03/14 14:42:01 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 14:42:01 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 66 ms on localhost (executor driver) (1/1)
21/03/14 14:42:01 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 14:42:01 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.077 s
21/03/14 14:42:01 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.179227 s
21/03/14 14:42:02 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:42:02 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:42:02 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/03/14 14:42:02 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:42:02 INFO DAGScheduler: Missing parents: List()
21/03/14 14:42:02 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135), which has no missing parents
21/03/14 14:42:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 14:42:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 14:42:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:58285 (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:42:02 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 14:42:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:42:02 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 14:42:02 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:42:02 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 14:42:02 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/03/14 14:42:02 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on localhost (executor driver) (1/1)
21/03/14 14:42:02 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 14:42:02 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.016 s
21/03/14 14:42:02 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.019138 s
21/03/14 14:42:02 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:42:02 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:135)
21/03/14 14:42:02 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/14 14:42:02 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/03/14 14:42:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/03/14 14:42:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/03/14 14:42:02 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/03/14 14:42:02 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/03/14 14:42:02 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/03/14 14:42:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:58285 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:42:02 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 14:42:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:42:02 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 14:42:02 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:42:02 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 14:42:02 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/03/14 14:42:02 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 12 ms on localhost (executor driver) (1/1)
21/03/14 14:42:02 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 14:42:02 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.022 s
21/03/14 14:42:02 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:42:02 INFO DAGScheduler: running: Set()
21/03/14 14:42:02 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/03/14 14:42:02 INFO DAGScheduler: failed: Set()
21/03/14 14:42:02 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/03/14 14:42:02 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:42:02 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:42:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:58285 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:42:02 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 14:42:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:42:02 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 14:42:02 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:42:02 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 14:42:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:42:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:42:02 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/03/14 14:42:02 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 6 ms on localhost (executor driver) (1/1)
21/03/14 14:42:02 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 14:42:02 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.015 s
21/03/14 14:42:02 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.042684 s
21/03/14 14:42:02 INFO CodeGenerator: Code generated in 37.862212 ms
21/03/14 14:42:02 INFO CodeGenerator: Code generated in 14.431482 ms
21/03/14 14:42:03 INFO CodeGenerator: Code generated in 16.010066 ms
21/03/14 14:42:03 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:42:03 INFO DAGScheduler: Registering RDD 28 (count at utils.scala:135)
21/03/14 14:42:03 INFO DAGScheduler: Got job 5 (count at utils.scala:135) with 1 output partitions
21/03/14 14:42:03 INFO DAGScheduler: Final stage: ResultStage 8 (count at utils.scala:135)
21/03/14 14:42:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
21/03/14 14:42:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
21/03/14 14:42:03 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135), which has no missing parents
21/03/14 14:42:03 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:42:03 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:42:03 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:58285 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:42:03 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 14:42:03 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/03/14 14:42:03 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
21/03/14 14:42:03 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8034 bytes)
21/03/14 14:42:03 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 8, localhost, executor driver, partition 1, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:42:03 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 9, localhost, executor driver, partition 2, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:42:03 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 10, localhost, executor driver, partition 3, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:42:03 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 14:42:03 INFO Executor: Running task 1.0 in stage 7.0 (TID 8)
21/03/14 14:42:03 INFO Executor: Running task 3.0 in stage 7.0 (TID 10)
21/03/14 14:42:03 INFO Executor: Running task 2.0 in stage 7.0 (TID 9)
21/03/14 14:42:03 INFO Executor: Finished task 1.0 in stage 7.0 (TID 8). 1499 bytes result sent to driver
21/03/14 14:42:03 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 8) in 13 ms on localhost (executor driver) (1/4)
21/03/14 14:42:03 INFO Executor: Finished task 3.0 in stage 7.0 (TID 10). 1499 bytes result sent to driver
21/03/14 14:42:03 INFO Executor: Finished task 2.0 in stage 7.0 (TID 9). 1499 bytes result sent to driver
21/03/14 14:42:03 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1499 bytes result sent to driver
21/03/14 14:42:03 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 10) in 14 ms on localhost (executor driver) (2/4)
21/03/14 14:42:03 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 9) in 14 ms on localhost (executor driver) (3/4)
21/03/14 14:42:03 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 16 ms on localhost (executor driver) (4/4)
21/03/14 14:42:03 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 14:42:03 INFO DAGScheduler: ShuffleMapStage 7 (count at utils.scala:135) finished in 0.026 s
21/03/14 14:42:03 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:42:03 INFO DAGScheduler: running: Set()
21/03/14 14:42:03 INFO DAGScheduler: waiting: Set(ResultStage 8)
21/03/14 14:42:03 INFO DAGScheduler: failed: Set()
21/03/14 14:42:03 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135), which has no missing parents
21/03/14 14:42:03 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:42:03 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:42:03 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:58285 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:42:03 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 14:42:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:42:03 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 14:42:03 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:42:03 INFO Executor: Running task 0.0 in stage 8.0 (TID 11)
21/03/14 14:42:03 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
21/03/14 14:42:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:42:03 INFO Executor: Finished task 0.0 in stage 8.0 (TID 11). 1782 bytes result sent to driver
21/03/14 14:42:03 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 11) in 9 ms on localhost (executor driver) (1/1)
21/03/14 14:42:03 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 14:42:03 INFO DAGScheduler: ResultStage 8 (count at utils.scala:135) finished in 0.019 s
21/03/14 14:42:03 INFO DAGScheduler: Job 5 finished: count at utils.scala:135, took 0.050851 s
21/03/14 14:42:03 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 14:42:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 14:42:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 14:42:03 INFO MemoryStore: MemoryStore cleared
21/03/14 14:42:03 INFO BlockManager: BlockManager stopped
21/03/14 14:42:03 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 14:42:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 14:42:03 INFO SparkContext: Successfully stopped SparkContext
21/03/14 14:42:03 INFO ShutdownHookManager: Shutdown hook called
21/03/14 14:42:03 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-224c045e-4c76-4242-88ed-b65462c29e6a
21/03/14 14:42:03 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-1b5b16d9-fe65-4535-b67f-cd03ed236c32
21/03/14 14:42:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 14:42:07 INFO SparkContext: Running Spark version 2.4.3
21/03/14 14:42:07 INFO SparkContext: Submitted application: sparklyr
21/03/14 14:42:07 INFO SecurityManager: Changing view acls to: nathan
21/03/14 14:42:07 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 14:42:07 INFO SecurityManager: Changing view acls groups to: 
21/03/14 14:42:07 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 14:42:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 14:42:07 INFO Utils: Successfully started service 'sparkDriver' on port 58445.
21/03/14 14:42:07 INFO SparkEnv: Registering MapOutputTracker
21/03/14 14:42:08 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 14:42:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 14:42:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 14:42:08 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-90eda06a-64da-4f11-85a6-53e21202479c
21/03/14 14:42:08 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 14:42:08 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 14:42:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 14:42:08 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 14:42:08 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:58445/jars/sparklyr-2.4-2.11.jar with timestamp 1615729328528
21/03/14 14:42:08 INFO Executor: Starting executor ID driver on host localhost
21/03/14 14:42:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58446.
21/03/14 14:42:08 INFO NettyBlockTransferService: Server created on localhost:58446
21/03/14 14:42:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 14:42:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 58446, None)
21/03/14 14:42:08 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58446 with 912.3 MB RAM, BlockManagerId(driver, localhost, 58446, None)
21/03/14 14:42:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 58446, None)
21/03/14 14:42:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 58446, None)
21/03/14 14:42:09 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 14:42:09 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 14:42:09 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 14:42:10 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 14:42:12 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 14:42:12 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 14:42:13 INFO ObjectStore: ObjectStore, initialize called
21/03/14 14:42:13 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 14:42:13 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 14:42:15 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 14:42:16 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:42:16 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:42:17 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:42:17 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:42:17 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 14:42:17 INFO ObjectStore: Initialized ObjectStore
21/03/14 14:42:17 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 14:42:17 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 14:42:18 INFO HiveMetaStore: Added admin role in metastore
21/03/14 14:42:18 INFO HiveMetaStore: Added public role in metastore
21/03/14 14:42:18 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 14:42:18 INFO HiveMetaStore: 0: get_all_databases
21/03/14 14:42:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 14:42:18 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:42:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:42:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:42:18 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/8559a142-777c-478f-9f73-94df44c2e286_resources
21/03/14 14:42:18 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/8559a142-777c-478f-9f73-94df44c2e286
21/03/14 14:42:18 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/8559a142-777c-478f-9f73-94df44c2e286
21/03/14 14:42:18 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/8559a142-777c-478f-9f73-94df44c2e286/_tmp_space.db
21/03/14 14:42:18 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 14:42:18 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:42:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:42:18 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:42:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:42:18 INFO HiveMetaStore: 0: get_database: fake_database
21/03/14 14:42:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: fake_database	
21/03/14 14:42:18 WARN ObjectStore: Failed to get database fake_database, returning NoSuchObjectException
21/03/14 14:42:18 INFO HiveMetaStore: 0: get_databases: *
21/03/14 14:42:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_databases: *	
21/03/14 14:42:18 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:42:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:42:18 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:42:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:42:19 INFO CodeGenerator: Code generated in 328.36418 ms
21/03/14 14:42:20 INFO CodeGenerator: Code generated in 23.18228 ms
21/03/14 14:42:20 INFO CodeGenerator: Code generated in 16.169016 ms
21/03/14 14:42:20 INFO ContextCleaner: Cleaned accumulator 1
21/03/14 14:42:20 INFO CodeGenerator: Code generated in 34.082027 ms
21/03/14 14:42:20 INFO CodeGenerator: Code generated in 27.253536 ms
21/03/14 14:42:20 INFO CodeGenerator: Code generated in 21.89096 ms
21/03/14 14:42:20 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:42:21 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:135)
21/03/14 14:42:21 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/03/14 14:42:21 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/03/14 14:42:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/03/14 14:42:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/03/14 14:42:21 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135), which has no missing parents
21/03/14 14:42:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 14:42:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 14:42:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58446 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:42:21 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 14:42:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:42:21 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 14:42:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 14:42:21 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 14:42:21 INFO Executor: Fetching spark://localhost:58445/jars/sparklyr-2.4-2.11.jar with timestamp 1615729328528
21/03/14 14:42:21 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:58445 after 23 ms (0 ms spent in bootstraps)
21/03/14 14:42:21 INFO Utils: Fetching spark://localhost:58445/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-4a47966c-2722-4fda-9381-57fb1a2719dc/userFiles-ea35b3c7-5f0f-4346-b122-8e0dbd57fa2e/fetchFileTemp3569265391029756192.tmp
21/03/14 14:42:21 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-4a47966c-2722-4fda-9381-57fb1a2719dc/userFiles-ea35b3c7-5f0f-4346-b122-8e0dbd57fa2e/sparklyr-2.4-2.11.jar to class loader
21/03/14 14:42:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1585 bytes result sent to driver
21/03/14 14:42:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 559 ms on localhost (executor driver) (1/1)
21/03/14 14:42:21 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 14:42:21 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:135) finished in 0.931 s
21/03/14 14:42:21 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:42:21 INFO DAGScheduler: running: Set()
21/03/14 14:42:21 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/03/14 14:42:21 INFO DAGScheduler: failed: Set()
21/03/14 14:42:21 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135), which has no missing parents
21/03/14 14:42:21 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:42:21 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:42:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58446 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:42:21 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 14:42:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:42:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 14:42:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:42:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 14:42:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:42:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
21/03/14 14:42:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1825 bytes result sent to driver
21/03/14 14:42:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 65 ms on localhost (executor driver) (1/1)
21/03/14 14:42:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 14:42:22 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.083 s
21/03/14 14:42:22 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 1.104136 s
21/03/14 14:42:22 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 14:42:22 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 14:42:22 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 14:42:22 INFO HiveMetaStore: 0: create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})
21/03/14 14:42:22 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})	
21/03/14 14:42:22 WARN ObjectStore: Failed to get database catalog_test_database_db, returning NoSuchObjectException
21/03/14 14:42:22 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:42:22 INFO CodeGenerator: Code generated in 13.076673 ms
21/03/14 14:42:22 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:42:22 INFO DAGScheduler: Registering RDD 10 (count at utils.scala:135)
21/03/14 14:42:22 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/03/14 14:42:22 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 14:42:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 14:42:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 14:42:22 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[10] at count at utils.scala:135), which has no missing parents
21/03/14 14:42:22 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 14:42:22 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 14:42:22 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58446 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:42:22 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 14:42:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[10] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:42:22 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 14:42:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 14:42:22 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 14:42:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1499 bytes result sent to driver
21/03/14 14:42:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 10 ms on localhost (executor driver) (1/1)
21/03/14 14:42:22 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 14:42:22 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.020 s
21/03/14 14:42:22 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:42:22 INFO DAGScheduler: running: Set()
21/03/14 14:42:22 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 14:42:22 INFO DAGScheduler: failed: Set()
21/03/14 14:42:22 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[13] at count at utils.scala:135), which has no missing parents
21/03/14 14:42:22 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:42:22 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:42:22 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:58446 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:42:22 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 14:42:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:42:22 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 14:42:22 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:42:22 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 14:42:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:42:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:42:22 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1775 bytes result sent to driver
21/03/14 14:42:22 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 11 ms on localhost (executor driver) (1/1)
21/03/14 14:42:22 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 14:42:22 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.021 s
21/03/14 14:42:22 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.048891 s
21/03/14 14:42:22 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:42:22 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:42:22 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:42:22 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:42:22 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:42:22 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:42:22 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:42:22 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:42:22 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:42:22 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:42:22 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:42:22 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:42:22 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:42:22 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:42:22 INFO HiveMetaStore: 0: drop_database: catalog_test_database_db
21/03/14 14:42:22 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=drop_database: catalog_test_database_db	
21/03/14 14:42:22 INFO HiveMetaStore: 0: get_all_tables: db=catalog_test_database_db
21/03/14 14:42:22 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_tables: db=catalog_test_database_db	
21/03/14 14:42:22 INFO HiveMetaStore: 0: get_functions: db=catalog_test_database_db pat=*
21/03/14 14:42:22 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=catalog_test_database_db pat=*	
21/03/14 14:42:22 INFO ObjectStore: Dropping database catalog_test_database_db along with all tables
21/03/14 14:42:22 INFO hivemetastoressimpl: deleting  file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:42:22 INFO deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
21/03/14 14:42:22 INFO TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
21/03/14 14:42:22 INFO hivemetastoressimpl: Deleted the diretory file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:42:23 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:42:23 INFO DAGScheduler: Registering RDD 17 (count at utils.scala:135)
21/03/14 14:42:23 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 14:42:23 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/03/14 14:42:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 14:42:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 14:42:23 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at count at utils.scala:135), which has no missing parents
21/03/14 14:42:23 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:42:23 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:42:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:58446 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:42:23 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 14:42:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:42:23 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 14:42:23 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 14:42:23 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 14:42:23 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1499 bytes result sent to driver
21/03/14 14:42:23 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 11 ms on localhost (executor driver) (1/1)
21/03/14 14:42:23 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 14:42:23 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.020 s
21/03/14 14:42:23 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:42:23 INFO DAGScheduler: running: Set()
21/03/14 14:42:23 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 14:42:23 INFO DAGScheduler: failed: Set()
21/03/14 14:42:23 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[20] at count at utils.scala:135), which has no missing parents
21/03/14 14:42:23 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:42:23 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:42:23 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:58446 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:42:23 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 14:42:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:42:23 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 14:42:23 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:42:23 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 14:42:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:42:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:42:23 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1775 bytes result sent to driver
21/03/14 14:42:23 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 8 ms on localhost (executor driver) (1/1)
21/03/14 14:42:23 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 14:42:23 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.017 s
21/03/14 14:42:23 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.043023 s
21/03/14 14:42:23 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 14:42:23 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 14:42:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 14:42:23 INFO MemoryStore: MemoryStore cleared
21/03/14 14:42:23 INFO BlockManager: BlockManager stopped
21/03/14 14:42:23 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 14:42:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 14:42:23 INFO SparkContext: Successfully stopped SparkContext
21/03/14 14:42:23 INFO ShutdownHookManager: Shutdown hook called
21/03/14 14:42:23 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-4a47966c-2722-4fda-9381-57fb1a2719dc
21/03/14 14:42:23 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-c64a0d2f-75a9-4f51-b83b-8d03de50d5e9
21/03/14 14:42:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 14:42:27 INFO SparkContext: Running Spark version 2.4.3
21/03/14 14:42:27 INFO SparkContext: Submitted application: sparklyr
21/03/14 14:42:27 INFO SecurityManager: Changing view acls to: nathan
21/03/14 14:42:27 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 14:42:27 INFO SecurityManager: Changing view acls groups to: 
21/03/14 14:42:27 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 14:42:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 14:42:27 INFO Utils: Successfully started service 'sparkDriver' on port 58527.
21/03/14 14:42:27 INFO SparkEnv: Registering MapOutputTracker
21/03/14 14:42:27 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 14:42:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 14:42:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 14:42:28 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-6c8d60b3-4f2b-4f14-af87-425e49aa040c
21/03/14 14:42:28 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 14:42:28 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 14:42:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 14:42:28 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 14:42:28 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:58527/jars/sparklyr-2.4-2.11.jar with timestamp 1615729348402
21/03/14 14:42:28 INFO Executor: Starting executor ID driver on host localhost
21/03/14 14:42:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58528.
21/03/14 14:42:28 INFO NettyBlockTransferService: Server created on localhost:58528
21/03/14 14:42:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 14:42:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 58528, None)
21/03/14 14:42:28 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58528 with 912.3 MB RAM, BlockManagerId(driver, localhost, 58528, None)
21/03/14 14:42:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 58528, None)
21/03/14 14:42:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 58528, None)
21/03/14 14:42:29 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 14:42:29 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 14:42:29 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 14:42:29 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 14:42:32 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 14:42:32 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 14:42:33 INFO ObjectStore: ObjectStore, initialize called
21/03/14 14:42:33 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 14:42:33 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 14:42:34 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 14:42:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:42:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:42:37 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:42:37 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:42:37 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 14:42:37 INFO ObjectStore: Initialized ObjectStore
21/03/14 14:42:37 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 14:42:37 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 14:42:37 INFO HiveMetaStore: Added admin role in metastore
21/03/14 14:42:37 INFO HiveMetaStore: Added public role in metastore
21/03/14 14:42:38 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 14:42:38 INFO HiveMetaStore: 0: get_all_databases
21/03/14 14:42:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 14:42:38 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:42:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:42:38 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:42:38 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/2bdc5258-4832-4632-9500-fd6f37674a5f_resources
21/03/14 14:42:38 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/2bdc5258-4832-4632-9500-fd6f37674a5f
21/03/14 14:42:38 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/2bdc5258-4832-4632-9500-fd6f37674a5f
21/03/14 14:42:38 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/2bdc5258-4832-4632-9500-fd6f37674a5f/_tmp_space.db
21/03/14 14:42:38 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 14:42:38 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:42:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:42:38 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:42:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:42:38 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:42:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:42:38 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:42:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:42:38 INFO HiveMetaStore: 0: get_function: default.catalog_fake_function
21/03/14 14:42:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_function: default.catalog_fake_function	
21/03/14 14:42:38 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:42:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:42:38 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:42:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:42:38 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:42:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:42:38 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:42:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:42:39 INFO CodeGenerator: Code generated in 320.045645 ms
21/03/14 14:42:40 INFO CodeGenerator: Code generated in 18.305847 ms
21/03/14 14:42:40 INFO CodeGenerator: Code generated in 20.301192 ms
21/03/14 14:42:40 INFO CodeGenerator: Code generated in 28.66243 ms
21/03/14 14:42:40 INFO CodeGenerator: Code generated in 15.596922 ms
21/03/14 14:42:40 INFO CodeGenerator: Code generated in 9.428099 ms
21/03/14 14:42:41 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:42:41 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:135)
21/03/14 14:42:41 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/03/14 14:42:41 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/03/14 14:42:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/03/14 14:42:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/03/14 14:42:41 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135), which has no missing parents
21/03/14 14:42:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 14:42:41 INFO ContextCleaner: Cleaned accumulator 1
21/03/14 14:42:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 14:42:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58528 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:42:41 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 14:42:41 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/03/14 14:42:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 4 tasks
21/03/14 14:42:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 9258 bytes)
21/03/14 14:42:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 9275 bytes)
21/03/14 14:42:41 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 9258 bytes)
21/03/14 14:42:41 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 9275 bytes)
21/03/14 14:42:41 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
21/03/14 14:42:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
21/03/14 14:42:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 14:42:41 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
21/03/14 14:42:41 INFO Executor: Fetching spark://localhost:58527/jars/sparklyr-2.4-2.11.jar with timestamp 1615729348402
21/03/14 14:42:41 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:58527 after 23 ms (0 ms spent in bootstraps)
21/03/14 14:42:41 INFO Utils: Fetching spark://localhost:58527/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-374f451f-b0f9-426c-af70-06d270be3a61/userFiles-24443af7-bd47-4e8f-bb1b-3a3d60956701/fetchFileTemp8424375247462802742.tmp
21/03/14 14:42:41 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-374f451f-b0f9-426c-af70-06d270be3a61/userFiles-24443af7-bd47-4e8f-bb1b-3a3d60956701/sparklyr-2.4-2.11.jar to class loader
21/03/14 14:42:41 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1542 bytes result sent to driver
21/03/14 14:42:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1542 bytes result sent to driver
21/03/14 14:42:41 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1542 bytes result sent to driver
21/03/14 14:42:41 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1542 bytes result sent to driver
21/03/14 14:42:41 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 280 ms on localhost (executor driver) (1/4)
21/03/14 14:42:41 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 283 ms on localhost (executor driver) (2/4)
21/03/14 14:42:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 302 ms on localhost (executor driver) (3/4)
21/03/14 14:42:41 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 286 ms on localhost (executor driver) (4/4)
21/03/14 14:42:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 14:42:42 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:135) finished in 0.752 s
21/03/14 14:42:42 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:42:42 INFO DAGScheduler: running: Set()
21/03/14 14:42:42 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/03/14 14:42:42 INFO DAGScheduler: failed: Set()
21/03/14 14:42:42 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135), which has no missing parents
21/03/14 14:42:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:42:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:42:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58528 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:42:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 14:42:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:42:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 14:42:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:42:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 4)
21/03/14 14:42:42 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
21/03/14 14:42:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
21/03/14 14:42:42 INFO Executor: Finished task 0.0 in stage 1.0 (TID 4). 1825 bytes result sent to driver
21/03/14 14:42:42 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 4) in 46 ms on localhost (executor driver) (1/1)
21/03/14 14:42:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 14:42:42 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.060 s
21/03/14 14:42:42 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.918786 s
21/03/14 14:42:42 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 14:42:42 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 14:42:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 14:42:42 INFO MemoryStore: MemoryStore cleared
21/03/14 14:42:42 INFO BlockManager: BlockManager stopped
21/03/14 14:42:42 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 14:42:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 14:42:42 INFO SparkContext: Successfully stopped SparkContext
21/03/14 14:42:42 INFO ShutdownHookManager: Shutdown hook called
21/03/14 14:42:42 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-f66094e2-e0e8-4a53-b817-2c5e8fb28675
21/03/14 14:42:42 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-374f451f-b0f9-426c-af70-06d270be3a61
21/03/14 14:42:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 14:42:46 INFO SparkContext: Running Spark version 2.4.3
21/03/14 14:42:46 INFO SparkContext: Submitted application: sparklyr
21/03/14 14:42:46 INFO SecurityManager: Changing view acls to: nathan
21/03/14 14:42:46 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 14:42:46 INFO SecurityManager: Changing view acls groups to: 
21/03/14 14:42:46 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 14:42:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 14:42:46 INFO Utils: Successfully started service 'sparkDriver' on port 58607.
21/03/14 14:42:46 INFO SparkEnv: Registering MapOutputTracker
21/03/14 14:42:46 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 14:42:46 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 14:42:46 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 14:42:46 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-a3b0e6f3-0b2e-4658-9a31-075457109911
21/03/14 14:42:46 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 14:42:46 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 14:42:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 14:42:47 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 14:42:47 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:58607/jars/sparklyr-2.4-2.11.jar with timestamp 1615729367175
21/03/14 14:42:47 INFO Executor: Starting executor ID driver on host localhost
21/03/14 14:42:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58608.
21/03/14 14:42:47 INFO NettyBlockTransferService: Server created on localhost:58608
21/03/14 14:42:47 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 14:42:47 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 58608, None)
21/03/14 14:42:47 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58608 with 912.3 MB RAM, BlockManagerId(driver, localhost, 58608, None)
21/03/14 14:42:47 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 58608, None)
21/03/14 14:42:47 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 58608, None)
21/03/14 14:42:47 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 14:42:47 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 14:42:47 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 14:42:48 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 14:42:51 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 14:42:52 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 14:42:52 INFO ObjectStore: ObjectStore, initialize called
21/03/14 14:42:52 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 14:42:52 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 14:42:54 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 14:42:55 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:42:55 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:42:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:42:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:42:56 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 14:42:56 INFO ObjectStore: Initialized ObjectStore
21/03/14 14:42:56 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 14:42:56 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 14:42:56 INFO HiveMetaStore: Added admin role in metastore
21/03/14 14:42:56 INFO HiveMetaStore: Added public role in metastore
21/03/14 14:42:57 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 14:42:57 INFO HiveMetaStore: 0: get_all_databases
21/03/14 14:42:57 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 14:42:57 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:42:57 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:42:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:42:57 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/b33644aa-ae79-4a91-82aa-5f297cb90115_resources
21/03/14 14:42:57 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/b33644aa-ae79-4a91-82aa-5f297cb90115
21/03/14 14:42:57 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/b33644aa-ae79-4a91-82aa-5f297cb90115
21/03/14 14:42:57 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/b33644aa-ae79-4a91-82aa-5f297cb90115/_tmp_space.db
21/03/14 14:42:57 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 14:42:57 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:42:57 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:42:57 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:42:57 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:42:57 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:42:57 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
21/03/14 14:42:58 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 14:42:58 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:42:58 INFO CodeGenerator: Code generated in 296.210616 ms
21/03/14 14:42:58 INFO CodeGenerator: Code generated in 29.786254 ms
21/03/14 14:42:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 284.3 KB, free 912.0 MB)
21/03/14 14:42:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.9 KB, free 912.0 MB)
21/03/14 14:42:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58608 (size: 23.9 KB, free: 912.3 MB)
21/03/14 14:42:58 INFO SparkContext: Created broadcast 0 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 14:42:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:42:59 INFO SparkContext: Starting job: createTable at NativeMethodAccessorImpl.java:0
21/03/14 14:42:59 INFO DAGScheduler: Got job 0 (createTable at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:42:59 INFO DAGScheduler: Final stage: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0)
21/03/14 14:42:59 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:42:59 INFO DAGScheduler: Missing parents: List()
21/03/14 14:42:59 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:42:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 912.0 MB)
21/03/14 14:42:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.0 MB)
21/03/14 14:42:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58608 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:42:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 14:42:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:42:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 14:42:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8362 bytes)
21/03/14 14:42:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 14:42:59 INFO Executor: Fetching spark://localhost:58607/jars/sparklyr-2.4-2.11.jar with timestamp 1615729367175
21/03/14 14:42:59 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:58607 after 28 ms (0 ms spent in bootstraps)
21/03/14 14:42:59 INFO Utils: Fetching spark://localhost:58607/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-07fc3f73-2724-477c-aa65-ca242cf6e7c4/userFiles-dc99da94-415d-4f4b-8b8f-64850bab26a2/fetchFileTemp7244523045070264282.tmp
21/03/14 14:42:59 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-07fc3f73-2724-477c-aa65-ca242cf6e7c4/userFiles-dc99da94-415d-4f4b-8b8f-64850bab26a2/sparklyr-2.4-2.11.jar to class loader
21/03/14 14:42:59 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpFXZ7Dv/file150a815e41a76, range: 0-1303, partition values: [empty row]
21/03/14 14:42:59 INFO CodeGenerator: Code generated in 16.743992 ms
21/03/14 14:42:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1329 bytes result sent to driver
21/03/14 14:42:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 356 ms on localhost (executor driver) (1/1)
21/03/14 14:42:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 14:42:59 INFO DAGScheduler: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0) finished in 0.477 s
21/03/14 14:42:59 INFO DAGScheduler: Job 0 finished: createTable at NativeMethodAccessorImpl.java:0, took 0.531930 s
21/03/14 14:42:59 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:42:59 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 14:42:59 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 14:42:59 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:42:59 INFO CodeGenerator: Code generated in 8.963544 ms
21/03/14 14:42:59 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 284.3 KB, free 911.7 MB)
21/03/14 14:42:59 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.7 MB)
21/03/14 14:42:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58608 (size: 23.9 KB, free: 912.2 MB)
21/03/14 14:42:59 INFO SparkContext: Created broadcast 2 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 14:42:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:43:00 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:43:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:43:00 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:00 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:43:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:43:00 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:00 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `default`.`mtcars` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.
21/03/14 14:43:00 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:43:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:43:00 INFO HiveMetaStore: 0: create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615729370, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpFXZ7Dv/file150a815e41a76, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
21/03/14 14:43:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615729370, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpFXZ7Dv/file150a815e41a76, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
21/03/14 14:43:00 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__
21/03/14 14:43:00 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 14:43:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 14:43:00 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 14:43:00 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:00 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:01 INFO CodeGenerator: Code generated in 22.79908 ms
21/03/14 14:43:01 INFO CodeGenerator: Code generated in 16.284134 ms
21/03/14 14:43:01 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:43:01 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:43:01 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 14:43:01 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:43:01 INFO DAGScheduler: Missing parents: List()
21/03/14 14:43:01 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135), which has no missing parents
21/03/14 14:43:01 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.5 KB, free 911.7 MB)
21/03/14 14:43:01 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 14:43:01 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:58608 (size: 3.3 KB, free: 912.2 MB)
21/03/14 14:43:01 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 14:43:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:43:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 14:43:01 INFO CodeGenerator: Code generated in 8.57089 ms
21/03/14 14:43:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 14:43:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 31 ms on localhost (executor driver) (1/1)
21/03/14 14:43:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 14:43:01 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.040 s
21/03/14 14:43:01 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.045431 s
21/03/14 14:43:01 INFO CodeGenerator: Code generated in 18.364951 ms
21/03/14 14:43:01 INFO CodeGenerator: Code generated in 13.854055 ms
21/03/14 14:43:01 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:43:01 INFO DAGScheduler: Registering RDD 16 (count at utils.scala:135)
21/03/14 14:43:01 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 14:43:01 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 14:43:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 14:43:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 14:43:01 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135), which has no missing parents
21/03/14 14:43:01 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.4 KB, free 911.7 MB)
21/03/14 14:43:01 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.7 MB)
21/03/14 14:43:01 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:58608 (size: 4.5 KB, free: 912.2 MB)
21/03/14 14:43:01 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 14:43:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:43:01 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 14:43:01 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 14:43:01 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 59 ms on localhost (executor driver) (1/1)
21/03/14 14:43:01 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 14:43:01 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.076 s
21/03/14 14:43:01 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:43:01 INFO DAGScheduler: running: Set()
21/03/14 14:43:01 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 14:43:01 INFO DAGScheduler: failed: Set()
21/03/14 14:43:01 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135), which has no missing parents
21/03/14 14:43:01 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 14:43:01 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 14:43:01 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:58608 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:43:01 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:01 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 14:43:01 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:43:01 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 14:43:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:43:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
21/03/14 14:43:01 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 14:43:01 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 57 ms on localhost (executor driver) (1/1)
21/03/14 14:43:01 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 14:43:01 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.071 s
21/03/14 14:43:01 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.182252 s
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 111
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 118
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 13
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 94
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 11
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 21
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 119
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 78
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 74
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 80
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 36
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 64
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 15
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 81
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 96
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 108
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 120
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 65
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 117
21/03/14 14:43:01 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:58608 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 77
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 23
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 93
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 90
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 99
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 79
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 89
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 17
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 84
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 121
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 24
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 101
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 12
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 72
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 110
21/03/14 14:43:01 INFO ContextCleaner: Cleaned shuffle 0
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 70
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 16
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 82
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 14:43:01 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:58608 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 95
21/03/14 14:43:01 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:58608 in memory (size: 3.3 KB, free: 912.2 MB)
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 83
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 92
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 73
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 112
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 26
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 85
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 68
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 22
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 69
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 122
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 124
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 126
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 103
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 8
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 10
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 102
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 27
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 76
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 75
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 88
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 29
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 115
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 7
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 67
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 6
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 123
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 25
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 19
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 71
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 14
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 109
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 127
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 106
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 87
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 18
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 100
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 116
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 28
21/03/14 14:43:01 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:58608 in memory (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 98
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 86
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 97
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 30
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 125
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 20
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 37
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 107
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 114
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 9
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 66
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 91
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 113
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 105
21/03/14 14:43:01 INFO ContextCleaner: Cleaned accumulator 104
21/03/14 14:43:01 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:01 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:02 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:02 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:02 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:43:02 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 14:43:02 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 14:43:02 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:43:02 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:02 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:02 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 284.5 KB, free 911.4 MB)
21/03/14 14:43:02 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.4 MB)
21/03/14 14:43:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:58608 (size: 23.9 KB, free: 912.2 MB)
21/03/14 14:43:02 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
21/03/14 14:43:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:43:02 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 14:43:02 INFO DAGScheduler: Registering RDD 27 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:43:02 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:43:02 INFO DAGScheduler: Final stage: ResultStage 5 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:43:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 14:43:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 14:43:02 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:43:02 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 911.4 MB)
21/03/14 14:43:02 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 12.2 KB, free 911.4 MB)
21/03/14 14:43:02 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:58608 (size: 12.2 KB, free: 912.2 MB)
21/03/14 14:43:02 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:02 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 14:43:02 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 14:43:02 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 14:43:02 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpFXZ7Dv/file150a815e41a76, range: 0-1303, partition values: [empty row]
21/03/14 14:43:02 INFO CodeGenerator: Code generated in 21.736176 ms
21/03/14 14:43:02 INFO MemoryStore: Block rdd_22_0 stored as values in memory (estimated size 4.1 KB, free 911.4 MB)
21/03/14 14:43:02 INFO BlockManagerInfo: Added rdd_22_0 in memory on localhost:58608 (size: 4.1 KB, free: 912.2 MB)
21/03/14 14:43:02 INFO CodeGenerator: Code generated in 7.546177 ms
21/03/14 14:43:02 INFO CodeGenerator: Code generated in 21.935196 ms
21/03/14 14:43:02 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1871 bytes result sent to driver
21/03/14 14:43:02 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 199 ms on localhost (executor driver) (1/1)
21/03/14 14:43:02 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 14:43:02 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.242 s
21/03/14 14:43:02 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:43:02 INFO DAGScheduler: running: Set()
21/03/14 14:43:02 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 14:43:02 INFO DAGScheduler: failed: Set()
21/03/14 14:43:02 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:43:02 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 14:43:02 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 14:43:02 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:58608 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:43:02 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:02 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 14:43:02 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:43:02 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 14:43:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:43:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:43:02 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1782 bytes result sent to driver
21/03/14 14:43:02 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 8 ms on localhost (executor driver) (1/1)
21/03/14 14:43:02 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 14:43:02 INFO DAGScheduler: ResultStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.018 s
21/03/14 14:43:02 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.272378 s
21/03/14 14:43:02 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:02 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 14:43:02 INFO DAGScheduler: Registering RDD 35 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:43:02 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:43:02 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:43:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
21/03/14 14:43:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
21/03/14 14:43:02 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:43:02 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 25.9 KB, free 911.3 MB)
21/03/14 14:43:02 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.1 KB, free 911.3 MB)
21/03/14 14:43:02 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:58608 (size: 12.1 KB, free: 912.2 MB)
21/03/14 14:43:02 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:02 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 14:43:02 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 14:43:02 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 14:43:02 INFO BlockManager: Found block rdd_22_0 locally
21/03/14 14:43:02 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1871 bytes result sent to driver
21/03/14 14:43:02 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 14 ms on localhost (executor driver) (1/1)
21/03/14 14:43:02 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 14:43:02 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.029 s
21/03/14 14:43:02 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:43:02 INFO DAGScheduler: running: Set()
21/03/14 14:43:02 INFO DAGScheduler: waiting: Set(ResultStage 7)
21/03/14 14:43:02 INFO DAGScheduler: failed: Set()
21/03/14 14:43:02 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:43:02 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 14:43:02 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 14:43:02 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:58608 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:43:02 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:02 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/14 14:43:02 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:43:02 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 14:43:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:43:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:43:02 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1782 bytes result sent to driver
21/03/14 14:43:02 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 6 ms on localhost (executor driver) (1/1)
21/03/14 14:43:02 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 14:43:02 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.014 s
21/03/14 14:43:02 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.049590 s
21/03/14 14:43:02 INFO MapPartitionsRDD: Removing RDD 22 from persistence list
21/03/14 14:43:02 INFO BlockManager: Removing RDD 22
21/03/14 14:43:02 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:43:02 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 14:43:02 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 14:43:02 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:43:02 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:02 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 284.5 KB, free 911.0 MB)
21/03/14 14:43:02 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.0 MB)
21/03/14 14:43:02 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:58608 (size: 23.9 KB, free: 912.2 MB)
21/03/14 14:43:02 INFO SparkContext: Created broadcast 11 from count at NativeMethodAccessorImpl.java:0
21/03/14 14:43:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:43:03 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 14:43:03 INFO DAGScheduler: Registering RDD 46 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:43:03 INFO DAGScheduler: Got job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:43:03 INFO DAGScheduler: Final stage: ResultStage 9 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:43:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/03/14 14:43:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
21/03/14 14:43:03 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:43:03 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 25.9 KB, free 911.0 MB)
21/03/14 14:43:03 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 12.1 KB, free 911.0 MB)
21/03/14 14:43:03 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:58608 (size: 12.1 KB, free: 912.2 MB)
21/03/14 14:43:03 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:03 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 14:43:03 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 14:43:03 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/03/14 14:43:03 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpFXZ7Dv/file150a815e41a76, range: 0-2539, partition values: [empty row]
21/03/14 14:43:03 INFO MemoryStore: Block rdd_41_0 stored as values in memory (estimated size 4.9 KB, free 911.0 MB)
21/03/14 14:43:03 INFO BlockManagerInfo: Added rdd_41_0 in memory on localhost:58608 (size: 4.9 KB, free: 912.2 MB)
21/03/14 14:43:03 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1871 bytes result sent to driver
21/03/14 14:43:03 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 44 ms on localhost (executor driver) (1/1)
21/03/14 14:43:03 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 14:43:03 INFO DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.057 s
21/03/14 14:43:03 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:43:03 INFO DAGScheduler: running: Set()
21/03/14 14:43:03 INFO DAGScheduler: waiting: Set(ResultStage 9)
21/03/14 14:43:03 INFO DAGScheduler: failed: Set()
21/03/14 14:43:03 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[49] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:43:03 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.1 KB, free 911.0 MB)
21/03/14 14:43:03 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.8 KB, free 910.9 MB)
21/03/14 14:43:03 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:58608 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:43:03 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[49] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:03 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 14:43:03 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:43:03 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/03/14 14:43:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:43:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:43:03 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1782 bytes result sent to driver
21/03/14 14:43:03 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 6 ms on localhost (executor driver) (1/1)
21/03/14 14:43:03 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 14:43:03 INFO DAGScheduler: ResultStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.013 s
21/03/14 14:43:03 INFO DAGScheduler: Job 5 finished: count at NativeMethodAccessorImpl.java:0, took 0.076505 s
21/03/14 14:43:03 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 14:43:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 14:43:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 14:43:03 INFO MemoryStore: MemoryStore cleared
21/03/14 14:43:03 INFO BlockManager: BlockManager stopped
21/03/14 14:43:03 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 14:43:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 14:43:03 INFO SparkContext: Successfully stopped SparkContext
21/03/14 14:43:03 INFO ShutdownHookManager: Shutdown hook called
21/03/14 14:43:03 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-07fc3f73-2724-477c-aa65-ca242cf6e7c4
21/03/14 14:43:03 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-f69487d3-c916-4714-864d-acc4da9e3d22
21/03/14 14:43:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 14:43:07 INFO SparkContext: Running Spark version 2.4.3
21/03/14 14:43:07 INFO SparkContext: Submitted application: sparklyr
21/03/14 14:43:07 INFO SecurityManager: Changing view acls to: nathan
21/03/14 14:43:07 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 14:43:07 INFO SecurityManager: Changing view acls groups to: 
21/03/14 14:43:07 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 14:43:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 14:43:07 INFO Utils: Successfully started service 'sparkDriver' on port 58690.
21/03/14 14:43:07 INFO SparkEnv: Registering MapOutputTracker
21/03/14 14:43:07 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 14:43:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 14:43:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 14:43:07 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-f44cd6d0-616f-4fc3-a720-e55bd9318fee
21/03/14 14:43:07 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 14:43:07 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 14:43:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 14:43:08 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 14:43:08 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:58690/jars/sparklyr-2.4-2.11.jar with timestamp 1615729388263
21/03/14 14:43:08 INFO Executor: Starting executor ID driver on host localhost
21/03/14 14:43:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58691.
21/03/14 14:43:08 INFO NettyBlockTransferService: Server created on localhost:58691
21/03/14 14:43:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 14:43:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 58691, None)
21/03/14 14:43:08 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58691 with 912.3 MB RAM, BlockManagerId(driver, localhost, 58691, None)
21/03/14 14:43:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 58691, None)
21/03/14 14:43:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 58691, None)
21/03/14 14:43:08 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 14:43:09 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 14:43:09 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 14:43:09 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 14:43:13 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 14:43:15 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 14:43:15 INFO ObjectStore: ObjectStore, initialize called
21/03/14 14:43:15 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 14:43:15 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 14:43:17 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 14:43:19 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:43:19 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:43:20 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:43:20 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:43:20 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 14:43:20 INFO ObjectStore: Initialized ObjectStore
21/03/14 14:43:21 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 14:43:21 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 14:43:21 INFO HiveMetaStore: Added admin role in metastore
21/03/14 14:43:21 INFO HiveMetaStore: Added public role in metastore
21/03/14 14:43:21 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 14:43:21 INFO HiveMetaStore: 0: get_all_databases
21/03/14 14:43:21 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 14:43:21 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:43:21 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:43:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:43:21 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/281c9471-8376-47b9-b065-218d21d4732d_resources
21/03/14 14:43:21 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/281c9471-8376-47b9-b065-218d21d4732d
21/03/14 14:43:21 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/281c9471-8376-47b9-b065-218d21d4732d
21/03/14 14:43:21 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/281c9471-8376-47b9-b065-218d21d4732d/_tmp_space.db
21/03/14 14:43:21 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 14:43:21 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:43:21 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:43:21 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:21 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:22 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:43:22 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
21/03/14 14:43:22 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 14:43:22 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:43:23 INFO CodeGenerator: Code generated in 377.279442 ms
21/03/14 14:43:23 INFO CodeGenerator: Code generated in 34.412207 ms
21/03/14 14:43:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 284.3 KB, free 912.0 MB)
21/03/14 14:43:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.9 KB, free 912.0 MB)
21/03/14 14:43:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58691 (size: 23.9 KB, free: 912.3 MB)
21/03/14 14:43:23 INFO SparkContext: Created broadcast 0 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 14:43:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:43:23 INFO SparkContext: Starting job: createTable at NativeMethodAccessorImpl.java:0
21/03/14 14:43:23 INFO DAGScheduler: Got job 0 (createTable at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:43:23 INFO DAGScheduler: Final stage: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0)
21/03/14 14:43:23 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:43:23 INFO DAGScheduler: Missing parents: List()
21/03/14 14:43:23 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:43:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 912.0 MB)
21/03/14 14:43:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.0 MB)
21/03/14 14:43:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58691 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:43:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 14:43:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8362 bytes)
21/03/14 14:43:23 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 14:43:23 INFO Executor: Fetching spark://localhost:58690/jars/sparklyr-2.4-2.11.jar with timestamp 1615729388263
21/03/14 14:43:24 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:58690 after 27 ms (0 ms spent in bootstraps)
21/03/14 14:43:24 INFO Utils: Fetching spark://localhost:58690/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-c9f80af7-0bf5-42bd-9416-11ef1d4ba071/userFiles-82501a42-e975-40eb-9a68-45bcde1a1908/fetchFileTemp1520594629851858727.tmp
21/03/14 14:43:24 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-c9f80af7-0bf5-42bd-9416-11ef1d4ba071/userFiles-82501a42-e975-40eb-9a68-45bcde1a1908/sparklyr-2.4-2.11.jar to class loader
21/03/14 14:43:24 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpFXZ7Dv/file150a8442231fb, range: 0-1303, partition values: [empty row]
21/03/14 14:43:24 INFO CodeGenerator: Code generated in 14.001461 ms
21/03/14 14:43:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1329 bytes result sent to driver
21/03/14 14:43:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 368 ms on localhost (executor driver) (1/1)
21/03/14 14:43:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 14:43:24 INFO DAGScheduler: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0) finished in 0.497 s
21/03/14 14:43:24 INFO DAGScheduler: Job 0 finished: createTable at NativeMethodAccessorImpl.java:0, took 0.570480 s
21/03/14 14:43:24 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:43:24 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 14:43:24 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 14:43:24 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:43:24 INFO CodeGenerator: Code generated in 9.142748 ms
21/03/14 14:43:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 284.3 KB, free 911.7 MB)
21/03/14 14:43:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.7 MB)
21/03/14 14:43:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58691 (size: 23.9 KB, free: 912.2 MB)
21/03/14 14:43:24 INFO SparkContext: Created broadcast 2 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 14:43:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:43:24 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:43:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:43:24 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:24 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:43:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:43:24 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:24 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `default`.`mtcars` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.
21/03/14 14:43:24 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:43:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:43:24 INFO HiveMetaStore: 0: create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615729391, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpFXZ7Dv/file150a8442231fb, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
21/03/14 14:43:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615729391, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpFXZ7Dv/file150a8442231fb, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
21/03/14 14:43:24 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__
21/03/14 14:43:25 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 14:43:25 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 14:43:25 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 14:43:25 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:25 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:25 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:25 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:25 INFO CodeGenerator: Code generated in 19.668335 ms
21/03/14 14:43:26 INFO CodeGenerator: Code generated in 14.684992 ms
21/03/14 14:43:26 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:43:26 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:43:26 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 14:43:26 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:43:26 INFO DAGScheduler: Missing parents: List()
21/03/14 14:43:26 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135), which has no missing parents
21/03/14 14:43:26 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.5 KB, free 911.7 MB)
21/03/14 14:43:26 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 14:43:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:58691 (size: 3.3 KB, free: 912.2 MB)
21/03/14 14:43:26 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 14:43:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:43:26 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 14:43:26 INFO CodeGenerator: Code generated in 9.41527 ms
21/03/14 14:43:26 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 14:43:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on localhost (executor driver) (1/1)
21/03/14 14:43:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 14:43:26 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.042 s
21/03/14 14:43:26 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.047494 s
21/03/14 14:43:26 INFO CodeGenerator: Code generated in 21.658674 ms
21/03/14 14:43:26 INFO CodeGenerator: Code generated in 13.275366 ms
21/03/14 14:43:26 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:43:26 INFO DAGScheduler: Registering RDD 16 (count at utils.scala:135)
21/03/14 14:43:26 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 14:43:26 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 14:43:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 14:43:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 14:43:26 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135), which has no missing parents
21/03/14 14:43:26 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.4 KB, free 911.7 MB)
21/03/14 14:43:26 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.7 MB)
21/03/14 14:43:26 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:58691 (size: 4.5 KB, free: 912.2 MB)
21/03/14 14:43:26 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:26 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 14:43:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:43:26 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 14:43:26 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 14:43:26 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 80 ms on localhost (executor driver) (1/1)
21/03/14 14:43:26 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 14:43:26 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.103 s
21/03/14 14:43:26 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:43:26 INFO DAGScheduler: running: Set()
21/03/14 14:43:26 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 14:43:26 INFO DAGScheduler: failed: Set()
21/03/14 14:43:26 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135), which has no missing parents
21/03/14 14:43:26 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 14:43:26 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 14:43:26 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:58691 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:43:26 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:26 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 14:43:26 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:43:26 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 14:43:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:43:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
21/03/14 14:43:26 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 14:43:26 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 80 ms on localhost (executor driver) (1/1)
21/03/14 14:43:26 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 14:43:26 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.112 s
21/03/14 14:43:26 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.258935 s
21/03/14 14:43:26 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:26 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:26 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:26 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:26 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:26 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:26 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:26 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:27 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:43:27 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 14:43:27 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 14:43:27 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:43:27 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:27 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:27 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:27 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:27 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:27 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:27 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:27 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:27 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:43:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:43:27 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:43:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:43:27 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 14:43:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 14:43:27 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:43:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:43:27 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:27 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:27 INFO CodeGenerator: Code generated in 48.318617 ms
21/03/14 14:43:27 INFO CodeGenerator: Code generated in 22.103617 ms
21/03/14 14:43:27 INFO CodeGenerator: Code generated in 25.181481 ms
21/03/14 14:43:27 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:43:27 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135)
21/03/14 14:43:27 INFO DAGScheduler: Got job 3 (count at utils.scala:135) with 1 output partitions
21/03/14 14:43:27 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/03/14 14:43:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 14:43:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 14:43:27 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/03/14 14:43:27 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.9 KB, free 911.6 MB)
21/03/14 14:43:27 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.2 KB, free 911.6 MB)
21/03/14 14:43:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:58691 (size: 4.2 KB, free: 912.2 MB)
21/03/14 14:43:27 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:27 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 14:43:27 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 14:43:27 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 14:43:27 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1499 bytes result sent to driver
21/03/14 14:43:27 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 14 ms on localhost (executor driver) (1/1)
21/03/14 14:43:27 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 14:43:27 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.022 s
21/03/14 14:43:27 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:43:27 INFO DAGScheduler: running: Set()
21/03/14 14:43:27 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 14:43:27 INFO DAGScheduler: failed: Set()
21/03/14 14:43:27 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/03/14 14:43:27 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 14:43:27 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 14:43:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:58691 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:43:27 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:27 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 14:43:27 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:43:27 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 14:43:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:43:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:43:27 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1782 bytes result sent to driver
21/03/14 14:43:27 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:43:27 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 14:43:27 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.015 s
21/03/14 14:43:27 INFO DAGScheduler: Job 3 finished: count at utils.scala:135, took 0.043855 s
21/03/14 14:43:28 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:28 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:43:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:43:28 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:28 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:28 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:28 INFO HiveMetaStore: 0: get_table : db=default tbl=fake_table
21/03/14 14:43:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=fake_table	
21/03/14 14:43:28 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:28 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:28 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 183
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 178
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 10
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 147
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 12
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 86
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 160
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 119
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 91
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 180
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 71
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 114
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 85
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 154
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 75
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 109
21/03/14 14:43:28 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:43:28 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 14:43:28 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 14:43:28 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:43:28 INFO ContextCleaner: Cleaned shuffle 1
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 174
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 110
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 8
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 134
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 29
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 21
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 132
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 122
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 151
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 118
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 14
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 144
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 169
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 120
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 130
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 98
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 171
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 36
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 142
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 181
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 131
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 165
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 187
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 79
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 127
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 80
21/03/14 14:43:28 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:28 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:58691 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:43:28 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:58691 in memory (size: 3.3 KB, free: 912.2 MB)
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 101
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 182
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 158
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 167
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 16
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 26
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 149
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 15
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 135
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 6
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 189
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 124
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 92
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 113
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 73
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 68
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 112
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 77
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 76
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 19
21/03/14 14:43:28 INFO ContextCleaner: Cleaned shuffle 0
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 194
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 188
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 168
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 150
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 103
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 152
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 90
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 157
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 170
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 78
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 111
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 121
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 186
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 28
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 192
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 140
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 95
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 123
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 100
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 143
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 162
21/03/14 14:43:28 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:58691 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 184
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 9
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 88
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 99
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 84
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 67
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 23
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 163
21/03/14 14:43:28 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:58691 in memory (size: 4.2 KB, free: 912.2 MB)
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 81
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 64
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 74
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 179
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 102
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 65
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 106
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 66
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 153
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 89
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 104
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 72
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 137
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 37
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 25
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 24
21/03/14 14:43:28 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:58691 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 161
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 139
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 17
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 93
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 128
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 141
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 129
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 185
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 82
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 125
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 145
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 83
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 116
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 175
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 172
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 97
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 156
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 115
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 108
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 176
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 27
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 117
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 11
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 87
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 126
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 30
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 22
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 166
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 173
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 155
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 159
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 191
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 190
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 177
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 94
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 138
21/03/14 14:43:28 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:58691 in memory (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 7
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 107
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 13
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 164
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 148
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 193
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 96
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 18
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 133
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 146
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 105
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 70
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 136
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 69
21/03/14 14:43:28 INFO ContextCleaner: Cleaned accumulator 20
21/03/14 14:43:28 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:43:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:43:28 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:43:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:43:28 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 14:43:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 14:43:28 INFO CodeGenerator: Code generated in 7.590876 ms
21/03/14 14:43:28 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 14:43:28 INFO DAGScheduler: Got job 4 (collect at utils.scala:61) with 1 output partitions
21/03/14 14:43:28 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:61)
21/03/14 14:43:28 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:43:28 INFO DAGScheduler: Missing parents: List()
21/03/14 14:43:28 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[31] at map at utils.scala:54), which has no missing parents
21/03/14 14:43:28 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 6.0 KB, free 911.7 MB)
21/03/14 14:43:28 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.4 KB, free 911.7 MB)
21/03/14 14:43:28 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:58691 (size: 3.4 KB, free: 912.3 MB)
21/03/14 14:43:28 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[31] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:28 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 14:43:28 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
21/03/14 14:43:28 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 14:43:28 INFO CodeGenerator: Code generated in 8.7975 ms
21/03/14 14:43:28 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 979 bytes result sent to driver
21/03/14 14:43:28 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 19 ms on localhost (executor driver) (1/1)
21/03/14 14:43:28 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 14:43:28 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:61) finished in 0.026 s
21/03/14 14:43:28 INFO DAGScheduler: Job 4 finished: collect at utils.scala:61, took 0.029651 s
21/03/14 14:43:28 INFO CodeGenerator: Code generated in 10.249817 ms
21/03/14 14:43:28 INFO CodeGenerator: Code generated in 9.421397 ms
21/03/14 14:43:28 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:43:28 INFO DAGScheduler: Got job 5 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:43:28 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:135)
21/03/14 14:43:28 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:43:28 INFO DAGScheduler: Missing parents: List()
21/03/14 14:43:28 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[35] at collect at utils.scala:135), which has no missing parents
21/03/14 14:43:28 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 6.3 KB, free 911.7 MB)
21/03/14 14:43:28 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 14:43:28 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:58691 (size: 3.3 KB, free: 912.2 MB)
21/03/14 14:43:28 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:28 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/14 14:43:28 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:43:28 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 14:43:28 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1286 bytes result sent to driver
21/03/14 14:43:28 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (executor driver) (1/1)
21/03/14 14:43:28 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 14:43:28 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:135) finished in 0.014 s
21/03/14 14:43:28 INFO DAGScheduler: Job 5 finished: collect at utils.scala:135, took 0.016445 s
21/03/14 14:43:28 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:43:28 INFO DAGScheduler: Registering RDD 38 (count at utils.scala:135)
21/03/14 14:43:28 INFO DAGScheduler: Got job 6 (count at utils.scala:135) with 1 output partitions
21/03/14 14:43:28 INFO DAGScheduler: Final stage: ResultStage 9 (count at utils.scala:135)
21/03/14 14:43:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/03/14 14:43:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
21/03/14 14:43:28 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[38] at count at utils.scala:135), which has no missing parents
21/03/14 14:43:28 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.4 KB, free 911.7 MB)
21/03/14 14:43:28 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.7 MB)
21/03/14 14:43:28 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:58691 (size: 4.5 KB, free: 912.2 MB)
21/03/14 14:43:28 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[38] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:28 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 14:43:28 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:43:28 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/03/14 14:43:29 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1542 bytes result sent to driver
21/03/14 14:43:29 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 10 ms on localhost (executor driver) (1/1)
21/03/14 14:43:29 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 14:43:29 INFO DAGScheduler: ShuffleMapStage 8 (count at utils.scala:135) finished in 0.018 s
21/03/14 14:43:29 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:43:29 INFO DAGScheduler: running: Set()
21/03/14 14:43:29 INFO DAGScheduler: waiting: Set(ResultStage 9)
21/03/14 14:43:29 INFO DAGScheduler: failed: Set()
21/03/14 14:43:29 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[41] at count at utils.scala:135), which has no missing parents
21/03/14 14:43:29 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 14:43:29 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 14:43:29 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:58691 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:43:29 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[41] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:29 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 14:43:29 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:43:29 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/03/14 14:43:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:43:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:43:29 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1782 bytes result sent to driver
21/03/14 14:43:29 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 8 ms on localhost (executor driver) (1/1)
21/03/14 14:43:29 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 14:43:29 INFO DAGScheduler: ResultStage 9 (count at utils.scala:135) finished in 0.015 s
21/03/14 14:43:29 INFO DAGScheduler: Job 6 finished: count at utils.scala:135, took 0.038570 s
21/03/14 14:43:29 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:43:29 INFO DAGScheduler: Got job 7 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:43:29 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:135)
21/03/14 14:43:29 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:43:29 INFO DAGScheduler: Missing parents: List()
21/03/14 14:43:29 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[44] at collect at utils.scala:135), which has no missing parents
21/03/14 14:43:29 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 6.3 KB, free 911.7 MB)
21/03/14 14:43:29 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.6 MB)
21/03/14 14:43:29 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:58691 (size: 3.3 KB, free: 912.2 MB)
21/03/14 14:43:29 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[44] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:29 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/03/14 14:43:29 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:43:29 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/03/14 14:43:29 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1286 bytes result sent to driver
21/03/14 14:43:29 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:43:29 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/03/14 14:43:29 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:135) finished in 0.014 s
21/03/14 14:43:29 INFO DAGScheduler: Job 7 finished: collect at utils.scala:135, took 0.016646 s
21/03/14 14:43:29 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:43:29 INFO DAGScheduler: Registering RDD 47 (count at utils.scala:135)
21/03/14 14:43:29 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/03/14 14:43:29 INFO DAGScheduler: Final stage: ResultStage 12 (count at utils.scala:135)
21/03/14 14:43:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
21/03/14 14:43:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
21/03/14 14:43:29 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[47] at count at utils.scala:135), which has no missing parents
21/03/14 14:43:29 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.4 KB, free 911.6 MB)
21/03/14 14:43:29 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.6 MB)
21/03/14 14:43:29 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:58691 (size: 4.5 KB, free: 912.2 MB)
21/03/14 14:43:29 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[47] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:29 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/03/14 14:43:29 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:43:29 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/03/14 14:43:29 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1499 bytes result sent to driver
21/03/14 14:43:29 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 10 ms on localhost (executor driver) (1/1)
21/03/14 14:43:29 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/03/14 14:43:29 INFO DAGScheduler: ShuffleMapStage 11 (count at utils.scala:135) finished in 0.017 s
21/03/14 14:43:29 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:43:29 INFO DAGScheduler: running: Set()
21/03/14 14:43:29 INFO DAGScheduler: waiting: Set(ResultStage 12)
21/03/14 14:43:29 INFO DAGScheduler: failed: Set()
21/03/14 14:43:29 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[50] at count at utils.scala:135), which has no missing parents
21/03/14 14:43:29 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 14:43:29 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 14:43:29 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:58691 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:43:29 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[50] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:29 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/03/14 14:43:29 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:43:29 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/03/14 14:43:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:43:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:43:29 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1782 bytes result sent to driver
21/03/14 14:43:29 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 9 ms on localhost (executor driver) (1/1)
21/03/14 14:43:29 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/03/14 14:43:29 INFO DAGScheduler: ResultStage 12 (count at utils.scala:135) finished in 0.016 s
21/03/14 14:43:29 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.041957 s
21/03/14 14:43:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:29 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:43:29 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 14:43:29 INFO FileSourceStrategy: Output Data Schema: struct<>
21/03/14 14:43:29 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:43:29 INFO CodeGenerator: Code generated in 12.150013 ms
21/03/14 14:43:29 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 284.5 KB, free 911.3 MB)
21/03/14 14:43:29 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.3 MB)
21/03/14 14:43:29 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:58691 (size: 23.9 KB, free: 912.2 MB)
21/03/14 14:43:29 INFO SparkContext: Created broadcast 15 from count at NativeMethodAccessorImpl.java:0
21/03/14 14:43:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:43:29 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 14:43:29 INFO DAGScheduler: Registering RDD 53 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:43:29 INFO DAGScheduler: Got job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:43:29 INFO DAGScheduler: Final stage: ResultStage 14 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:43:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/03/14 14:43:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/03/14 14:43:29 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:43:29 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 14.2 KB, free 911.3 MB)
21/03/14 14:43:29 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.3 MB)
21/03/14 14:43:29 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:58691 (size: 8.0 KB, free: 912.2 MB)
21/03/14 14:43:29 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:29 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/03/14 14:43:29 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 14:43:29 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/03/14 14:43:29 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpFXZ7Dv/file150a8442231fb, range: 0-1303, partition values: [empty row]
21/03/14 14:43:29 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1585 bytes result sent to driver
21/03/14 14:43:29 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 39 ms on localhost (executor driver) (1/1)
21/03/14 14:43:29 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/03/14 14:43:29 INFO DAGScheduler: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.062 s
21/03/14 14:43:29 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:43:29 INFO DAGScheduler: running: Set()
21/03/14 14:43:29 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/03/14 14:43:29 INFO DAGScheduler: failed: Set()
21/03/14 14:43:29 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:43:29 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 14:43:29 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 14:43:29 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:58691 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:43:29 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:29 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/03/14 14:43:29 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:43:29 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/03/14 14:43:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:43:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:43:29 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1782 bytes result sent to driver
21/03/14 14:43:29 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:43:29 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/03/14 14:43:29 INFO DAGScheduler: ResultStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0.014 s
21/03/14 14:43:29 INFO DAGScheduler: Job 9 finished: count at NativeMethodAccessorImpl.java:0, took 0.081272 s
21/03/14 14:43:29 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:43:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:43:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:43:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:43:30 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:43:30 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 14:43:30 INFO FileSourceStrategy: Output Data Schema: struct<>
21/03/14 14:43:30 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:43:30 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 284.5 KB, free 911.0 MB)
21/03/14 14:43:30 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.0 MB)
21/03/14 14:43:30 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:58691 (size: 23.9 KB, free: 912.2 MB)
21/03/14 14:43:30 INFO SparkContext: Created broadcast 18 from count at NativeMethodAccessorImpl.java:0
21/03/14 14:43:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:43:30 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 14:43:30 INFO DAGScheduler: Registering RDD 59 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:43:30 INFO DAGScheduler: Got job 10 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:43:30 INFO DAGScheduler: Final stage: ResultStage 16 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:43:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
21/03/14 14:43:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
21/03/14 14:43:30 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:43:30 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 14.2 KB, free 911.0 MB)
21/03/14 14:43:30 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
21/03/14 14:43:30 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:58691 (size: 8.0 KB, free: 912.2 MB)
21/03/14 14:43:30 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:30 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/03/14 14:43:30 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 14:43:30 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/03/14 14:43:30 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpFXZ7Dv/file150a8442231fb, range: 0-2539, partition values: [empty row]
21/03/14 14:43:30 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1585 bytes result sent to driver
21/03/14 14:43:30 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 15 ms on localhost (executor driver) (1/1)
21/03/14 14:43:30 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/03/14 14:43:30 INFO DAGScheduler: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.027 s
21/03/14 14:43:30 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:43:30 INFO DAGScheduler: running: Set()
21/03/14 14:43:30 INFO DAGScheduler: waiting: Set(ResultStage 16)
21/03/14 14:43:30 INFO DAGScheduler: failed: Set()
21/03/14 14:43:30 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:43:30 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.1 KB, free 911.0 MB)
21/03/14 14:43:30 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.0 MB)
21/03/14 14:43:30 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:58691 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:43:30 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:30 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/03/14 14:43:30 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:43:30 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/03/14 14:43:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:43:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:43:30 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1782 bytes result sent to driver
21/03/14 14:43:30 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:43:30 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/03/14 14:43:30 INFO DAGScheduler: ResultStage 16 (count at NativeMethodAccessorImpl.java:0) finished in 0.014 s
21/03/14 14:43:30 INFO DAGScheduler: Job 10 finished: count at NativeMethodAccessorImpl.java:0, took 0.047677 s
21/03/14 14:43:30 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 14:43:30 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 14:43:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 14:43:30 INFO MemoryStore: MemoryStore cleared
21/03/14 14:43:30 INFO BlockManager: BlockManager stopped
21/03/14 14:43:30 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 14:43:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 14:43:30 INFO SparkContext: Successfully stopped SparkContext
21/03/14 14:43:30 INFO ShutdownHookManager: Shutdown hook called
21/03/14 14:43:30 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-b434204d-42d6-4be1-98b8-a84b0bd5fc6f
21/03/14 14:43:30 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-c9f80af7-0bf5-42bd-9416-11ef1d4ba071
21/03/14 14:43:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 14:43:35 INFO SparkContext: Running Spark version 2.4.3
21/03/14 14:43:35 INFO SparkContext: Submitted application: sparklyr
21/03/14 14:43:35 INFO SecurityManager: Changing view acls to: nathan
21/03/14 14:43:35 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 14:43:35 INFO SecurityManager: Changing view acls groups to: 
21/03/14 14:43:35 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 14:43:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 14:43:35 INFO Utils: Successfully started service 'sparkDriver' on port 58844.
21/03/14 14:43:35 INFO SparkEnv: Registering MapOutputTracker
21/03/14 14:43:35 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 14:43:35 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 14:43:35 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 14:43:35 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-275b2093-5c44-4f00-81aa-2576cb942f27
21/03/14 14:43:35 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 14:43:35 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 14:43:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 14:43:36 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 14:43:36 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:58844/jars/sparklyr-2.4-2.11.jar with timestamp 1615729416411
21/03/14 14:43:36 INFO Executor: Starting executor ID driver on host localhost
21/03/14 14:43:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58857.
21/03/14 14:43:36 INFO NettyBlockTransferService: Server created on localhost:58857
21/03/14 14:43:36 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 14:43:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 58857, None)
21/03/14 14:43:36 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58857 with 912.3 MB RAM, BlockManagerId(driver, localhost, 58857, None)
21/03/14 14:43:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 58857, None)
21/03/14 14:43:36 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 58857, None)
21/03/14 14:43:37 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 14:43:37 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 14:43:37 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 14:43:38 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 14:43:41 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 14:43:42 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 14:43:42 INFO ObjectStore: ObjectStore, initialize called
21/03/14 14:43:42 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 14:43:42 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 14:43:45 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 14:43:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:43:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:43:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:43:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:43:47 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 14:43:47 INFO ObjectStore: Initialized ObjectStore
21/03/14 14:43:47 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 14:43:47 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 14:43:47 INFO HiveMetaStore: Added admin role in metastore
21/03/14 14:43:47 INFO HiveMetaStore: Added public role in metastore
21/03/14 14:43:47 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 14:43:48 INFO HiveMetaStore: 0: get_all_databases
21/03/14 14:43:48 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 14:43:48 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:43:48 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:43:48 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:43:48 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/7a94567c-9259-4027-85b8-3efa49ab516e_resources
21/03/14 14:43:48 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/7a94567c-9259-4027-85b8-3efa49ab516e
21/03/14 14:43:48 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/7a94567c-9259-4027-85b8-3efa49ab516e
21/03/14 14:43:48 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/7a94567c-9259-4027-85b8-3efa49ab516e/_tmp_space.db
21/03/14 14:43:48 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 14:43:48 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:43:48 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:43:48 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 14:43:48 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 14:43:48 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 14:43:48 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:43:48 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:43:48 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:43:48 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:43:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 14:43:48 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 14:43:48 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 14:43:48 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/03/14 14:43:48 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/03/14 14:43:48 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:43:48 INFO DAGScheduler: Missing parents: List()
21/03/14 14:43:49 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/03/14 14:43:49 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/03/14 14:43:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/03/14 14:43:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58857 (size: 3.4 KB, free: 912.3 MB)
21/03/14 14:43:49 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:49 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 14:43:49 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/03/14 14:43:49 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 14:43:49 INFO Executor: Fetching spark://localhost:58844/jars/sparklyr-2.4-2.11.jar with timestamp 1615729416411
21/03/14 14:43:49 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:58844 after 26 ms (0 ms spent in bootstraps)
21/03/14 14:43:49 INFO Utils: Fetching spark://localhost:58844/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-81fa2ab7-3567-425b-8f84-457bba40b1b0/userFiles-aac20bdd-22d2-489b-b9d9-0370c485f58b/fetchFileTemp1732943297711822065.tmp
21/03/14 14:43:49 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-81fa2ab7-3567-425b-8f84-457bba40b1b0/userFiles-aac20bdd-22d2-489b-b9d9-0370c485f58b/sparklyr-2.4-2.11.jar to class loader
21/03/14 14:43:50 INFO CodeGenerator: Code generated in 277.350024 ms
21/03/14 14:43:50 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
21/03/14 14:43:50 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 768 ms on localhost (executor driver) (1/1)
21/03/14 14:43:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 14:43:50 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 1.140 s
21/03/14 14:43:50 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 1.295407 s
21/03/14 14:43:50 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:58857 in memory (size: 3.4 KB, free: 912.3 MB)
21/03/14 14:43:50 INFO ContextCleaner: Cleaned accumulator 0
21/03/14 14:43:51 INFO CodeGenerator: Code generated in 27.746116 ms
21/03/14 14:43:51 INFO CodeGenerator: Code generated in 23.947896 ms
21/03/14 14:43:51 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:43:51 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:43:51 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 14:43:51 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:43:51 INFO DAGScheduler: Missing parents: List()
21/03/14 14:43:51 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/03/14 14:43:51 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 14:43:51 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 14:43:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58857 (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:43:51 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:51 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 14:43:51 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:43:51 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 14:43:51 INFO CodeGenerator: Code generated in 10.85667 ms
21/03/14 14:43:51 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1286 bytes result sent to driver
21/03/14 14:43:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 37 ms on localhost (executor driver) (1/1)
21/03/14 14:43:51 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 14:43:51 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.046 s
21/03/14 14:43:51 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.052165 s
21/03/14 14:43:51 INFO CodeGenerator: Code generated in 31.34918 ms
21/03/14 14:43:51 INFO CodeGenerator: Code generated in 29.175944 ms
21/03/14 14:43:51 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:43:51 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/03/14 14:43:51 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 14:43:51 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 14:43:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 14:43:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 14:43:51 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/03/14 14:43:51 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/03/14 14:43:51 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/03/14 14:43:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58857 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:43:51 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:51 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 14:43:51 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:43:51 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 14:43:51 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 14:43:51 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 71 ms on localhost (executor driver) (1/1)
21/03/14 14:43:51 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 14:43:51 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.097 s
21/03/14 14:43:51 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:43:51 INFO DAGScheduler: running: Set()
21/03/14 14:43:51 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 14:43:51 INFO DAGScheduler: failed: Set()
21/03/14 14:43:51 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/03/14 14:43:51 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:43:51 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:43:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:58857 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:43:51 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:51 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 14:43:51 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:43:51 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 14:43:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:43:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
21/03/14 14:43:52 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1825 bytes result sent to driver
21/03/14 14:43:52 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 67 ms on localhost (executor driver) (1/1)
21/03/14 14:43:52 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 14:43:52 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.082 s
21/03/14 14:43:52 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.214836 s
21/03/14 14:43:52 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:43:52 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:43:52 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/03/14 14:43:52 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:43:52 INFO DAGScheduler: Missing parents: List()
21/03/14 14:43:52 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135), which has no missing parents
21/03/14 14:43:52 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 14:43:52 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 14:43:52 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:58857 (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:43:52 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:52 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 14:43:52 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:43:52 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 14:43:52 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/03/14 14:43:52 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on localhost (executor driver) (1/1)
21/03/14 14:43:52 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 14:43:52 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.016 s
21/03/14 14:43:52 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.019735 s
21/03/14 14:43:52 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:43:52 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:135)
21/03/14 14:43:52 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/14 14:43:52 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/03/14 14:43:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/03/14 14:43:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/03/14 14:43:52 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/03/14 14:43:52 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/03/14 14:43:52 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/03/14 14:43:52 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:58857 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:43:52 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:52 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 14:43:52 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:43:52 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 14:43:52 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/03/14 14:43:52 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 9 ms on localhost (executor driver) (1/1)
21/03/14 14:43:52 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 14:43:52 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.021 s
21/03/14 14:43:52 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:43:52 INFO DAGScheduler: running: Set()
21/03/14 14:43:52 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/03/14 14:43:52 INFO DAGScheduler: failed: Set()
21/03/14 14:43:52 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/03/14 14:43:52 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:43:52 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:43:52 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:58857 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:43:52 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 14:43:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:43:52 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 14:43:52 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:43:52 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 14:43:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:43:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:43:52 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/03/14 14:43:52 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:43:52 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 14:43:52 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.016 s
21/03/14 14:43:52 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.043108 s
21/03/14 14:43:52 INFO HiveMetaStore: 0: get_table : db=default tbl=view
21/03/14 14:43:52 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=view	
21/03/14 14:43:52 INFO HiveMetaStore: 0: get_table : db=default tbl=view
21/03/14 14:43:52 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=view	
21/03/14 14:43:52 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 14:43:52 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 14:43:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 14:43:52 INFO MemoryStore: MemoryStore cleared
21/03/14 14:43:52 INFO BlockManager: BlockManager stopped
21/03/14 14:43:52 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 14:43:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 14:43:52 INFO SparkContext: Successfully stopped SparkContext
21/03/14 14:43:52 INFO ShutdownHookManager: Shutdown hook called
21/03/14 14:43:52 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-2679bc34-bbe5-4fec-bf12-d70807b0e0be
21/03/14 14:43:52 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-81fa2ab7-3567-425b-8f84-457bba40b1b0
21/03/14 14:52:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 14:52:25 INFO SparkContext: Running Spark version 2.4.3
21/03/14 14:52:25 INFO SparkContext: Submitted application: sparklyr
21/03/14 14:52:25 INFO SecurityManager: Changing view acls to: nathan
21/03/14 14:52:25 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 14:52:25 INFO SecurityManager: Changing view acls groups to: 
21/03/14 14:52:25 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 14:52:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 14:52:25 INFO Utils: Successfully started service 'sparkDriver' on port 60107.
21/03/14 14:52:25 INFO SparkEnv: Registering MapOutputTracker
21/03/14 14:52:25 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 14:52:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 14:52:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 14:52:25 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-8845f1f1-7649-497c-b23e-40224b115579
21/03/14 14:52:25 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 14:52:25 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 14:52:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 14:52:26 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 14:52:26 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:60107/jars/sparklyr-2.4-2.11.jar with timestamp 1615729946060
21/03/14 14:52:26 INFO Executor: Starting executor ID driver on host localhost
21/03/14 14:52:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60108.
21/03/14 14:52:26 INFO NettyBlockTransferService: Server created on localhost:60108
21/03/14 14:52:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 14:52:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 60108, None)
21/03/14 14:52:26 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60108 with 912.3 MB RAM, BlockManagerId(driver, localhost, 60108, None)
21/03/14 14:52:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 60108, None)
21/03/14 14:52:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 60108, None)
21/03/14 14:52:26 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 14:52:26 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 14:52:26 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 14:52:27 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 14:52:30 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 14:52:31 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 14:52:31 INFO ObjectStore: ObjectStore, initialize called
21/03/14 14:52:32 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 14:52:32 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 14:52:34 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 14:52:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:52:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:52:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:52:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:52:36 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 14:52:36 INFO ObjectStore: Initialized ObjectStore
21/03/14 14:52:36 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 14:52:37 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 14:52:37 INFO HiveMetaStore: Added admin role in metastore
21/03/14 14:52:37 INFO HiveMetaStore: Added public role in metastore
21/03/14 14:52:37 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 14:52:37 INFO HiveMetaStore: 0: get_all_databases
21/03/14 14:52:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 14:52:37 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:52:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:52:37 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:52:37 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/b7befa65-3bd2-41a5-af49-a62c98b84194_resources
21/03/14 14:52:37 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/b7befa65-3bd2-41a5-af49-a62c98b84194
21/03/14 14:52:37 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/b7befa65-3bd2-41a5-af49-a62c98b84194
21/03/14 14:52:37 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/b7befa65-3bd2-41a5-af49-a62c98b84194/_tmp_space.db
21/03/14 14:52:37 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 14:52:37 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:52:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:52:37 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 14:52:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 14:52:37 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 14:52:37 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:52:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:52:37 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:52:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:52:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 14:52:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 14:52:38 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 14:52:38 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/03/14 14:52:38 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/03/14 14:52:38 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:52:38 INFO DAGScheduler: Missing parents: List()
21/03/14 14:52:38 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/03/14 14:52:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/03/14 14:52:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/03/14 14:52:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60108 (size: 3.4 KB, free: 912.3 MB)
21/03/14 14:52:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 14:52:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 14:52:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 14:52:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/03/14 14:52:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 14:52:39 INFO Executor: Fetching spark://localhost:60107/jars/sparklyr-2.4-2.11.jar with timestamp 1615729946060
21/03/14 14:52:39 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:60107 after 32 ms (0 ms spent in bootstraps)
21/03/14 14:52:39 INFO Utils: Fetching spark://localhost:60107/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-398edd64-1c70-4757-ad13-47190126806c/userFiles-940682cf-8020-4189-947b-5f946dfd6ca0/fetchFileTemp3733610123896637654.tmp
21/03/14 14:52:39 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-398edd64-1c70-4757-ad13-47190126806c/userFiles-940682cf-8020-4189-947b-5f946dfd6ca0/sparklyr-2.4-2.11.jar to class loader
21/03/14 14:52:39 INFO CodeGenerator: Code generated in 287.897695 ms
21/03/14 14:52:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
21/03/14 14:52:40 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 960 ms on localhost (executor driver) (1/1)
21/03/14 14:52:40 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 14:52:40 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 1.618 s
21/03/14 14:52:40 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 2.068874 s
21/03/14 14:52:40 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:60108 in memory (size: 3.4 KB, free: 912.3 MB)
21/03/14 14:52:41 INFO CodeGenerator: Code generated in 27.371094 ms
21/03/14 14:52:41 INFO CodeGenerator: Code generated in 25.063714 ms
21/03/14 14:52:41 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:52:41 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:52:41 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 14:52:41 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:52:41 INFO DAGScheduler: Missing parents: List()
21/03/14 14:52:41 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/03/14 14:52:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 14:52:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 14:52:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60108 (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:52:41 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 14:52:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:52:41 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 14:52:41 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:52:41 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 14:52:41 INFO CodeGenerator: Code generated in 12.065279 ms
21/03/14 14:52:41 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 14:52:41 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 39 ms on localhost (executor driver) (1/1)
21/03/14 14:52:41 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 14:52:41 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.049 s
21/03/14 14:52:41 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.055010 s
21/03/14 14:52:41 INFO CodeGenerator: Code generated in 19.947829 ms
21/03/14 14:52:41 INFO CodeGenerator: Code generated in 22.170154 ms
21/03/14 14:52:41 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:52:41 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/03/14 14:52:41 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 14:52:41 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 14:52:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 14:52:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 14:52:41 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/03/14 14:52:41 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/03/14 14:52:41 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/03/14 14:52:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60108 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:52:41 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 14:52:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:52:41 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 14:52:41 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:52:41 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 14:52:41 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 14:52:41 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 63 ms on localhost (executor driver) (1/1)
21/03/14 14:52:41 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 14:52:41 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.079 s
21/03/14 14:52:41 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:52:41 INFO DAGScheduler: running: Set()
21/03/14 14:52:41 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 14:52:41 INFO DAGScheduler: failed: Set()
21/03/14 14:52:41 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/03/14 14:52:41 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:52:41 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:52:41 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:60108 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:52:41 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 14:52:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:52:41 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 14:52:41 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:52:41 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 14:52:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:52:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
21/03/14 14:52:41 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 14:52:41 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 53 ms on localhost (executor driver) (1/1)
21/03/14 14:52:41 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 14:52:41 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.064 s
21/03/14 14:52:41 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.174993 s
21/03/14 14:52:42 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:52:42 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:52:42 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/03/14 14:52:42 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:52:42 INFO DAGScheduler: Missing parents: List()
21/03/14 14:52:42 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135), which has no missing parents
21/03/14 14:52:42 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 14:52:42 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 14:52:42 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:60108 (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:52:42 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 14:52:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:52:42 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 14:52:42 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:52:42 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 14:52:42 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/03/14 14:52:42 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:52:42 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 14:52:42 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.015 s
21/03/14 14:52:42 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.018670 s
21/03/14 14:52:42 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:52:42 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:135)
21/03/14 14:52:42 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/14 14:52:42 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/03/14 14:52:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/03/14 14:52:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/03/14 14:52:42 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/03/14 14:52:42 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/03/14 14:52:42 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/03/14 14:52:42 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:60108 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:52:42 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 14:52:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:52:42 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 14:52:42 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:52:42 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 14:52:42 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/03/14 14:52:42 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 11 ms on localhost (executor driver) (1/1)
21/03/14 14:52:42 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 14:52:42 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.021 s
21/03/14 14:52:42 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:52:42 INFO DAGScheduler: running: Set()
21/03/14 14:52:42 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/03/14 14:52:42 INFO DAGScheduler: failed: Set()
21/03/14 14:52:42 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/03/14 14:52:42 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:52:42 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:52:42 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:60108 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:52:42 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 14:52:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:52:42 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 14:52:42 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:52:42 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 14:52:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:52:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:52:42 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1825 bytes result sent to driver
21/03/14 14:52:42 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 8 ms on localhost (executor driver) (1/1)
21/03/14 14:52:42 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 14:52:42 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.016 s
21/03/14 14:52:42 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.043184 s
21/03/14 14:52:42 INFO CodeGenerator: Code generated in 45.130686 ms
21/03/14 14:52:43 INFO CodeGenerator: Code generated in 18.634532 ms
21/03/14 14:52:43 INFO CodeGenerator: Code generated in 22.070106 ms
21/03/14 14:52:43 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:52:43 INFO DAGScheduler: Registering RDD 28 (count at utils.scala:135)
21/03/14 14:52:43 INFO DAGScheduler: Got job 5 (count at utils.scala:135) with 1 output partitions
21/03/14 14:52:43 INFO DAGScheduler: Final stage: ResultStage 8 (count at utils.scala:135)
21/03/14 14:52:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
21/03/14 14:52:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
21/03/14 14:52:43 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135), which has no missing parents
21/03/14 14:52:43 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:52:43 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:52:43 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:60108 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:52:43 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 14:52:43 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/03/14 14:52:43 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
21/03/14 14:52:43 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8034 bytes)
21/03/14 14:52:43 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 8, localhost, executor driver, partition 1, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:52:43 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 9, localhost, executor driver, partition 2, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:52:43 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 10, localhost, executor driver, partition 3, PROCESS_LOCAL, 8051 bytes)
21/03/14 14:52:43 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 14:52:43 INFO Executor: Running task 1.0 in stage 7.0 (TID 8)
21/03/14 14:52:43 INFO Executor: Running task 2.0 in stage 7.0 (TID 9)
21/03/14 14:52:43 INFO Executor: Running task 3.0 in stage 7.0 (TID 10)
21/03/14 14:52:43 INFO Executor: Finished task 2.0 in stage 7.0 (TID 9). 1499 bytes result sent to driver
21/03/14 14:52:43 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1499 bytes result sent to driver
21/03/14 14:52:43 INFO Executor: Finished task 3.0 in stage 7.0 (TID 10). 1542 bytes result sent to driver
21/03/14 14:52:43 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 9) in 20 ms on localhost (executor driver) (1/4)
21/03/14 14:52:43 INFO Executor: Finished task 1.0 in stage 7.0 (TID 8). 1499 bytes result sent to driver
21/03/14 14:52:43 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 10) in 19 ms on localhost (executor driver) (2/4)
21/03/14 14:52:43 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 24 ms on localhost (executor driver) (3/4)
21/03/14 14:52:43 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 8) in 22 ms on localhost (executor driver) (4/4)
21/03/14 14:52:43 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 14:52:43 INFO DAGScheduler: ShuffleMapStage 7 (count at utils.scala:135) finished in 0.036 s
21/03/14 14:52:43 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:52:43 INFO DAGScheduler: running: Set()
21/03/14 14:52:43 INFO DAGScheduler: waiting: Set(ResultStage 8)
21/03/14 14:52:43 INFO DAGScheduler: failed: Set()
21/03/14 14:52:43 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135), which has no missing parents
21/03/14 14:52:43 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:52:43 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 27
21/03/14 14:52:43 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:60108 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 169
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 31
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 136
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 204
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 146
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 199
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 196
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 210
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 201
21/03/14 14:52:43 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 105
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 203
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 166
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 104
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 36
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 65
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 152
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 73
21/03/14 14:52:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:52:43 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 14:52:43 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:52:43 INFO Executor: Running task 0.0 in stage 8.0 (TID 11)
21/03/14 14:52:43 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:60108 in memory (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:52:43 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 14:52:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 96
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 155
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 95
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 108
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 127
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 101
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 202
21/03/14 14:52:43 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:60108 in memory (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:52:43 INFO Executor: Finished task 0.0 in stage 8.0 (TID 11). 1782 bytes result sent to driver
21/03/14 14:52:43 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 11) in 9 ms on localhost (executor driver) (1/1)
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 185
21/03/14 14:52:43 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 70
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 67
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 125
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 176
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 35
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 191
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 109
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 147
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 33
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 144
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 106
21/03/14 14:52:43 INFO DAGScheduler: ResultStage 8 (count at utils.scala:135) finished in 0.033 s
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 71
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 64
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 79
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 162
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 97
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 86
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 77
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 26
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 76
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 207
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 114
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 107
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 157
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 84
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 206
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 134
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 93
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 120
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 115
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 209
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 168
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 195
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 163
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 29
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 183
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 74
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 184
21/03/14 14:52:43 INFO DAGScheduler: Job 5 finished: count at utils.scala:135, took 0.079700 s
21/03/14 14:52:43 INFO ContextCleaner: Cleaned shuffle 0
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 175
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 180
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 122
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 129
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 154
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 158
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 148
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 117
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 150
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 186
21/03/14 14:52:43 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:60108 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 32
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 135
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 177
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 14:52:43 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:60108 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 72
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 164
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 113
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 187
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 149
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 165
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 133
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 145
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 194
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 100
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 193
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 140
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 151
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 178
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 91
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 205
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 78
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 130
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 66
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 112
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 170
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 102
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 198
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 200
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 174
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 143
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 197
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 85
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 110
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 123
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 116
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 173
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 81
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 139
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 14:52:43 INFO ContextCleaner: Cleaned shuffle 1
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 188
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 137
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 208
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 190
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 131
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 124
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 138
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 68
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 212
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 172
21/03/14 14:52:43 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:60108 in memory (size: 3.3 KB, free: 912.3 MB)
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 94
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 160
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 83
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 119
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 37
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 103
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 89
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 80
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 99
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 88
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 75
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 111
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 69
21/03/14 14:52:43 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:60108 in memory (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 128
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 142
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 181
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 182
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 171
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 30
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 179
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 87
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 167
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 92
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 189
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 28
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 161
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 192
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 90
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 82
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 153
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 141
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 34
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 98
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 132
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 126
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 121
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 156
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 159
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 14:52:43 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 14:52:43 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 14:52:43 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 14:52:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 14:52:43 INFO MemoryStore: MemoryStore cleared
21/03/14 14:52:43 INFO BlockManager: BlockManager stopped
21/03/14 14:52:43 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 14:52:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 14:52:43 INFO SparkContext: Successfully stopped SparkContext
21/03/14 14:52:43 INFO ShutdownHookManager: Shutdown hook called
21/03/14 14:52:43 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-398edd64-1c70-4757-ad13-47190126806c
21/03/14 14:52:43 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-3c9bd80e-7855-4906-bc0d-95badf333a6a
21/03/14 14:52:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 14:52:48 INFO SparkContext: Running Spark version 2.4.3
21/03/14 14:52:48 INFO SparkContext: Submitted application: sparklyr
21/03/14 14:52:48 INFO SecurityManager: Changing view acls to: nathan
21/03/14 14:52:48 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 14:52:48 INFO SecurityManager: Changing view acls groups to: 
21/03/14 14:52:48 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 14:52:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 14:52:48 INFO Utils: Successfully started service 'sparkDriver' on port 60275.
21/03/14 14:52:48 INFO SparkEnv: Registering MapOutputTracker
21/03/14 14:52:48 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 14:52:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 14:52:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 14:52:48 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-acb7d12c-9e03-483b-a956-d763a343d6ea
21/03/14 14:52:48 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 14:52:48 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 14:52:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 14:52:48 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 14:52:49 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:60275/jars/sparklyr-2.4-2.11.jar with timestamp 1615729969022
21/03/14 14:52:49 INFO Executor: Starting executor ID driver on host localhost
21/03/14 14:52:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60276.
21/03/14 14:52:49 INFO NettyBlockTransferService: Server created on localhost:60276
21/03/14 14:52:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 14:52:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 60276, None)
21/03/14 14:52:49 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60276 with 912.3 MB RAM, BlockManagerId(driver, localhost, 60276, None)
21/03/14 14:52:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 60276, None)
21/03/14 14:52:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 60276, None)
21/03/14 14:52:49 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 14:52:49 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 14:52:49 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 14:52:51 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 14:52:53 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 14:52:54 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 14:52:54 INFO ObjectStore: ObjectStore, initialize called
21/03/14 14:52:54 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 14:52:54 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 14:52:57 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 14:52:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:52:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:53:01 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:53:01 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:53:01 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 14:53:01 INFO ObjectStore: Initialized ObjectStore
21/03/14 14:53:01 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 14:53:02 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 14:53:02 INFO HiveMetaStore: Added admin role in metastore
21/03/14 14:53:02 INFO HiveMetaStore: Added public role in metastore
21/03/14 14:53:02 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 14:53:02 INFO HiveMetaStore: 0: get_all_databases
21/03/14 14:53:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 14:53:02 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:53:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:53:02 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:53:02 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/435d43da-7c19-45a2-a0b6-ffef4c89c4c2_resources
21/03/14 14:53:02 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/435d43da-7c19-45a2-a0b6-ffef4c89c4c2
21/03/14 14:53:02 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/435d43da-7c19-45a2-a0b6-ffef4c89c4c2
21/03/14 14:53:02 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/435d43da-7c19-45a2-a0b6-ffef4c89c4c2/_tmp_space.db
21/03/14 14:53:02 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 14:53:02 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:53:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:53:02 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:53:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:53:02 INFO HiveMetaStore: 0: get_database: fake_database
21/03/14 14:53:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: fake_database	
21/03/14 14:53:02 WARN ObjectStore: Failed to get database fake_database, returning NoSuchObjectException
21/03/14 14:53:02 INFO HiveMetaStore: 0: get_databases: *
21/03/14 14:53:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_databases: *	
21/03/14 14:53:02 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:53:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:53:02 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:53:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:53:04 INFO CodeGenerator: Code generated in 495.402461 ms
21/03/14 14:53:05 INFO CodeGenerator: Code generated in 20.763283 ms
21/03/14 14:53:05 INFO CodeGenerator: Code generated in 24.614405 ms
21/03/14 14:53:06 INFO CodeGenerator: Code generated in 32.274358 ms
21/03/14 14:53:06 INFO CodeGenerator: Code generated in 13.748019 ms
21/03/14 14:53:06 INFO CodeGenerator: Code generated in 13.449373 ms
21/03/14 14:53:06 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:53:06 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:135)
21/03/14 14:53:06 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/03/14 14:53:06 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/03/14 14:53:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/03/14 14:53:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/03/14 14:53:06 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135), which has no missing parents
21/03/14 14:53:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 14:53:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 14:53:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60276 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:53:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 14:53:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:53:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 14:53:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 14:53:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 14:53:06 INFO Executor: Fetching spark://localhost:60275/jars/sparklyr-2.4-2.11.jar with timestamp 1615729969022
21/03/14 14:53:06 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:60275 after 36 ms (0 ms spent in bootstraps)
21/03/14 14:53:06 INFO Utils: Fetching spark://localhost:60275/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-2220350f-8d16-4f90-8c57-d74ddc987a10/userFiles-5b552d48-fd22-4717-8ffe-ff4052f17d0f/fetchFileTemp8686615754464189789.tmp
21/03/14 14:53:07 INFO ContextCleaner: Cleaned accumulator 1
21/03/14 14:53:07 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-2220350f-8d16-4f90-8c57-d74ddc987a10/userFiles-5b552d48-fd22-4717-8ffe-ff4052f17d0f/sparklyr-2.4-2.11.jar to class loader
21/03/14 14:53:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1585 bytes result sent to driver
21/03/14 14:53:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 605 ms on localhost (executor driver) (1/1)
21/03/14 14:53:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 14:53:07 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:135) finished in 0.925 s
21/03/14 14:53:07 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:53:07 INFO DAGScheduler: running: Set()
21/03/14 14:53:07 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/03/14 14:53:07 INFO DAGScheduler: failed: Set()
21/03/14 14:53:07 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135), which has no missing parents
21/03/14 14:53:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:53:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:53:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60276 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:53:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 14:53:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:53:07 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 14:53:07 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:53:07 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 14:53:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:53:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
21/03/14 14:53:07 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1782 bytes result sent to driver
21/03/14 14:53:07 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 52 ms on localhost (executor driver) (1/1)
21/03/14 14:53:07 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 14:53:07 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.067 s
21/03/14 14:53:07 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 1.086093 s
21/03/14 14:53:07 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 14:53:07 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 14:53:07 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 14:53:07 INFO HiveMetaStore: 0: create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})
21/03/14 14:53:07 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})	
21/03/14 14:53:07 WARN ObjectStore: Failed to get database catalog_test_database_db, returning NoSuchObjectException
21/03/14 14:53:07 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:53:08 INFO CodeGenerator: Code generated in 10.478216 ms
21/03/14 14:53:08 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:53:08 INFO DAGScheduler: Registering RDD 10 (count at utils.scala:135)
21/03/14 14:53:08 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/03/14 14:53:08 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 14:53:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 14:53:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 14:53:08 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[10] at count at utils.scala:135), which has no missing parents
21/03/14 14:53:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 14:53:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 14:53:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60276 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:53:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 14:53:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[10] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:53:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 14:53:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 14:53:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 14:53:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1499 bytes result sent to driver
21/03/14 14:53:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 14 ms on localhost (executor driver) (1/1)
21/03/14 14:53:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 14:53:08 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.023 s
21/03/14 14:53:08 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:53:08 INFO DAGScheduler: running: Set()
21/03/14 14:53:08 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 14:53:08 INFO DAGScheduler: failed: Set()
21/03/14 14:53:08 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[13] at count at utils.scala:135), which has no missing parents
21/03/14 14:53:08 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:53:08 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:53:08 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:60276 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:53:08 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 14:53:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:53:08 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 14:53:08 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:53:08 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 14:53:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:53:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:53:08 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1775 bytes result sent to driver
21/03/14 14:53:08 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 10 ms on localhost (executor driver) (1/1)
21/03/14 14:53:08 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 14:53:08 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.018 s
21/03/14 14:53:08 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.046995 s
21/03/14 14:53:08 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:53:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:53:08 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:53:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:53:08 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:53:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:53:08 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:53:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:53:08 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:53:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:53:08 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:53:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:53:08 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 14:53:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 14:53:08 INFO HiveMetaStore: 0: drop_database: catalog_test_database_db
21/03/14 14:53:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=drop_database: catalog_test_database_db	
21/03/14 14:53:08 INFO HiveMetaStore: 0: get_all_tables: db=catalog_test_database_db
21/03/14 14:53:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_tables: db=catalog_test_database_db	
21/03/14 14:53:08 INFO HiveMetaStore: 0: get_functions: db=catalog_test_database_db pat=*
21/03/14 14:53:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=catalog_test_database_db pat=*	
21/03/14 14:53:08 INFO ObjectStore: Dropping database catalog_test_database_db along with all tables
21/03/14 14:53:08 INFO hivemetastoressimpl: deleting  file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:53:08 INFO deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
21/03/14 14:53:08 INFO TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
21/03/14 14:53:08 INFO hivemetastoressimpl: Deleted the diretory file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 14:53:08 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:53:08 INFO DAGScheduler: Registering RDD 17 (count at utils.scala:135)
21/03/14 14:53:08 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 14:53:08 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/03/14 14:53:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 14:53:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 14:53:08 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at count at utils.scala:135), which has no missing parents
21/03/14 14:53:08 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 14:53:08 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 14:53:08 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:60276 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:53:08 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 14:53:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:53:08 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 14:53:08 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 14:53:08 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 14:53:08 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1542 bytes result sent to driver
21/03/14 14:53:08 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 10 ms on localhost (executor driver) (1/1)
21/03/14 14:53:08 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 14:53:08 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.020 s
21/03/14 14:53:08 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:53:08 INFO DAGScheduler: running: Set()
21/03/14 14:53:08 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 14:53:08 INFO DAGScheduler: failed: Set()
21/03/14 14:53:08 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[20] at count at utils.scala:135), which has no missing parents
21/03/14 14:53:08 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 14:53:08 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 14:53:08 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:60276 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:53:08 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 14:53:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:53:08 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 14:53:08 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:53:08 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 14:53:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:53:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:53:08 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1775 bytes result sent to driver
21/03/14 14:53:08 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 6 ms on localhost (executor driver) (1/1)
21/03/14 14:53:08 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 14:53:08 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.014 s
21/03/14 14:53:08 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.041276 s
21/03/14 14:53:08 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 14:53:08 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 14:53:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 14:53:08 INFO MemoryStore: MemoryStore cleared
21/03/14 14:53:08 INFO BlockManager: BlockManager stopped
21/03/14 14:53:08 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 14:53:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 14:53:08 INFO SparkContext: Successfully stopped SparkContext
21/03/14 14:53:08 INFO ShutdownHookManager: Shutdown hook called
21/03/14 14:53:08 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-0522c5f2-0f5a-4b29-966d-c1d5c015a5ac
21/03/14 14:53:08 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-2220350f-8d16-4f90-8c57-d74ddc987a10
21/03/14 14:53:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 14:53:13 INFO SparkContext: Running Spark version 2.4.3
21/03/14 14:53:14 INFO SparkContext: Submitted application: sparklyr
21/03/14 14:53:14 INFO SecurityManager: Changing view acls to: nathan
21/03/14 14:53:14 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 14:53:14 INFO SecurityManager: Changing view acls groups to: 
21/03/14 14:53:14 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 14:53:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 14:53:14 INFO Utils: Successfully started service 'sparkDriver' on port 60459.
21/03/14 14:53:14 INFO SparkEnv: Registering MapOutputTracker
21/03/14 14:53:14 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 14:53:14 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 14:53:14 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 14:53:14 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-d0b46842-6ee0-4528-b61b-eff778e0a337
21/03/14 14:53:14 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 14:53:14 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 14:53:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 14:53:14 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 14:53:14 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:60459/jars/sparklyr-2.4-2.11.jar with timestamp 1615729994803
21/03/14 14:53:14 INFO Executor: Starting executor ID driver on host localhost
21/03/14 14:53:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60460.
21/03/14 14:53:15 INFO NettyBlockTransferService: Server created on localhost:60460
21/03/14 14:53:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 14:53:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 60460, None)
21/03/14 14:53:15 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60460 with 912.3 MB RAM, BlockManagerId(driver, localhost, 60460, None)
21/03/14 14:53:15 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 60460, None)
21/03/14 14:53:15 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 60460, None)
21/03/14 14:53:16 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 14:53:16 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 14:53:16 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 14:53:17 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 14:53:19 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 14:53:21 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 14:53:21 INFO ObjectStore: ObjectStore, initialize called
21/03/14 14:53:21 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 14:53:21 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 14:53:24 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 14:53:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:53:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:53:27 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:53:27 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:53:27 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 14:53:27 INFO ObjectStore: Initialized ObjectStore
21/03/14 14:53:28 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 14:53:28 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 14:53:28 INFO HiveMetaStore: Added admin role in metastore
21/03/14 14:53:28 INFO HiveMetaStore: Added public role in metastore
21/03/14 14:53:28 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 14:53:29 INFO HiveMetaStore: 0: get_all_databases
21/03/14 14:53:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 14:53:29 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:53:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:53:29 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:53:29 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/423db430-de41-4b3e-843d-84d7204498dd_resources
21/03/14 14:53:29 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/423db430-de41-4b3e-843d-84d7204498dd
21/03/14 14:53:29 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/423db430-de41-4b3e-843d-84d7204498dd
21/03/14 14:53:29 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/423db430-de41-4b3e-843d-84d7204498dd/_tmp_space.db
21/03/14 14:53:29 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 14:53:29 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:53:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:53:29 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:53:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:53:29 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:53:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:53:29 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:53:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:53:29 INFO HiveMetaStore: 0: get_function: default.catalog_fake_function
21/03/14 14:53:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_function: default.catalog_fake_function	
21/03/14 14:53:29 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:53:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:53:29 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:53:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:53:29 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:53:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:53:29 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:53:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:53:30 INFO CodeGenerator: Code generated in 371.323915 ms
21/03/14 14:53:31 INFO CodeGenerator: Code generated in 29.017148 ms
21/03/14 14:53:31 INFO CodeGenerator: Code generated in 20.107998 ms
21/03/14 14:53:33 INFO CodeGenerator: Code generated in 95.9992 ms
21/03/14 14:53:33 INFO CodeGenerator: Code generated in 31.837887 ms
21/03/14 14:53:33 INFO CodeGenerator: Code generated in 23.86709 ms
21/03/14 14:53:33 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:53:33 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:135)
21/03/14 14:53:33 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/03/14 14:53:33 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/03/14 14:53:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/03/14 14:53:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/03/14 14:53:33 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135), which has no missing parents
21/03/14 14:53:34 INFO ContextCleaner: Cleaned accumulator 1
21/03/14 14:53:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 14:53:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 14:53:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60460 (size: 4.2 KB, free: 912.3 MB)
21/03/14 14:53:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 14:53:34 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/03/14 14:53:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 4 tasks
21/03/14 14:53:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 9258 bytes)
21/03/14 14:53:34 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 9275 bytes)
21/03/14 14:53:34 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 9258 bytes)
21/03/14 14:53:34 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 9275 bytes)
21/03/14 14:53:34 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
21/03/14 14:53:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 14:53:34 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
21/03/14 14:53:34 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
21/03/14 14:53:34 INFO Executor: Fetching spark://localhost:60459/jars/sparklyr-2.4-2.11.jar with timestamp 1615729994803
21/03/14 14:53:34 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:60459 after 30 ms (0 ms spent in bootstraps)
21/03/14 14:53:34 INFO Utils: Fetching spark://localhost:60459/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-9eb33572-f9dd-4ffe-adf5-1dc46f81583f/userFiles-26c85fb6-2e1b-420f-8877-1a0734fb286f/fetchFileTemp7103809044047425993.tmp
21/03/14 14:53:34 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-9eb33572-f9dd-4ffe-adf5-1dc46f81583f/userFiles-26c85fb6-2e1b-420f-8877-1a0734fb286f/sparklyr-2.4-2.11.jar to class loader
21/03/14 14:53:34 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1542 bytes result sent to driver
21/03/14 14:53:34 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1542 bytes result sent to driver
21/03/14 14:53:34 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1542 bytes result sent to driver
21/03/14 14:53:34 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1542 bytes result sent to driver
21/03/14 14:53:34 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 347 ms on localhost (executor driver) (1/4)
21/03/14 14:53:34 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 352 ms on localhost (executor driver) (2/4)
21/03/14 14:53:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 354 ms on localhost (executor driver) (3/4)
21/03/14 14:53:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 382 ms on localhost (executor driver) (4/4)
21/03/14 14:53:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 14:53:34 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:135) finished in 1.025 s
21/03/14 14:53:34 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:53:34 INFO DAGScheduler: running: Set()
21/03/14 14:53:34 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/03/14 14:53:34 INFO DAGScheduler: failed: Set()
21/03/14 14:53:34 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135), which has no missing parents
21/03/14 14:53:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 14:53:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 14:53:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60460 (size: 3.8 KB, free: 912.3 MB)
21/03/14 14:53:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 14:53:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:53:34 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 14:53:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:53:34 INFO Executor: Running task 0.0 in stage 1.0 (TID 4)
21/03/14 14:53:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
21/03/14 14:53:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
21/03/14 14:53:34 INFO Executor: Finished task 0.0 in stage 1.0 (TID 4). 1825 bytes result sent to driver
21/03/14 14:53:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 4) in 78 ms on localhost (executor driver) (1/1)
21/03/14 14:53:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 14:53:34 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.092 s
21/03/14 14:53:34 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 1.248146 s
21/03/14 14:53:35 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 14:53:35 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 14:53:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 14:53:35 INFO MemoryStore: MemoryStore cleared
21/03/14 14:53:35 INFO BlockManager: BlockManager stopped
21/03/14 14:53:35 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 14:53:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 14:53:35 INFO SparkContext: Successfully stopped SparkContext
21/03/14 14:53:35 INFO ShutdownHookManager: Shutdown hook called
21/03/14 14:53:35 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-9eb33572-f9dd-4ffe-adf5-1dc46f81583f
21/03/14 14:53:35 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-ea04067b-7dee-4496-adb8-edb2dabb6def
21/03/14 14:53:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 14:53:42 INFO SparkContext: Running Spark version 2.4.3
21/03/14 14:53:42 INFO SparkContext: Submitted application: sparklyr
21/03/14 14:53:43 INFO SecurityManager: Changing view acls to: nathan
21/03/14 14:53:43 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 14:53:43 INFO SecurityManager: Changing view acls groups to: 
21/03/14 14:53:43 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 14:53:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 14:53:43 INFO Utils: Successfully started service 'sparkDriver' on port 60688.
21/03/14 14:53:43 INFO SparkEnv: Registering MapOutputTracker
21/03/14 14:53:44 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 14:53:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 14:53:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 14:53:44 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-aa7f989a-702e-4084-8893-69beb7ad81f0
21/03/14 14:53:44 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 14:53:44 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 14:53:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 14:53:45 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 14:53:45 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:60688/jars/sparklyr-2.4-2.11.jar with timestamp 1615730025537
21/03/14 14:53:45 INFO Executor: Starting executor ID driver on host localhost
21/03/14 14:53:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60690.
21/03/14 14:53:45 INFO NettyBlockTransferService: Server created on localhost:60690
21/03/14 14:53:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 14:53:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 60690, None)
21/03/14 14:53:45 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60690 with 912.3 MB RAM, BlockManagerId(driver, localhost, 60690, None)
21/03/14 14:53:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 60690, None)
21/03/14 14:53:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 60690, None)
21/03/14 14:53:46 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 14:53:46 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 14:53:46 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 14:53:48 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 14:53:52 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 14:53:53 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 14:53:53 INFO ObjectStore: ObjectStore, initialize called
21/03/14 14:53:53 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 14:53:53 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 14:53:55 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 14:53:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:53:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:53:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:53:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:53:59 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 14:53:59 INFO ObjectStore: Initialized ObjectStore
21/03/14 14:53:59 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 14:53:59 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 14:53:59 INFO HiveMetaStore: Added admin role in metastore
21/03/14 14:53:59 INFO HiveMetaStore: Added public role in metastore
21/03/14 14:53:59 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 14:53:59 INFO HiveMetaStore: 0: get_all_databases
21/03/14 14:53:59 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 14:53:59 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:53:59 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:53:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:54:00 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/c902208c-7332-416d-9652-a49cf76e0cc8_resources
21/03/14 14:54:00 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/c902208c-7332-416d-9652-a49cf76e0cc8
21/03/14 14:54:00 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/c902208c-7332-416d-9652-a49cf76e0cc8
21/03/14 14:54:00 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/c902208c-7332-416d-9652-a49cf76e0cc8/_tmp_space.db
21/03/14 14:54:00 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 14:54:00 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:54:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:54:00 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:00 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:54:00 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
21/03/14 14:54:00 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 14:54:00 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:54:01 INFO CodeGenerator: Code generated in 242.49473 ms
21/03/14 14:54:01 INFO CodeGenerator: Code generated in 135.500703 ms
21/03/14 14:54:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 284.3 KB, free 912.0 MB)
21/03/14 14:54:02 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.9 KB, free 912.0 MB)
21/03/14 14:54:02 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60690 (size: 23.9 KB, free: 912.3 MB)
21/03/14 14:54:02 INFO SparkContext: Created broadcast 0 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 14:54:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:54:02 INFO SparkContext: Starting job: createTable at NativeMethodAccessorImpl.java:0
21/03/14 14:54:02 INFO DAGScheduler: Got job 0 (createTable at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:54:02 INFO DAGScheduler: Final stage: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0)
21/03/14 14:54:02 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:54:02 INFO DAGScheduler: Missing parents: List()
21/03/14 14:54:02 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:54:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 912.0 MB)
21/03/14 14:54:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.0 MB)
21/03/14 14:54:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60690 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:54:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:02 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 14:54:02 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8362 bytes)
21/03/14 14:54:02 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 14:54:02 INFO Executor: Fetching spark://localhost:60688/jars/sparklyr-2.4-2.11.jar with timestamp 1615730025537
21/03/14 14:54:03 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:60688 after 24 ms (0 ms spent in bootstraps)
21/03/14 14:54:03 INFO Utils: Fetching spark://localhost:60688/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-196600a3-0d01-45bb-a02e-9d94231dd241/userFiles-33b9d32e-ae17-4c8c-a675-ae2c277ddf95/fetchFileTemp4403133208557581254.tmp
21/03/14 14:54:03 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-196600a3-0d01-45bb-a02e-9d94231dd241/userFiles-33b9d32e-ae17-4c8c-a675-ae2c277ddf95/sparklyr-2.4-2.11.jar to class loader
21/03/14 14:54:03 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpfUs57X/file154ce37740167, range: 0-1303, partition values: [empty row]
21/03/14 14:54:03 INFO CodeGenerator: Code generated in 16.723038 ms
21/03/14 14:54:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1329 bytes result sent to driver
21/03/14 14:54:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 371 ms on localhost (executor driver) (1/1)
21/03/14 14:54:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 14:54:03 INFO DAGScheduler: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0) finished in 0.538 s
21/03/14 14:54:03 INFO DAGScheduler: Job 0 finished: createTable at NativeMethodAccessorImpl.java:0, took 0.857560 s
21/03/14 14:54:03 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:54:03 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 14:54:03 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 14:54:03 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:54:03 INFO CodeGenerator: Code generated in 12.581009 ms
21/03/14 14:54:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 284.3 KB, free 911.7 MB)
21/03/14 14:54:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.7 MB)
21/03/14 14:54:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60690 (size: 23.9 KB, free: 912.2 MB)
21/03/14 14:54:03 INFO SparkContext: Created broadcast 2 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 14:54:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:54:03 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:54:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:54:03 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:03 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:54:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:54:03 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:03 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `default`.`mtcars` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.
21/03/14 14:54:03 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:54:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:54:03 INFO HiveMetaStore: 0: create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615730030, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpfUs57X/file154ce37740167, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
21/03/14 14:54:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615730030, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpfUs57X/file154ce37740167, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
21/03/14 14:54:03 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__
21/03/14 14:54:04 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 14:54:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 14:54:04 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 14:54:04 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:04 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:05 INFO CodeGenerator: Code generated in 29.332267 ms
21/03/14 14:54:05 INFO CodeGenerator: Code generated in 38.050299 ms
21/03/14 14:54:05 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:54:05 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:54:05 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 14:54:05 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:54:05 INFO DAGScheduler: Missing parents: List()
21/03/14 14:54:05 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135), which has no missing parents
21/03/14 14:54:05 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.5 KB, free 911.7 MB)
21/03/14 14:54:05 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 14:54:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:60690 (size: 3.3 KB, free: 912.2 MB)
21/03/14 14:54:05 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:05 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 14:54:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:54:05 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 14:54:05 INFO CodeGenerator: Code generated in 10.882529 ms
21/03/14 14:54:05 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 14:54:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on localhost (executor driver) (1/1)
21/03/14 14:54:05 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 14:54:05 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.046 s
21/03/14 14:54:05 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.050820 s
21/03/14 14:54:05 INFO CodeGenerator: Code generated in 15.139885 ms
21/03/14 14:54:05 INFO CodeGenerator: Code generated in 15.000907 ms
21/03/14 14:54:05 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:54:05 INFO DAGScheduler: Registering RDD 16 (count at utils.scala:135)
21/03/14 14:54:05 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 14:54:05 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 14:54:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 14:54:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 14:54:05 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135), which has no missing parents
21/03/14 14:54:05 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.4 KB, free 911.7 MB)
21/03/14 14:54:05 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.7 MB)
21/03/14 14:54:05 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:60690 (size: 4.5 KB, free: 912.2 MB)
21/03/14 14:54:05 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 14:54:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:54:05 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 14:54:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1585 bytes result sent to driver
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 14:54:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 121 ms on localhost (executor driver) (1/1)
21/03/14 14:54:05 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 14:54:05 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:60690 in memory (size: 3.3 KB, free: 912.2 MB)
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 14:54:05 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:60690 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 14:54:05 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 14:54:05 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.169 s
21/03/14 14:54:05 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:54:05 INFO DAGScheduler: running: Set()
21/03/14 14:54:05 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 14:54:05 INFO DAGScheduler: failed: Set()
21/03/14 14:54:05 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135), which has no missing parents
21/03/14 14:54:05 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 14:54:05 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 14:54:05 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:60690 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:54:05 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:05 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 14:54:05 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:54:05 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 14:54:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:54:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
21/03/14 14:54:05 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 14:54:05 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 54 ms on localhost (executor driver) (1/1)
21/03/14 14:54:05 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 14:54:05 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.068 s
21/03/14 14:54:05 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.287255 s
21/03/14 14:54:06 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:06 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:06 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:06 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:54:06 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 14:54:06 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 14:54:06 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:54:06 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:06 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:06 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 284.5 KB, free 911.4 MB)
21/03/14 14:54:06 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.4 MB)
21/03/14 14:54:06 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:60690 (size: 23.9 KB, free: 912.2 MB)
21/03/14 14:54:06 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
21/03/14 14:54:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:54:06 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 14:54:06 INFO DAGScheduler: Registering RDD 27 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:54:06 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:54:06 INFO DAGScheduler: Final stage: ResultStage 5 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:54:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 14:54:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 14:54:06 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:54:06 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 911.3 MB)
21/03/14 14:54:06 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 12.2 KB, free 911.3 MB)
21/03/14 14:54:06 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:60690 (size: 12.2 KB, free: 912.2 MB)
21/03/14 14:54:06 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:06 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 14:54:06 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 14:54:06 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 14:54:06 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpfUs57X/file154ce37740167, range: 0-1303, partition values: [empty row]
21/03/14 14:54:06 INFO CodeGenerator: Code generated in 20.235723 ms
21/03/14 14:54:06 INFO MemoryStore: Block rdd_22_0 stored as values in memory (estimated size 4.1 KB, free 911.3 MB)
21/03/14 14:54:06 INFO BlockManagerInfo: Added rdd_22_0 in memory on localhost:60690 (size: 4.1 KB, free: 912.2 MB)
21/03/14 14:54:06 INFO CodeGenerator: Code generated in 6.596432 ms
21/03/14 14:54:06 INFO CodeGenerator: Code generated in 17.141021 ms
21/03/14 14:54:06 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1871 bytes result sent to driver
21/03/14 14:54:06 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 182 ms on localhost (executor driver) (1/1)
21/03/14 14:54:06 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 14:54:06 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.221 s
21/03/14 14:54:06 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:54:06 INFO DAGScheduler: running: Set()
21/03/14 14:54:06 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 14:54:06 INFO DAGScheduler: failed: Set()
21/03/14 14:54:06 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:54:06 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 14:54:06 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 14:54:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:60690 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:54:06 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:06 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 14:54:06 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:54:06 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 14:54:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:54:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:54:06 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1782 bytes result sent to driver
21/03/14 14:54:06 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 10 ms on localhost (executor driver) (1/1)
21/03/14 14:54:06 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 14:54:06 INFO DAGScheduler: ResultStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.017 s
21/03/14 14:54:06 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.246198 s
21/03/14 14:54:06 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:06 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 14:54:06 INFO DAGScheduler: Registering RDD 35 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:54:06 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:54:06 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:54:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
21/03/14 14:54:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
21/03/14 14:54:06 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:54:06 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 25.9 KB, free 911.3 MB)
21/03/14 14:54:06 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.1 KB, free 911.3 MB)
21/03/14 14:54:06 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:60690 (size: 12.1 KB, free: 912.2 MB)
21/03/14 14:54:06 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:06 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 14:54:06 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 14:54:06 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 14:54:06 INFO BlockManager: Found block rdd_22_0 locally
21/03/14 14:54:06 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1914 bytes result sent to driver
21/03/14 14:54:06 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 20 ms on localhost (executor driver) (1/1)
21/03/14 14:54:06 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 14:54:06 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.034 s
21/03/14 14:54:06 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:54:06 INFO DAGScheduler: running: Set()
21/03/14 14:54:06 INFO DAGScheduler: waiting: Set(ResultStage 7)
21/03/14 14:54:06 INFO DAGScheduler: failed: Set()
21/03/14 14:54:06 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:54:06 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 14:54:06 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 14:54:06 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:60690 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:54:06 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:06 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/14 14:54:06 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:54:06 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 14:54:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:54:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:54:06 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1782 bytes result sent to driver
21/03/14 14:54:06 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 10 ms on localhost (executor driver) (1/1)
21/03/14 14:54:06 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 14:54:06 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.017 s
21/03/14 14:54:06 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.066503 s
21/03/14 14:54:07 INFO MapPartitionsRDD: Removing RDD 22 from persistence list
21/03/14 14:54:07 INFO BlockManager: Removing RDD 22
21/03/14 14:54:07 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:54:07 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 14:54:07 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 14:54:07 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:54:07 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:07 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:07 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 284.5 KB, free 911.0 MB)
21/03/14 14:54:07 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.0 MB)
21/03/14 14:54:07 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:60690 (size: 23.9 KB, free: 912.2 MB)
21/03/14 14:54:07 INFO SparkContext: Created broadcast 11 from count at NativeMethodAccessorImpl.java:0
21/03/14 14:54:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:54:07 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 14:54:07 INFO DAGScheduler: Registering RDD 46 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:54:07 INFO DAGScheduler: Got job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:54:07 INFO DAGScheduler: Final stage: ResultStage 9 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:54:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/03/14 14:54:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
21/03/14 14:54:07 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:54:07 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 25.9 KB, free 911.0 MB)
21/03/14 14:54:07 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 12.1 KB, free 910.9 MB)
21/03/14 14:54:07 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:60690 (size: 12.1 KB, free: 912.2 MB)
21/03/14 14:54:07 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:07 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 14:54:07 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 14:54:07 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/03/14 14:54:07 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpfUs57X/file154ce37740167, range: 0-2539, partition values: [empty row]
21/03/14 14:54:07 INFO MemoryStore: Block rdd_41_0 stored as values in memory (estimated size 4.9 KB, free 910.9 MB)
21/03/14 14:54:07 INFO BlockManagerInfo: Added rdd_41_0 in memory on localhost:60690 (size: 4.9 KB, free: 912.2 MB)
21/03/14 14:54:07 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1871 bytes result sent to driver
21/03/14 14:54:07 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 58 ms on localhost (executor driver) (1/1)
21/03/14 14:54:07 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 14:54:07 INFO DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.070 s
21/03/14 14:54:07 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:54:07 INFO DAGScheduler: running: Set()
21/03/14 14:54:07 INFO DAGScheduler: waiting: Set(ResultStage 9)
21/03/14 14:54:07 INFO DAGScheduler: failed: Set()
21/03/14 14:54:07 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[49] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:54:07 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.1 KB, free 910.9 MB)
21/03/14 14:54:07 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.8 KB, free 910.9 MB)
21/03/14 14:54:07 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:60690 (size: 3.8 KB, free: 912.1 MB)
21/03/14 14:54:07 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[49] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:07 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 14:54:07 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:54:07 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/03/14 14:54:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:54:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:54:07 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1825 bytes result sent to driver
21/03/14 14:54:07 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 8 ms on localhost (executor driver) (1/1)
21/03/14 14:54:07 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 14:54:07 INFO DAGScheduler: ResultStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.015 s
21/03/14 14:54:07 INFO DAGScheduler: Job 5 finished: count at NativeMethodAccessorImpl.java:0, took 0.090132 s
21/03/14 14:54:07 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 14:54:07 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 14:54:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 14:54:07 INFO MemoryStore: MemoryStore cleared
21/03/14 14:54:07 INFO BlockManager: BlockManager stopped
21/03/14 14:54:07 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 14:54:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 14:54:07 INFO SparkContext: Successfully stopped SparkContext
21/03/14 14:54:07 INFO ShutdownHookManager: Shutdown hook called
21/03/14 14:54:07 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-9aa54977-0178-495f-9e13-0c1a09e8ccd2
21/03/14 14:54:07 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-196600a3-0d01-45bb-a02e-9d94231dd241
21/03/14 14:54:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 14:54:13 INFO SparkContext: Running Spark version 2.4.3
21/03/14 14:54:13 INFO SparkContext: Submitted application: sparklyr
21/03/14 14:54:13 INFO SecurityManager: Changing view acls to: nathan
21/03/14 14:54:13 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 14:54:13 INFO SecurityManager: Changing view acls groups to: 
21/03/14 14:54:13 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 14:54:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 14:54:13 INFO Utils: Successfully started service 'sparkDriver' on port 60800.
21/03/14 14:54:13 INFO SparkEnv: Registering MapOutputTracker
21/03/14 14:54:13 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 14:54:13 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 14:54:13 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 14:54:13 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-4bf8dbbe-9c5a-4c94-857c-73ab1fc59082
21/03/14 14:54:13 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 14:54:13 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 14:54:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 14:54:13 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 14:54:13 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:60800/jars/sparklyr-2.4-2.11.jar with timestamp 1615730053788
21/03/14 14:54:13 INFO Executor: Starting executor ID driver on host localhost
21/03/14 14:54:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60801.
21/03/14 14:54:13 INFO NettyBlockTransferService: Server created on localhost:60801
21/03/14 14:54:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 14:54:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 60801, None)
21/03/14 14:54:14 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60801 with 912.3 MB RAM, BlockManagerId(driver, localhost, 60801, None)
21/03/14 14:54:14 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 60801, None)
21/03/14 14:54:14 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 60801, None)
21/03/14 14:54:14 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 14:54:14 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 14:54:14 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 14:54:14 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 14:54:18 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 14:54:18 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 14:54:18 INFO ObjectStore: ObjectStore, initialize called
21/03/14 14:54:19 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 14:54:19 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 14:54:20 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 14:54:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:54:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:54:24 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:54:24 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:54:24 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 14:54:24 INFO ObjectStore: Initialized ObjectStore
21/03/14 14:54:24 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 14:54:24 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 14:54:24 INFO HiveMetaStore: Added admin role in metastore
21/03/14 14:54:24 INFO HiveMetaStore: Added public role in metastore
21/03/14 14:54:25 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 14:54:25 INFO HiveMetaStore: 0: get_all_databases
21/03/14 14:54:25 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 14:54:25 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 14:54:25 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 14:54:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 14:54:25 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/3aac06e3-268b-4635-bf35-8529280e7429_resources
21/03/14 14:54:25 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/3aac06e3-268b-4635-bf35-8529280e7429
21/03/14 14:54:25 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/3aac06e3-268b-4635-bf35-8529280e7429
21/03/14 14:54:25 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/3aac06e3-268b-4635-bf35-8529280e7429/_tmp_space.db
21/03/14 14:54:25 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 14:54:25 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:54:25 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:54:25 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:25 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:26 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:54:26 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
21/03/14 14:54:26 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 14:54:26 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:54:26 INFO CodeGenerator: Code generated in 411.236721 ms
21/03/14 14:54:27 INFO CodeGenerator: Code generated in 35.393877 ms
21/03/14 14:54:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 284.3 KB, free 912.0 MB)
21/03/14 14:54:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.9 KB, free 912.0 MB)
21/03/14 14:54:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60801 (size: 23.9 KB, free: 912.3 MB)
21/03/14 14:54:27 INFO SparkContext: Created broadcast 0 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 14:54:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:54:27 INFO SparkContext: Starting job: createTable at NativeMethodAccessorImpl.java:0
21/03/14 14:54:27 INFO DAGScheduler: Got job 0 (createTable at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:54:27 INFO DAGScheduler: Final stage: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0)
21/03/14 14:54:27 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:54:27 INFO DAGScheduler: Missing parents: List()
21/03/14 14:54:27 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:54:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 912.0 MB)
21/03/14 14:54:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.0 MB)
21/03/14 14:54:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60801 (size: 4.5 KB, free: 912.3 MB)
21/03/14 14:54:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 14:54:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8362 bytes)
21/03/14 14:54:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 14:54:27 INFO Executor: Fetching spark://localhost:60800/jars/sparklyr-2.4-2.11.jar with timestamp 1615730053788
21/03/14 14:54:27 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:60800 after 23 ms (0 ms spent in bootstraps)
21/03/14 14:54:27 INFO Utils: Fetching spark://localhost:60800/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-b74816d9-4449-49b1-b1d2-d47d1399b181/userFiles-73419b3b-f565-46e7-a30b-0eec6926dcd3/fetchFileTemp2579629690372359877.tmp
21/03/14 14:54:27 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-b74816d9-4449-49b1-b1d2-d47d1399b181/userFiles-73419b3b-f565-46e7-a30b-0eec6926dcd3/sparklyr-2.4-2.11.jar to class loader
21/03/14 14:54:28 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpfUs57X/file154ce765b0ed7, range: 0-1303, partition values: [empty row]
21/03/14 14:54:28 INFO CodeGenerator: Code generated in 14.908469 ms
21/03/14 14:54:28 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1329 bytes result sent to driver
21/03/14 14:54:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 333 ms on localhost (executor driver) (1/1)
21/03/14 14:54:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 14:54:28 INFO DAGScheduler: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0) finished in 0.453 s
21/03/14 14:54:28 INFO DAGScheduler: Job 0 finished: createTable at NativeMethodAccessorImpl.java:0, took 0.507623 s
21/03/14 14:54:28 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:54:28 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 14:54:28 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 14:54:28 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:54:28 INFO CodeGenerator: Code generated in 9.634813 ms
21/03/14 14:54:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 284.3 KB, free 911.7 MB)
21/03/14 14:54:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.7 MB)
21/03/14 14:54:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60801 (size: 23.9 KB, free: 912.2 MB)
21/03/14 14:54:28 INFO SparkContext: Created broadcast 2 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 14:54:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:54:28 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:54:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:54:28 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:28 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:54:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:54:28 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:28 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `default`.`mtcars` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.
21/03/14 14:54:28 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:54:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:54:28 INFO HiveMetaStore: 0: create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615730057, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpfUs57X/file154ce765b0ed7, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
21/03/14 14:54:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615730057, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpfUs57X/file154ce765b0ed7, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
21/03/14 14:54:28 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__
21/03/14 14:54:28 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 14:54:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 14:54:28 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 14:54:28 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:29 INFO CodeGenerator: Code generated in 16.661884 ms
21/03/14 14:54:29 INFO CodeGenerator: Code generated in 14.363365 ms
21/03/14 14:54:30 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:54:30 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:54:30 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 14:54:30 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:54:30 INFO DAGScheduler: Missing parents: List()
21/03/14 14:54:30 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135), which has no missing parents
21/03/14 14:54:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.5 KB, free 911.7 MB)
21/03/14 14:54:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 14:54:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:60801 (size: 3.3 KB, free: 912.2 MB)
21/03/14 14:54:30 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 14:54:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:54:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 14:54:30 INFO CodeGenerator: Code generated in 10.99555 ms
21/03/14 14:54:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 14:54:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on localhost (executor driver) (1/1)
21/03/14 14:54:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 14:54:30 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.050 s
21/03/14 14:54:30 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.056662 s
21/03/14 14:54:30 INFO CodeGenerator: Code generated in 30.476211 ms
21/03/14 14:54:30 INFO CodeGenerator: Code generated in 22.556395 ms
21/03/14 14:54:30 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:54:30 INFO DAGScheduler: Registering RDD 16 (count at utils.scala:135)
21/03/14 14:54:30 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 14:54:30 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 14:54:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 14:54:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 14:54:30 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135), which has no missing parents
21/03/14 14:54:30 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.4 KB, free 911.7 MB)
21/03/14 14:54:30 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.7 MB)
21/03/14 14:54:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:60801 (size: 4.5 KB, free: 912.2 MB)
21/03/14 14:54:30 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 14:54:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:54:30 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 14:54:30 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 14:54:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 79 ms on localhost (executor driver) (1/1)
21/03/14 14:54:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 14:54:30 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.103 s
21/03/14 14:54:30 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:54:30 INFO DAGScheduler: running: Set()
21/03/14 14:54:30 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 14:54:30 INFO DAGScheduler: failed: Set()
21/03/14 14:54:30 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135), which has no missing parents
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 18
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 27
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 21
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 7
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 16
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 25
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 17
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 15
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 23
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 13
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 29
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 9
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 24
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 14:54:30 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 14:54:30 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 14:54:30 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:60801 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 14:54:30 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:60801 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:54:30 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:30 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 20
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 26
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 12
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 6
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 14:54:30 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:60801 in memory (size: 3.3 KB, free: 912.2 MB)
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 10
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 28
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 14
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 8
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 30
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 19
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 22
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 11
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 14:54:30 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 14:54:30 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:54:30 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 14:54:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:54:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
21/03/14 14:54:30 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 14:54:30 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 72 ms on localhost (executor driver) (1/1)
21/03/14 14:54:30 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 14:54:30 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.094 s
21/03/14 14:54:30 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.294679 s
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:31 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:54:31 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 14:54:31 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 14:54:31 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:32 INFO CodeGenerator: Code generated in 50.256052 ms
21/03/14 14:54:32 INFO CodeGenerator: Code generated in 21.118136 ms
21/03/14 14:54:32 INFO CodeGenerator: Code generated in 14.945824 ms
21/03/14 14:54:32 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:54:32 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135)
21/03/14 14:54:32 INFO DAGScheduler: Got job 3 (count at utils.scala:135) with 1 output partitions
21/03/14 14:54:32 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/03/14 14:54:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 14:54:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 14:54:32 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/03/14 14:54:32 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.9 KB, free 911.7 MB)
21/03/14 14:54:32 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.2 KB, free 911.7 MB)
21/03/14 14:54:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:60801 (size: 4.2 KB, free: 912.2 MB)
21/03/14 14:54:32 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:32 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 14:54:32 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 14:54:32 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 14:54:32 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1499 bytes result sent to driver
21/03/14 14:54:32 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 10 ms on localhost (executor driver) (1/1)
21/03/14 14:54:32 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 14:54:32 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.017 s
21/03/14 14:54:32 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:54:32 INFO DAGScheduler: running: Set()
21/03/14 14:54:32 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 14:54:32 INFO DAGScheduler: failed: Set()
21/03/14 14:54:32 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/03/14 14:54:32 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 14:54:32 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 14:54:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:60801 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:54:32 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:32 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 14:54:32 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:54:32 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 14:54:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:54:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:54:32 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1782 bytes result sent to driver
21/03/14 14:54:32 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 6 ms on localhost (executor driver) (1/1)
21/03/14 14:54:32 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 14:54:32 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.012 s
21/03/14 14:54:32 INFO DAGScheduler: Job 3 finished: count at utils.scala:135, took 0.035433 s
21/03/14 14:54:32 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:32 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:54:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:54:32 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:32 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:32 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:32 INFO HiveMetaStore: 0: get_table : db=default tbl=fake_table
21/03/14 14:54:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=fake_table	
21/03/14 14:54:32 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:32 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:32 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:32 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:54:32 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 14:54:32 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 14:54:32 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:54:32 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:32 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:54:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:54:32 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:54:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:54:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 14:54:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 14:54:32 INFO CodeGenerator: Code generated in 16.941575 ms
21/03/14 14:54:33 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 14:54:33 INFO DAGScheduler: Got job 4 (collect at utils.scala:61) with 1 output partitions
21/03/14 14:54:33 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:61)
21/03/14 14:54:33 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:54:33 INFO DAGScheduler: Missing parents: List()
21/03/14 14:54:33 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[31] at map at utils.scala:54), which has no missing parents
21/03/14 14:54:33 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 6.0 KB, free 911.6 MB)
21/03/14 14:54:33 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.4 KB, free 911.6 MB)
21/03/14 14:54:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:60801 (size: 3.4 KB, free: 912.2 MB)
21/03/14 14:54:33 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[31] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:33 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 14:54:33 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
21/03/14 14:54:33 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 14:54:33 INFO CodeGenerator: Code generated in 8.387881 ms
21/03/14 14:54:33 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 979 bytes result sent to driver
21/03/14 14:54:33 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 19 ms on localhost (executor driver) (1/1)
21/03/14 14:54:33 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 14:54:33 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:61) finished in 0.024 s
21/03/14 14:54:33 INFO DAGScheduler: Job 4 finished: collect at utils.scala:61, took 0.027576 s
21/03/14 14:54:33 INFO CodeGenerator: Code generated in 8.744501 ms
21/03/14 14:54:33 INFO CodeGenerator: Code generated in 9.174815 ms
21/03/14 14:54:33 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:54:33 INFO DAGScheduler: Got job 5 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:54:33 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:135)
21/03/14 14:54:33 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:54:33 INFO DAGScheduler: Missing parents: List()
21/03/14 14:54:33 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[35] at collect at utils.scala:135), which has no missing parents
21/03/14 14:54:33 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 6.3 KB, free 911.6 MB)
21/03/14 14:54:33 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.6 MB)
21/03/14 14:54:33 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:60801 (size: 3.3 KB, free: 912.2 MB)
21/03/14 14:54:33 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:33 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/14 14:54:33 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:54:33 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 14:54:33 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1286 bytes result sent to driver
21/03/14 14:54:33 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:54:33 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 14:54:33 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:135) finished in 0.014 s
21/03/14 14:54:33 INFO DAGScheduler: Job 5 finished: collect at utils.scala:135, took 0.016691 s
21/03/14 14:54:33 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:54:33 INFO DAGScheduler: Registering RDD 38 (count at utils.scala:135)
21/03/14 14:54:33 INFO DAGScheduler: Got job 6 (count at utils.scala:135) with 1 output partitions
21/03/14 14:54:33 INFO DAGScheduler: Final stage: ResultStage 9 (count at utils.scala:135)
21/03/14 14:54:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/03/14 14:54:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
21/03/14 14:54:33 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[38] at count at utils.scala:135), which has no missing parents
21/03/14 14:54:33 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.4 KB, free 911.6 MB)
21/03/14 14:54:33 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.6 MB)
21/03/14 14:54:33 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:60801 (size: 4.5 KB, free: 912.2 MB)
21/03/14 14:54:33 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[38] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:33 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 14:54:33 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:54:33 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/03/14 14:54:33 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1499 bytes result sent to driver
21/03/14 14:54:33 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 9 ms on localhost (executor driver) (1/1)
21/03/14 14:54:33 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 14:54:33 INFO DAGScheduler: ShuffleMapStage 8 (count at utils.scala:135) finished in 0.016 s
21/03/14 14:54:33 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:54:33 INFO DAGScheduler: running: Set()
21/03/14 14:54:33 INFO DAGScheduler: waiting: Set(ResultStage 9)
21/03/14 14:54:33 INFO DAGScheduler: failed: Set()
21/03/14 14:54:33 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[41] at count at utils.scala:135), which has no missing parents
21/03/14 14:54:33 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 14:54:33 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 14:54:33 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:60801 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:54:33 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[41] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:33 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 14:54:33 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:54:33 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/03/14 14:54:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:54:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:54:33 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1782 bytes result sent to driver
21/03/14 14:54:33 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:54:33 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 14:54:33 INFO DAGScheduler: ResultStage 9 (count at utils.scala:135) finished in 0.013 s
21/03/14 14:54:33 INFO DAGScheduler: Job 6 finished: count at utils.scala:135, took 0.034882 s
21/03/14 14:54:33 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 14:54:33 INFO DAGScheduler: Got job 7 (collect at utils.scala:135) with 1 output partitions
21/03/14 14:54:33 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:135)
21/03/14 14:54:33 INFO DAGScheduler: Parents of final stage: List()
21/03/14 14:54:33 INFO DAGScheduler: Missing parents: List()
21/03/14 14:54:33 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[44] at collect at utils.scala:135), which has no missing parents
21/03/14 14:54:33 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 6.3 KB, free 911.6 MB)
21/03/14 14:54:33 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.6 MB)
21/03/14 14:54:33 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:60801 (size: 3.3 KB, free: 912.2 MB)
21/03/14 14:54:33 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[44] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:33 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/03/14 14:54:33 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 14:54:33 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/03/14 14:54:33 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1286 bytes result sent to driver
21/03/14 14:54:33 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
21/03/14 14:54:33 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/03/14 14:54:33 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:135) finished in 0.011 s
21/03/14 14:54:33 INFO DAGScheduler: Job 7 finished: collect at utils.scala:135, took 0.013035 s
21/03/14 14:54:33 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 14:54:33 INFO DAGScheduler: Registering RDD 47 (count at utils.scala:135)
21/03/14 14:54:33 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/03/14 14:54:33 INFO DAGScheduler: Final stage: ResultStage 12 (count at utils.scala:135)
21/03/14 14:54:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
21/03/14 14:54:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
21/03/14 14:54:33 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[47] at count at utils.scala:135), which has no missing parents
21/03/14 14:54:33 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.4 KB, free 911.6 MB)
21/03/14 14:54:33 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.6 MB)
21/03/14 14:54:33 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:60801 (size: 4.5 KB, free: 912.2 MB)
21/03/14 14:54:33 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[47] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:33 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/03/14 14:54:33 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 14:54:33 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/03/14 14:54:33 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1499 bytes result sent to driver
21/03/14 14:54:33 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 9 ms on localhost (executor driver) (1/1)
21/03/14 14:54:33 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/03/14 14:54:33 INFO DAGScheduler: ShuffleMapStage 11 (count at utils.scala:135) finished in 0.015 s
21/03/14 14:54:33 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:54:33 INFO DAGScheduler: running: Set()
21/03/14 14:54:33 INFO DAGScheduler: waiting: Set(ResultStage 12)
21/03/14 14:54:33 INFO DAGScheduler: failed: Set()
21/03/14 14:54:33 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[50] at count at utils.scala:135), which has no missing parents
21/03/14 14:54:33 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 14:54:33 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 14:54:33 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:60801 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:54:33 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[50] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:33 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/03/14 14:54:33 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:54:33 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/03/14 14:54:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:54:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:54:33 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1782 bytes result sent to driver
21/03/14 14:54:33 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:54:33 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/03/14 14:54:33 INFO DAGScheduler: ResultStage 12 (count at utils.scala:135) finished in 0.013 s
21/03/14 14:54:33 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.032236 s
21/03/14 14:54:34 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:34 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:34 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:34 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:34 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:34 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:34 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:54:34 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 14:54:34 INFO FileSourceStrategy: Output Data Schema: struct<>
21/03/14 14:54:34 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:54:34 INFO CodeGenerator: Code generated in 11.974349 ms
21/03/14 14:54:34 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 284.5 KB, free 911.3 MB)
21/03/14 14:54:34 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.3 MB)
21/03/14 14:54:34 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:60801 (size: 23.9 KB, free: 912.2 MB)
21/03/14 14:54:34 INFO SparkContext: Created broadcast 15 from count at NativeMethodAccessorImpl.java:0
21/03/14 14:54:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:54:34 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 14:54:34 INFO DAGScheduler: Registering RDD 53 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:54:34 INFO DAGScheduler: Got job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:54:34 INFO DAGScheduler: Final stage: ResultStage 14 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:54:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/03/14 14:54:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/03/14 14:54:34 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:54:34 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 14.2 KB, free 911.3 MB)
21/03/14 14:54:34 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.3 MB)
21/03/14 14:54:34 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:60801 (size: 8.0 KB, free: 912.2 MB)
21/03/14 14:54:34 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:34 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/03/14 14:54:34 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 14:54:34 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/03/14 14:54:34 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpfUs57X/file154ce765b0ed7, range: 0-1303, partition values: [empty row]
21/03/14 14:54:34 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1585 bytes result sent to driver
21/03/14 14:54:34 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 47 ms on localhost (executor driver) (1/1)
21/03/14 14:54:34 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/03/14 14:54:34 INFO DAGScheduler: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.063 s
21/03/14 14:54:34 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:54:34 INFO DAGScheduler: running: Set()
21/03/14 14:54:34 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/03/14 14:54:34 INFO DAGScheduler: failed: Set()
21/03/14 14:54:34 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:54:34 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.1 KB, free 911.2 MB)
21/03/14 14:54:34 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.2 MB)
21/03/14 14:54:34 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:60801 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:54:34 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:34 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/03/14 14:54:34 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:54:34 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/03/14 14:54:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:54:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 14:54:34 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1782 bytes result sent to driver
21/03/14 14:54:34 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 7 ms on localhost (executor driver) (1/1)
21/03/14 14:54:34 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/03/14 14:54:34 INFO DAGScheduler: ResultStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0.012 s
21/03/14 14:54:34 INFO DAGScheduler: Job 9 finished: count at NativeMethodAccessorImpl.java:0, took 0.081955 s
21/03/14 14:54:34 INFO HiveMetaStore: 0: get_database: default
21/03/14 14:54:34 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 14:54:34 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:34 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:34 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:34 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:34 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:34 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:34 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 14:54:34 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 14:54:34 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 14:54:34 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 14:54:34 INFO FileSourceStrategy: Output Data Schema: struct<>
21/03/14 14:54:34 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 14:54:34 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 284.5 KB, free 911.0 MB)
21/03/14 14:54:34 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.9 KB, free 910.9 MB)
21/03/14 14:54:34 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:60801 (size: 23.9 KB, free: 912.2 MB)
21/03/14 14:54:34 INFO SparkContext: Created broadcast 18 from count at NativeMethodAccessorImpl.java:0
21/03/14 14:54:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 358
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 118
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 140
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 440
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 107
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 111
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 266
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 399
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 229
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 431
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 364
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 191
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 137
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 116
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 230
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 428
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 433
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 426
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 222
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 275
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 233
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 464
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 113
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 165
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 286
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 288
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 372
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 172
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 329
21/03/14 14:54:35 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:60801 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 282
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 449
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 108
21/03/14 14:54:35 INFO ContextCleaner: Cleaned shuffle 4
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 381
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 161
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 204
21/03/14 14:54:35 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:60801 in memory (size: 3.3 KB, free: 912.2 MB)
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 415
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 202
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 410
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 147
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 284
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 251
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 302
21/03/14 14:54:35 INFO ContextCleaner: Cleaned shuffle 3
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 451
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 154
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 328
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 419
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 373
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 385
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 170
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 382
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 412
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 187
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 181
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 380
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 167
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 231
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 392
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 163
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 110
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 146
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 130
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 422
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 151
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 179
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 468
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 447
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 339
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 338
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 377
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 169
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 335
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 459
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 145
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 331
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 365
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 240
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 195
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 247
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 409
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 371
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 131
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 290
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 475
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 314
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 139
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 308
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 305
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 394
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 136
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 220
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 448
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 135
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 315
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 255
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 441
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 378
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 177
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 444
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 193
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 228
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 271
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 342
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 252
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 142
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 296
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 109
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 453
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 260
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 265
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 188
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 194
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 175
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 208
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 180
21/03/14 14:54:35 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:60801 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 343
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 183
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 322
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 278
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 152
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 241
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 259
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 321
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 162
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 112
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 408
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 203
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 355
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 253
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 398
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 217
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 369
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 219
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 225
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 143
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 387
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 361
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 337
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 357
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 463
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 164
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 340
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 281
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 238
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 149
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 289
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 326
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 457
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 400
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 348
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 423
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 206
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 462
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 114
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 201
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 270
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 209
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 396
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 405
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 258
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 418
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 298
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 403
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 389
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 384
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 120
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 332
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 407
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 452
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 318
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 466
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 324
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 455
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 346
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 353
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 227
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 272
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 312
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 224
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 313
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 182
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 269
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 445
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 117
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 205
21/03/14 14:54:35 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:60801 in memory (size: 3.3 KB, free: 912.2 MB)
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 159
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 301
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 390
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 119
21/03/14 14:54:35 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:60801 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 350
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 320
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 291
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 316
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 294
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 173
21/03/14 14:54:35 INFO ContextCleaner: Cleaned shuffle 1
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 300
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 256
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 417
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 104
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 393
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 150
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 124
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 215
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 246
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 273
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 435
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 141
21/03/14 14:54:35 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:60801 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 14:54:35 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:60801 in memory (size: 4.2 KB, free: 912.2 MB)
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 221
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 132
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 186
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 376
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 443
21/03/14 14:54:35 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:60801 in memory (size: 3.4 KB, free: 912.2 MB)
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 129
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 287
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 216
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 134
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 347
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 148
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 465
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 166
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 366
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 262
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 436
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 138
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 268
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 158
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 424
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 157
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 473
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 345
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 212
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 122
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 360
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 414
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 207
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 156
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 236
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 239
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 276
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 285
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 232
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 176
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 153
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 244
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 397
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 363
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 309
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 292
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 432
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 467
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 106
21/03/14 14:54:35 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:60801 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 200
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 274
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 430
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 299
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 450
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 242
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 429
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 317
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 126
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 243
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 333
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 261
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 367
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 391
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 264
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 416
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 319
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 386
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 155
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 245
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 352
21/03/14 14:54:35 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:60801 in memory (size: 8.0 KB, free: 912.2 MB)
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 213
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 123
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 421
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 210
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 351
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 402
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 427
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 185
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 199
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 307
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 420
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 197
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 196
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 304
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 283
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 249
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 121
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 190
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 279
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 128
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 234
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 425
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 171
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 293
21/03/14 14:54:35 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:60801 in memory (size: 23.9 KB, free: 912.2 MB)
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 125
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 456
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 434
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 263
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 211
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 311
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 401
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 237
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 178
21/03/14 14:54:35 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:60801 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 297
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 323
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 218
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 105
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 359
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 404
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 184
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 406
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 115
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 189
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 461
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 306
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 474
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 144
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 395
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 439
21/03/14 14:54:35 INFO ContextCleaner: Cleaned shuffle 2
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 370
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 310
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 460
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 356
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 458
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 454
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 469
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 413
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 374
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 341
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 388
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 267
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 214
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 235
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 257
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 248
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 438
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 277
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 344
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 303
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 349
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 362
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 330
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 442
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 336
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 254
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 334
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 354
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 223
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 437
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 127
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 476
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 103
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 470
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 327
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 472
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 250
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 226
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 379
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 198
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 471
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 280
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 375
21/03/14 14:54:35 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:60801 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 174
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 295
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 133
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 383
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 325
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 368
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 411
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 168
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 446
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 160
21/03/14 14:54:35 INFO ContextCleaner: Cleaned accumulator 192
21/03/14 14:54:35 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 14:54:35 INFO DAGScheduler: Registering RDD 59 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:54:35 INFO DAGScheduler: Got job 10 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 14:54:35 INFO DAGScheduler: Final stage: ResultStage 16 (count at NativeMethodAccessorImpl.java:0)
21/03/14 14:54:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
21/03/14 14:54:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
21/03/14 14:54:35 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:54:35 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 14.2 KB, free 911.4 MB)
21/03/14 14:54:35 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.4 MB)
21/03/14 14:54:35 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:60801 (size: 8.0 KB, free: 912.2 MB)
21/03/14 14:54:35 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:35 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/03/14 14:54:35 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 14:54:35 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/03/14 14:54:35 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpfUs57X/file154ce765b0ed7, range: 0-2539, partition values: [empty row]
21/03/14 14:54:35 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1585 bytes result sent to driver
21/03/14 14:54:35 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 17 ms on localhost (executor driver) (1/1)
21/03/14 14:54:35 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/03/14 14:54:35 INFO DAGScheduler: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.036 s
21/03/14 14:54:35 INFO DAGScheduler: looking for newly runnable stages
21/03/14 14:54:35 INFO DAGScheduler: running: Set()
21/03/14 14:54:35 INFO DAGScheduler: waiting: Set(ResultStage 16)
21/03/14 14:54:35 INFO DAGScheduler: failed: Set()
21/03/14 14:54:35 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 14:54:35 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.1 KB, free 911.4 MB)
21/03/14 14:54:35 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.4 MB)
21/03/14 14:54:35 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:60801 (size: 3.8 KB, free: 912.2 MB)
21/03/14 14:54:35 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1161
21/03/14 14:54:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 14:54:35 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/03/14 14:54:35 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 14:54:35 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/03/14 14:54:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 14:54:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 14:54:35 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1782 bytes result sent to driver
21/03/14 14:54:35 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 10 ms on localhost (executor driver) (1/1)
21/03/14 14:54:35 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/03/14 14:54:35 INFO DAGScheduler: ResultStage 16 (count at NativeMethodAccessorImpl.java:0) finished in 0.016 s
21/03/14 14:54:35 INFO DAGScheduler: Job 10 finished: count at NativeMethodAccessorImpl.java:0, took 0.057650 s
21/03/14 14:54:35 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 14:54:35 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 14:54:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 14:54:35 INFO MemoryStore: MemoryStore cleared
21/03/14 14:54:35 INFO BlockManager: BlockManager stopped
21/03/14 14:54:35 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 14:54:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 14:54:35 INFO SparkContext: Successfully stopped SparkContext
21/03/14 14:54:35 INFO ShutdownHookManager: Shutdown hook called
21/03/14 14:54:35 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-5c7b9bb1-1439-42f6-b5af-827a051e9051
21/03/14 14:54:35 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-b74816d9-4449-49b1-b1d2-d47d1399b181
21/03/14 14:54:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:00:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:00:42 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:00:42 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:00:42 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:00:42 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:00:42 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:00:42 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:00:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:00:42 INFO Utils: Successfully started service 'sparkDriver' on port 61754.
21/03/14 15:00:42 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:00:42 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:00:42 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:00:42 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:00:42 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-a67f5a62-bec0-4215-ac12-b5b82538cdc3
21/03/14 15:00:42 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:00:42 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:00:43 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:00:43 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:00:43 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:61754/jars/sparklyr-2.4-2.11.jar with timestamp 1615730443156
21/03/14 15:00:43 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:00:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61755.
21/03/14 15:00:43 INFO NettyBlockTransferService: Server created on localhost:61755
21/03/14 15:00:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:00:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 61755, None)
21/03/14 15:00:43 INFO BlockManagerMasterEndpoint: Registering block manager localhost:61755 with 912.3 MB RAM, BlockManagerId(driver, localhost, 61755, None)
21/03/14 15:00:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 61755, None)
21/03/14 15:00:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 61755, None)
21/03/14 15:00:43 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:00:43 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:00:43 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:00:44 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:00:47 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:00:47 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:00:47 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:00:48 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:00:48 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:00:49 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:00:50 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:00:50 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:00:52 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:00:52 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:00:52 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:00:52 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:00:52 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:00:52 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:00:52 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:00:52 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:00:52 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:00:53 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:00:53 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:00:53 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:00:53 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:00:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:00:53 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/9477d77e-f896-43fa-ba55-8baa5c1e7404_resources
21/03/14 15:00:53 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/9477d77e-f896-43fa-ba55-8baa5c1e7404
21/03/14 15:00:53 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/9477d77e-f896-43fa-ba55-8baa5c1e7404
21/03/14 15:00:53 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/9477d77e-f896-43fa-ba55-8baa5c1e7404/_tmp_space.db
21/03/14 15:00:53 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:00:53 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:00:53 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:00:53 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:00:53 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:00:53 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:00:53 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:00:53 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:00:53 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:00:53 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:00:53 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:00:53 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:00:53 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 15:00:53 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/03/14 15:00:53 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/03/14 15:00:53 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:00:53 INFO DAGScheduler: Missing parents: List()
21/03/14 15:00:53 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/03/14 15:00:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/03/14 15:00:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/03/14 15:00:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:61755 (size: 3.4 KB, free: 912.3 MB)
21/03/14 15:00:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 15:00:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 15:00:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:00:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/03/14 15:00:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:00:54 INFO Executor: Fetching spark://localhost:61754/jars/sparklyr-2.4-2.11.jar with timestamp 1615730443156
21/03/14 15:00:54 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:61754 after 23 ms (0 ms spent in bootstraps)
21/03/14 15:00:54 INFO Utils: Fetching spark://localhost:61754/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-f494db34-deb9-4f1b-8c62-d8f0868aaa4e/userFiles-38b0e2d1-659a-4b7a-90b0-04420cb2c73a/fetchFileTemp7618175998248173546.tmp
21/03/14 15:00:54 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-f494db34-deb9-4f1b-8c62-d8f0868aaa4e/userFiles-38b0e2d1-659a-4b7a-90b0-04420cb2c73a/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:00:54 INFO CodeGenerator: Code generated in 196.619227 ms
21/03/14 15:00:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
21/03/14 15:00:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 603 ms on localhost (executor driver) (1/1)
21/03/14 15:00:54 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:00:54 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 1.022 s
21/03/14 15:00:54 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 1.094274 s
21/03/14 15:00:55 INFO ContextCleaner: Cleaned accumulator 0
21/03/14 15:00:55 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:61755 in memory (size: 3.4 KB, free: 912.3 MB)
21/03/14 15:00:55 INFO CodeGenerator: Code generated in 21.67582 ms
21/03/14 15:00:56 INFO CodeGenerator: Code generated in 25.362946 ms
21/03/14 15:00:56 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:00:56 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:00:56 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:00:56 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:00:56 INFO DAGScheduler: Missing parents: List()
21/03/14 15:00:56 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/03/14 15:00:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 15:00:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 15:00:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:61755 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:00:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:00:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:00:56 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:00:56 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:00:56 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:00:56 INFO CodeGenerator: Code generated in 10.065608 ms
21/03/14 15:00:56 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 15:00:56 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 37 ms on localhost (executor driver) (1/1)
21/03/14 15:00:56 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:00:56 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.046 s
21/03/14 15:00:56 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.051162 s
21/03/14 15:00:56 INFO CodeGenerator: Code generated in 17.140301 ms
21/03/14 15:00:56 INFO CodeGenerator: Code generated in 15.771016 ms
21/03/14 15:00:56 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:00:56 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/03/14 15:00:56 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:00:56 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:00:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:00:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:00:56 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/03/14 15:00:56 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/03/14 15:00:56 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/03/14 15:00:56 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:61755 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:00:56 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 15:00:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:00:56 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:00:56 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:00:56 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:00:56 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:00:56 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 63 ms on localhost (executor driver) (1/1)
21/03/14 15:00:56 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:00:56 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.079 s
21/03/14 15:00:56 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:00:56 INFO DAGScheduler: running: Set()
21/03/14 15:00:56 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:00:56 INFO DAGScheduler: failed: Set()
21/03/14 15:00:56 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/03/14 15:00:56 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:00:56 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:00:56 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:61755 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:00:56 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:00:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:00:56 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:00:56 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:00:56 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:00:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:00:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
21/03/14 15:00:56 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:00:56 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 60 ms on localhost (executor driver) (1/1)
21/03/14 15:00:56 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:00:56 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.073 s
21/03/14 15:00:56 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.182219 s
21/03/14 15:00:56 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:00:56 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:00:56 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/03/14 15:00:56 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:00:56 INFO DAGScheduler: Missing parents: List()
21/03/14 15:00:56 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135), which has no missing parents
21/03/14 15:00:56 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 15:00:56 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 15:00:56 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:61755 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:00:56 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:00:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:00:56 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:00:56 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:00:56 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:00:56 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/03/14 15:00:56 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:00:56 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:00:56 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.017 s
21/03/14 15:00:56 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.020138 s
21/03/14 15:00:57 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:00:57 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:135)
21/03/14 15:00:57 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/14 15:00:57 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/03/14 15:00:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/03/14 15:00:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/03/14 15:00:57 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/03/14 15:00:57 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/03/14 15:00:57 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/03/14 15:00:57 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:61755 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:00:57 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:00:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:00:57 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:00:57 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:00:57 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:00:57 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1542 bytes result sent to driver
21/03/14 15:00:57 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 11 ms on localhost (executor driver) (1/1)
21/03/14 15:00:57 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:00:57 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.020 s
21/03/14 15:00:57 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:00:57 INFO DAGScheduler: running: Set()
21/03/14 15:00:57 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/03/14 15:00:57 INFO DAGScheduler: failed: Set()
21/03/14 15:00:57 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/03/14 15:00:57 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 15:00:57 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 15:00:57 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:61755 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:00:57 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 15:00:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:00:57 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:00:57 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:00:57 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:00:57 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:00:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:00:57 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/03/14 15:00:57 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 10 ms on localhost (executor driver) (1/1)
21/03/14 15:00:57 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:00:57 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.019 s
21/03/14 15:00:57 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.045468 s
21/03/14 15:00:57 INFO CodeGenerator: Code generated in 35.856675 ms
21/03/14 15:00:57 INFO CodeGenerator: Code generated in 15.396516 ms
21/03/14 15:00:57 INFO CodeGenerator: Code generated in 12.422957 ms
21/03/14 15:00:57 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:00:57 INFO DAGScheduler: Registering RDD 28 (count at utils.scala:135)
21/03/14 15:00:57 INFO DAGScheduler: Got job 5 (count at utils.scala:135) with 1 output partitions
21/03/14 15:00:57 INFO DAGScheduler: Final stage: ResultStage 8 (count at utils.scala:135)
21/03/14 15:00:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
21/03/14 15:00:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
21/03/14 15:00:57 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135), which has no missing parents
21/03/14 15:00:57 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 15:00:57 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 15:00:57 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:61755 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:00:57 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 15:00:57 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/03/14 15:00:57 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
21/03/14 15:00:57 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8034 bytes)
21/03/14 15:00:57 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 8, localhost, executor driver, partition 1, PROCESS_LOCAL, 8051 bytes)
21/03/14 15:00:57 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 9, localhost, executor driver, partition 2, PROCESS_LOCAL, 8051 bytes)
21/03/14 15:00:57 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 10, localhost, executor driver, partition 3, PROCESS_LOCAL, 8051 bytes)
21/03/14 15:00:57 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 15:00:57 INFO Executor: Running task 1.0 in stage 7.0 (TID 8)
21/03/14 15:00:57 INFO Executor: Running task 2.0 in stage 7.0 (TID 9)
21/03/14 15:00:57 INFO Executor: Running task 3.0 in stage 7.0 (TID 10)
21/03/14 15:00:57 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1499 bytes result sent to driver
21/03/14 15:00:57 INFO Executor: Finished task 3.0 in stage 7.0 (TID 10). 1499 bytes result sent to driver
21/03/14 15:00:57 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 13 ms on localhost (executor driver) (1/4)
21/03/14 15:00:57 INFO Executor: Finished task 2.0 in stage 7.0 (TID 9). 1499 bytes result sent to driver
21/03/14 15:00:57 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 9) in 13 ms on localhost (executor driver) (2/4)
21/03/14 15:00:57 INFO Executor: Finished task 1.0 in stage 7.0 (TID 8). 1499 bytes result sent to driver
21/03/14 15:00:57 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 10) in 14 ms on localhost (executor driver) (3/4)
21/03/14 15:00:57 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 8) in 17 ms on localhost (executor driver) (4/4)
21/03/14 15:00:57 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 15:00:57 INFO DAGScheduler: ShuffleMapStage 7 (count at utils.scala:135) finished in 0.028 s
21/03/14 15:00:57 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:00:57 INFO DAGScheduler: running: Set()
21/03/14 15:00:57 INFO DAGScheduler: waiting: Set(ResultStage 8)
21/03/14 15:00:57 INFO DAGScheduler: failed: Set()
21/03/14 15:00:57 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135), which has no missing parents
21/03/14 15:00:57 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 15:00:57 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 15:00:57 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:61755 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:00:57 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 15:00:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:00:57 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 15:00:57 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:00:57 INFO Executor: Running task 0.0 in stage 8.0 (TID 11)
21/03/14 15:00:57 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
21/03/14 15:00:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:00:57 INFO Executor: Finished task 0.0 in stage 8.0 (TID 11). 1825 bytes result sent to driver
21/03/14 15:00:57 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 11) in 9 ms on localhost (executor driver) (1/1)
21/03/14 15:00:57 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 15:00:57 INFO DAGScheduler: ResultStage 8 (count at utils.scala:135) finished in 0.020 s
21/03/14 15:00:57 INFO DAGScheduler: Job 5 finished: count at utils.scala:135, took 0.053716 s
21/03/14 15:00:57 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:00:57 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:00:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:00:57 INFO MemoryStore: MemoryStore cleared
21/03/14 15:00:57 INFO BlockManager: BlockManager stopped
21/03/14 15:00:57 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:00:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:00:57 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:00:57 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:00:57 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-f494db34-deb9-4f1b-8c62-d8f0868aaa4e
21/03/14 15:00:57 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-e0aa157b-edf6-4979-b776-6be0d9f261bc
21/03/14 15:01:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:01:01 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:01:01 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:01:01 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:01:01 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:01:01 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:01:01 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:01:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:01:01 INFO Utils: Successfully started service 'sparkDriver' on port 61777.
21/03/14 15:01:01 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:01:01 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:01:01 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:01:01 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:01:01 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-d4da0da3-efa6-4927-8cf8-d069dae29c35
21/03/14 15:01:01 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:01:01 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:01:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:01:02 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:01:02 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:61777/jars/sparklyr-2.4-2.11.jar with timestamp 1615730462186
21/03/14 15:01:02 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:01:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61778.
21/03/14 15:01:02 INFO NettyBlockTransferService: Server created on localhost:61778
21/03/14 15:01:02 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:01:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 61778, None)
21/03/14 15:01:02 INFO BlockManagerMasterEndpoint: Registering block manager localhost:61778 with 912.3 MB RAM, BlockManagerId(driver, localhost, 61778, None)
21/03/14 15:01:02 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 61778, None)
21/03/14 15:01:02 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 61778, None)
21/03/14 15:01:03 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:01:03 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:01:03 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:01:03 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:01:05 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:01:06 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:01:06 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:01:06 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:01:06 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:01:08 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:01:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:01:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:01:10 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:01:10 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:01:10 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:01:10 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:01:10 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:01:11 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:01:11 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:01:11 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:01:11 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:01:11 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:01:11 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:01:11 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:01:11 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:01:11 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:01:11 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/0194351b-bbb2-4d57-9102-dd6c70b8fbc1_resources
21/03/14 15:01:11 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/0194351b-bbb2-4d57-9102-dd6c70b8fbc1
21/03/14 15:01:11 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/0194351b-bbb2-4d57-9102-dd6c70b8fbc1
21/03/14 15:01:11 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/0194351b-bbb2-4d57-9102-dd6c70b8fbc1/_tmp_space.db
21/03/14 15:01:11 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:01:11 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:11 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:11 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:11 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:11 INFO HiveMetaStore: 0: get_database: fake_database
21/03/14 15:01:11 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: fake_database	
21/03/14 15:01:11 WARN ObjectStore: Failed to get database fake_database, returning NoSuchObjectException
21/03/14 15:01:11 INFO HiveMetaStore: 0: get_databases: *
21/03/14 15:01:11 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_databases: *	
21/03/14 15:01:11 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:11 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:11 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:11 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:12 INFO CodeGenerator: Code generated in 274.965565 ms
21/03/14 15:01:13 INFO CodeGenerator: Code generated in 20.336494 ms
21/03/14 15:01:13 INFO CodeGenerator: Code generated in 16.583365 ms
21/03/14 15:01:14 INFO CodeGenerator: Code generated in 26.35941 ms
21/03/14 15:01:14 INFO CodeGenerator: Code generated in 14.811327 ms
21/03/14 15:01:14 INFO CodeGenerator: Code generated in 9.538646 ms
21/03/14 15:01:14 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:01:14 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:135)
21/03/14 15:01:14 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/03/14 15:01:14 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/03/14 15:01:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/03/14 15:01:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/03/14 15:01:14 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135), which has no missing parents
21/03/14 15:01:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 15:01:14 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 15:01:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:61778 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:01:14 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:01:14 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:01:14 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 15:01:14 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:01:14 INFO Executor: Fetching spark://localhost:61777/jars/sparklyr-2.4-2.11.jar with timestamp 1615730462186
21/03/14 15:01:14 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:61777 after 26 ms (0 ms spent in bootstraps)
21/03/14 15:01:14 INFO Utils: Fetching spark://localhost:61777/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-a3e12eee-fe74-4700-9256-5c08217286a9/userFiles-d85ba76c-a972-43de-b653-f953845050eb/fetchFileTemp3226871596162780350.tmp
21/03/14 15:01:14 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-a3e12eee-fe74-4700-9256-5c08217286a9/userFiles-d85ba76c-a972-43de-b653-f953845050eb/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:01:14 INFO ContextCleaner: Cleaned accumulator 1
21/03/14 15:01:15 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1585 bytes result sent to driver
21/03/14 15:01:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 524 ms on localhost (executor driver) (1/1)
21/03/14 15:01:15 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:01:15 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:135) finished in 0.764 s
21/03/14 15:01:15 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:01:15 INFO DAGScheduler: running: Set()
21/03/14 15:01:15 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/03/14 15:01:15 INFO DAGScheduler: failed: Set()
21/03/14 15:01:15 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135), which has no missing parents
21/03/14 15:01:15 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:01:15 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:01:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:61778 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:01:15 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:01:15 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:01:15 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:01:15 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:01:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:01:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
21/03/14 15:01:15 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1825 bytes result sent to driver
21/03/14 15:01:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 60 ms on localhost (executor driver) (1/1)
21/03/14 15:01:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:01:15 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.079 s
21/03/14 15:01:15 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.925404 s
21/03/14 15:01:15 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:01:15 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:01:15 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:01:15 INFO HiveMetaStore: 0: create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})
21/03/14 15:01:15 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})	
21/03/14 15:01:15 WARN ObjectStore: Failed to get database catalog_test_database_db, returning NoSuchObjectException
21/03/14 15:01:15 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 15:01:15 INFO CodeGenerator: Code generated in 9.874606 ms
21/03/14 15:01:15 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:01:15 INFO DAGScheduler: Registering RDD 10 (count at utils.scala:135)
21/03/14 15:01:15 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/03/14 15:01:15 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:01:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:01:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:01:15 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[10] at count at utils.scala:135), which has no missing parents
21/03/14 15:01:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 15:01:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 15:01:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:61778 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:01:15 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[10] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:01:15 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:01:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 15:01:15 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:01:15 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1499 bytes result sent to driver
21/03/14 15:01:15 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 12 ms on localhost (executor driver) (1/1)
21/03/14 15:01:15 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:01:15 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.023 s
21/03/14 15:01:15 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:01:15 INFO DAGScheduler: running: Set()
21/03/14 15:01:15 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:01:15 INFO DAGScheduler: failed: Set()
21/03/14 15:01:15 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[13] at count at utils.scala:135), which has no missing parents
21/03/14 15:01:15 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:01:15 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:01:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:61778 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:01:15 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:01:15 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:01:15 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:01:15 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:01:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:01:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:01:15 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1775 bytes result sent to driver
21/03/14 15:01:15 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 10 ms on localhost (executor driver) (1/1)
21/03/14 15:01:15 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:01:15 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.019 s
21/03/14 15:01:15 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.048756 s
21/03/14 15:01:15 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 15:01:15 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 15:01:16 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 15:01:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 15:01:16 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 15:01:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 15:01:16 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:16 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:16 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:16 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 15:01:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 15:01:16 INFO HiveMetaStore: 0: drop_database: catalog_test_database_db
21/03/14 15:01:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=drop_database: catalog_test_database_db	
21/03/14 15:01:16 INFO HiveMetaStore: 0: get_all_tables: db=catalog_test_database_db
21/03/14 15:01:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_tables: db=catalog_test_database_db	
21/03/14 15:01:16 INFO HiveMetaStore: 0: get_functions: db=catalog_test_database_db pat=*
21/03/14 15:01:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=catalog_test_database_db pat=*	
21/03/14 15:01:16 INFO ObjectStore: Dropping database catalog_test_database_db along with all tables
21/03/14 15:01:16 INFO hivemetastoressimpl: deleting  file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 15:01:16 INFO deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
21/03/14 15:01:16 INFO TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
21/03/14 15:01:16 INFO hivemetastoressimpl: Deleted the diretory file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 15:01:16 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:01:16 INFO DAGScheduler: Registering RDD 17 (count at utils.scala:135)
21/03/14 15:01:16 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:01:16 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/03/14 15:01:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 15:01:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 15:01:16 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at count at utils.scala:135), which has no missing parents
21/03/14 15:01:16 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 15:01:16 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 15:01:16 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:61778 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:01:16 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:01:16 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:01:16 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 15:01:16 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:01:16 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1499 bytes result sent to driver
21/03/14 15:01:16 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 12 ms on localhost (executor driver) (1/1)
21/03/14 15:01:16 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:01:16 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.022 s
21/03/14 15:01:16 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:01:16 INFO DAGScheduler: running: Set()
21/03/14 15:01:16 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 15:01:16 INFO DAGScheduler: failed: Set()
21/03/14 15:01:16 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[20] at count at utils.scala:135), which has no missing parents
21/03/14 15:01:16 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 15:01:16 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 15:01:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:61778 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:01:16 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:01:16 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:01:16 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:01:16 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:01:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:01:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:01:16 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1775 bytes result sent to driver
21/03/14 15:01:16 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:01:16 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:01:16 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.017 s
21/03/14 15:01:16 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.045904 s
21/03/14 15:01:16 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:01:16 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:01:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:01:16 INFO MemoryStore: MemoryStore cleared
21/03/14 15:01:16 INFO BlockManager: BlockManager stopped
21/03/14 15:01:16 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:01:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:01:16 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:01:16 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:01:16 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-6237ad7b-7602-4ead-b014-400028707b81
21/03/14 15:01:16 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-a3e12eee-fe74-4700-9256-5c08217286a9
21/03/14 15:01:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:01:20 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:01:20 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:01:20 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:01:20 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:01:20 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:01:20 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:01:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:01:20 INFO Utils: Successfully started service 'sparkDriver' on port 61881.
21/03/14 15:01:20 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:01:20 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:01:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:01:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:01:20 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-84d30c2e-7c9a-4d40-97df-45fb72ee086f
21/03/14 15:01:20 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:01:20 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:01:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:01:20 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:01:20 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:61881/jars/sparklyr-2.4-2.11.jar with timestamp 1615730480773
21/03/14 15:01:20 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:01:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61882.
21/03/14 15:01:20 INFO NettyBlockTransferService: Server created on localhost:61882
21/03/14 15:01:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:01:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 61882, None)
21/03/14 15:01:21 INFO BlockManagerMasterEndpoint: Registering block manager localhost:61882 with 912.3 MB RAM, BlockManagerId(driver, localhost, 61882, None)
21/03/14 15:01:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 61882, None)
21/03/14 15:01:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 61882, None)
21/03/14 15:01:21 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:01:21 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:01:21 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:01:22 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:01:24 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:01:25 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:01:25 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:01:26 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:01:26 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:01:27 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:01:28 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:01:28 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:01:29 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:01:29 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:01:30 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:01:30 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:01:30 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:01:30 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:01:30 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:01:30 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:01:30 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:01:30 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:01:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:01:30 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:01:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:01:30 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:01:30 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/dbd50b03-5017-4c23-bfd2-465c6023cd60_resources
21/03/14 15:01:30 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/dbd50b03-5017-4c23-bfd2-465c6023cd60
21/03/14 15:01:30 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/dbd50b03-5017-4c23-bfd2-465c6023cd60
21/03/14 15:01:30 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/dbd50b03-5017-4c23-bfd2-465c6023cd60/_tmp_space.db
21/03/14 15:01:30 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:01:30 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:31 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:31 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:31 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:31 INFO HiveMetaStore: 0: get_function: default.catalog_fake_function
21/03/14 15:01:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_function: default.catalog_fake_function	
21/03/14 15:01:31 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:31 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:31 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:31 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:01:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:01:32 INFO CodeGenerator: Code generated in 300.361857 ms
21/03/14 15:01:32 INFO CodeGenerator: Code generated in 24.920169 ms
21/03/14 15:01:32 INFO CodeGenerator: Code generated in 46.828051 ms
21/03/14 15:01:33 INFO ContextCleaner: Cleaned accumulator 1
21/03/14 15:01:33 INFO CodeGenerator: Code generated in 31.386466 ms
21/03/14 15:01:33 INFO CodeGenerator: Code generated in 13.845548 ms
21/03/14 15:01:33 INFO CodeGenerator: Code generated in 9.216181 ms
21/03/14 15:01:34 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:01:34 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:135)
21/03/14 15:01:34 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/03/14 15:01:34 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/03/14 15:01:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/03/14 15:01:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/03/14 15:01:34 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135), which has no missing parents
21/03/14 15:01:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 15:01:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 15:01:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:61882 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:01:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:34 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/03/14 15:01:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 4 tasks
21/03/14 15:01:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 9258 bytes)
21/03/14 15:01:34 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 9275 bytes)
21/03/14 15:01:34 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 9258 bytes)
21/03/14 15:01:34 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 9275 bytes)
21/03/14 15:01:34 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
21/03/14 15:01:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:01:34 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
21/03/14 15:01:34 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
21/03/14 15:01:34 INFO Executor: Fetching spark://localhost:61881/jars/sparklyr-2.4-2.11.jar with timestamp 1615730480773
21/03/14 15:01:34 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:61881 after 27 ms (0 ms spent in bootstraps)
21/03/14 15:01:34 INFO Utils: Fetching spark://localhost:61881/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-a0c8ab49-15d6-4c34-93b9-aad4df91ece7/userFiles-a916af1a-07f4-413b-9b6a-d28bc9c2d283/fetchFileTemp2317925336996998698.tmp
21/03/14 15:01:34 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-a0c8ab49-15d6-4c34-93b9-aad4df91ece7/userFiles-a916af1a-07f4-413b-9b6a-d28bc9c2d283/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:01:35 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1542 bytes result sent to driver
21/03/14 15:01:35 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1542 bytes result sent to driver
21/03/14 15:01:35 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:01:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1542 bytes result sent to driver
21/03/14 15:01:35 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 321 ms on localhost (executor driver) (1/4)
21/03/14 15:01:35 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 328 ms on localhost (executor driver) (2/4)
21/03/14 15:01:35 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 329 ms on localhost (executor driver) (3/4)
21/03/14 15:01:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 348 ms on localhost (executor driver) (4/4)
21/03/14 15:01:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:01:35 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:135) finished in 0.869 s
21/03/14 15:01:35 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:01:35 INFO DAGScheduler: running: Set()
21/03/14 15:01:35 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/03/14 15:01:35 INFO DAGScheduler: failed: Set()
21/03/14 15:01:35 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135), which has no missing parents
21/03/14 15:01:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:01:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:01:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:61882 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:01:35 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:01:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:01:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:01:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 4)
21/03/14 15:01:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
21/03/14 15:01:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
21/03/14 15:01:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 4). 1825 bytes result sent to driver
21/03/14 15:01:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 4) in 58 ms on localhost (executor driver) (1/1)
21/03/14 15:01:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:01:35 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.071 s
21/03/14 15:01:35 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 1.049303 s
21/03/14 15:01:35 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:01:35 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:01:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:01:35 INFO MemoryStore: MemoryStore cleared
21/03/14 15:01:35 INFO BlockManager: BlockManager stopped
21/03/14 15:01:35 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:01:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:01:35 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:01:35 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:01:35 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-a0c8ab49-15d6-4c34-93b9-aad4df91ece7
21/03/14 15:01:35 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-30e72278-3c8f-449d-bf5d-a775946698df
21/03/14 15:01:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:01:38 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:01:38 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:01:38 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:01:38 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:01:38 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:01:38 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:01:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:01:39 INFO Utils: Successfully started service 'sparkDriver' on port 61905.
21/03/14 15:01:39 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:01:39 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:01:39 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:01:39 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:01:39 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-643c06b9-7612-426c-a967-fb304eef0bbe
21/03/14 15:01:39 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:01:39 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:01:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:01:39 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:01:39 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:61905/jars/sparklyr-2.4-2.11.jar with timestamp 1615730499644
21/03/14 15:01:39 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:01:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61907.
21/03/14 15:01:39 INFO NettyBlockTransferService: Server created on localhost:61907
21/03/14 15:01:39 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:01:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 61907, None)
21/03/14 15:01:39 INFO BlockManagerMasterEndpoint: Registering block manager localhost:61907 with 912.3 MB RAM, BlockManagerId(driver, localhost, 61907, None)
21/03/14 15:01:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 61907, None)
21/03/14 15:01:39 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 61907, None)
21/03/14 15:01:40 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:01:40 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:01:40 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:01:41 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:01:44 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:01:45 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:01:45 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:01:45 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:01:45 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:01:47 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:01:48 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:01:48 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:01:49 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:01:49 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:01:49 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:01:49 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:01:49 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:01:49 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:01:49 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:01:49 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:01:49 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:01:49 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:01:49 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:01:49 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:01:49 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:01:49 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:01:50 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/dbfd06f4-3ac9-41c4-9fa7-5b6e09197e87_resources
21/03/14 15:01:50 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/dbfd06f4-3ac9-41c4-9fa7-5b6e09197e87
21/03/14 15:01:50 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/dbfd06f4-3ac9-41c4-9fa7-5b6e09197e87
21/03/14 15:01:50 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/dbfd06f4-3ac9-41c4-9fa7-5b6e09197e87/_tmp_space.db
21/03/14 15:01:50 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:01:50 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:50 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:50 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:01:50 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:01:50 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:01:50 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
21/03/14 15:01:50 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:01:50 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:01:51 INFO CodeGenerator: Code generated in 266.589369 ms
21/03/14 15:01:51 INFO CodeGenerator: Code generated in 21.540952 ms
21/03/14 15:01:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 284.3 KB, free 912.0 MB)
21/03/14 15:01:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.9 KB, free 912.0 MB)
21/03/14 15:01:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:61907 (size: 23.9 KB, free: 912.3 MB)
21/03/14 15:01:51 INFO SparkContext: Created broadcast 0 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:01:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:01:52 INFO SparkContext: Starting job: createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:01:52 INFO DAGScheduler: Got job 0 (createTable at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:01:52 INFO DAGScheduler: Final stage: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0)
21/03/14 15:01:52 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:01:52 INFO DAGScheduler: Missing parents: List()
21/03/14 15:01:52 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:01:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 912.0 MB)
21/03/14 15:01:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.0 MB)
21/03/14 15:01:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:61907 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:01:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:01:52 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:01:52 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8362 bytes)
21/03/14 15:01:52 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:01:52 INFO Executor: Fetching spark://localhost:61905/jars/sparklyr-2.4-2.11.jar with timestamp 1615730499644
21/03/14 15:01:52 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:61905 after 27 ms (0 ms spent in bootstraps)
21/03/14 15:01:52 INFO Utils: Fetching spark://localhost:61905/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-0ab24744-4da2-4b01-b648-75178a787993/userFiles-33a45109-7002-44a6-af3e-3d07676c7c64/fetchFileTemp7651217915125383624.tmp
21/03/14 15:01:52 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-0ab24744-4da2-4b01-b648-75178a787993/userFiles-33a45109-7002-44a6-af3e-3d07676c7c64/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:01:52 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpPg7xRc/file1593d65f40a27, range: 0-1303, partition values: [empty row]
21/03/14 15:01:52 INFO CodeGenerator: Code generated in 13.653411 ms
21/03/14 15:01:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1372 bytes result sent to driver
21/03/14 15:01:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 332 ms on localhost (executor driver) (1/1)
21/03/14 15:01:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:01:52 INFO DAGScheduler: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0) finished in 0.473 s
21/03/14 15:01:52 INFO DAGScheduler: Job 0 finished: createTable at NativeMethodAccessorImpl.java:0, took 0.562558 s
21/03/14 15:01:52 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:01:52 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:01:52 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:01:52 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:01:52 INFO CodeGenerator: Code generated in 9.864415 ms
21/03/14 15:01:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 284.3 KB, free 911.7 MB)
21/03/14 15:01:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.7 MB)
21/03/14 15:01:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:61907 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:01:53 INFO SparkContext: Created broadcast 2 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:01:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:01:53 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:53 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:53 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:01:53 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:01:53 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:53 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:53 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:01:53 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:01:53 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `default`.`mtcars` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.
21/03/14 15:01:53 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:01:53 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:01:53 INFO HiveMetaStore: 0: create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615730503, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpPg7xRc/file1593d65f40a27, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
21/03/14 15:01:53 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615730503, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpPg7xRc/file1593d65f40a27, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
21/03/14 15:01:53 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__
21/03/14 15:01:53 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:01:53 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:01:53 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:01:53 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:01:53 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:01:54 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:01:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:01:54 INFO CodeGenerator: Code generated in 17.467032 ms
21/03/14 15:01:54 INFO CodeGenerator: Code generated in 15.396614 ms
21/03/14 15:01:54 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:01:54 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:01:54 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:01:54 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:01:54 INFO DAGScheduler: Missing parents: List()
21/03/14 15:01:54 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135), which has no missing parents
21/03/14 15:01:54 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.5 KB, free 911.7 MB)
21/03/14 15:01:54 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 15:01:54 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:61907 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:01:54 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:01:54 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:01:54 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:01:54 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:01:54 INFO CodeGenerator: Code generated in 10.297977 ms
21/03/14 15:01:54 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1286 bytes result sent to driver
21/03/14 15:01:54 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on localhost (executor driver) (1/1)
21/03/14 15:01:54 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:01:54 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.043 s
21/03/14 15:01:54 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.047541 s
21/03/14 15:01:54 INFO CodeGenerator: Code generated in 20.103853 ms
21/03/14 15:01:54 INFO CodeGenerator: Code generated in 13.795963 ms
21/03/14 15:01:54 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:01:54 INFO DAGScheduler: Registering RDD 16 (count at utils.scala:135)
21/03/14 15:01:54 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:01:54 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:01:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:01:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:01:54 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135), which has no missing parents
21/03/14 15:01:54 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.4 KB, free 911.7 MB)
21/03/14 15:01:54 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.7 MB)
21/03/14 15:01:54 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:61907 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:01:54 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:01:54 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:01:54 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:01:54 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:01:55 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:01:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 75 ms on localhost (executor driver) (1/1)
21/03/14 15:01:55 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:01:55 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.093 s
21/03/14 15:01:55 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:01:55 INFO DAGScheduler: running: Set()
21/03/14 15:01:55 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:01:55 INFO DAGScheduler: failed: Set()
21/03/14 15:01:55 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135), which has no missing parents
21/03/14 15:01:55 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 15:01:55 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 15:01:55 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:61907 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:01:55 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:01:55 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:01:55 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:01:55 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:01:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:01:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
21/03/14 15:01:55 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:01:55 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 73 ms on localhost (executor driver) (1/1)
21/03/14 15:01:55 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:01:55 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.085 s
21/03/14 15:01:55 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.213736 s
21/03/14 15:01:55 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:01:55 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:01:55 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:01:55 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:01:55 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:01:55 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:01:55 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:01:55 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:01:55 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:01:55 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:01:55 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:01:55 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:01:55 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:01:55 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:01:55 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 284.5 KB, free 911.4 MB)
21/03/14 15:01:55 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.4 MB)
21/03/14 15:01:55 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:61907 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:01:55 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:01:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:01:55 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:01:55 INFO DAGScheduler: Registering RDD 27 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:01:55 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:01:55 INFO DAGScheduler: Final stage: ResultStage 5 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:01:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 15:01:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 15:01:55 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:01:55 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 911.3 MB)
21/03/14 15:01:55 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 12.2 KB, free 911.3 MB)
21/03/14 15:01:55 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:61907 (size: 12.2 KB, free: 912.2 MB)
21/03/14 15:01:55 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:01:55 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:01:55 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:01:55 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:01:55 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpPg7xRc/file1593d65f40a27, range: 0-1303, partition values: [empty row]
21/03/14 15:01:55 INFO CodeGenerator: Code generated in 19.00659 ms
21/03/14 15:01:56 INFO MemoryStore: Block rdd_22_0 stored as values in memory (estimated size 4.1 KB, free 911.3 MB)
21/03/14 15:01:56 INFO BlockManagerInfo: Added rdd_22_0 in memory on localhost:61907 (size: 4.1 KB, free: 912.2 MB)
21/03/14 15:01:56 INFO CodeGenerator: Code generated in 7.356421 ms
21/03/14 15:01:56 INFO CodeGenerator: Code generated in 18.916533 ms
21/03/14 15:01:56 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1871 bytes result sent to driver
21/03/14 15:01:56 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 199 ms on localhost (executor driver) (1/1)
21/03/14 15:01:56 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:01:56 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.247 s
21/03/14 15:01:56 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:01:56 INFO DAGScheduler: running: Set()
21/03/14 15:01:56 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 15:01:56 INFO DAGScheduler: failed: Set()
21/03/14 15:01:56 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:01:56 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 15:01:56 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 15:01:56 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:61907 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:01:56 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:01:56 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:01:56 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:01:56 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:01:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:01:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:01:56 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1782 bytes result sent to driver
21/03/14 15:01:56 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:01:56 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:01:56 INFO DAGScheduler: ResultStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.020 s
21/03/14 15:01:56 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.278597 s
21/03/14 15:01:56 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:01:56 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:01:56 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:01:56 INFO DAGScheduler: Registering RDD 35 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:01:56 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:01:56 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:01:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
21/03/14 15:01:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
21/03/14 15:01:56 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:01:56 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 25.9 KB, free 911.3 MB)
21/03/14 15:01:56 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.1 KB, free 911.3 MB)
21/03/14 15:01:56 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:61907 (size: 12.1 KB, free: 912.2 MB)
21/03/14 15:01:56 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:01:56 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:01:56 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:01:56 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:01:56 INFO BlockManager: Found block rdd_22_0 locally
21/03/14 15:01:56 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1871 bytes result sent to driver
21/03/14 15:01:56 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 15 ms on localhost (executor driver) (1/1)
21/03/14 15:01:56 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:01:56 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.033 s
21/03/14 15:01:56 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:01:56 INFO DAGScheduler: running: Set()
21/03/14 15:01:56 INFO DAGScheduler: waiting: Set(ResultStage 7)
21/03/14 15:01:56 INFO DAGScheduler: failed: Set()
21/03/14 15:01:56 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:01:56 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 15:01:56 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 15:01:56 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:61907 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:01:56 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:01:56 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/14 15:01:56 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 94
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 108
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 192
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 194
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 117
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 15:01:56 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 15:01:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:01:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:01:56 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1825 bytes result sent to driver
21/03/14 15:01:56 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:01:56 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 15:01:56 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.076 s
21/03/14 15:01:56 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.117709 s
21/03/14 15:01:56 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:61907 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 12
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 193
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 137
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 171
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 73
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 182
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 184
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 66
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 199
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 122
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 139
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 97
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 101
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 29
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 74
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 173
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 87
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 104
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 158
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 81
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 70
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 77
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 136
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 85
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 95
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 10
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 71
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 169
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 64
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 67
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 27
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 142
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 140
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 161
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 150
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 14
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 89
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 157
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 99
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 167
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 177
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 176
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 186
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 141
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 68
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 151
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 107
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 134
21/03/14 15:01:56 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:61907 in memory (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 179
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 100
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 189
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 170
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 152
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 116
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 200
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 175
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 188
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 165
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 65
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 183
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 110
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 123
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 126
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 72
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 93
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 25
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 198
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 156
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 118
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 28
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 129
21/03/14 15:01:56 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:61907 in memory (size: 12.2 KB, free: 912.2 MB)
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 80
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 113
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 187
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 160
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 121
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 196
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 131
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 91
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 120
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 111
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 191
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 15:01:56 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:61907 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 9
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 153
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 185
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 190
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 6
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 180
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 164
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 154
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 82
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 124
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 75
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 96
21/03/14 15:01:56 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:61907 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 76
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 19
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 83
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 133
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 13
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 178
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 105
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 37
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 125
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 86
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 144
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 90
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 155
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 23
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 162
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 21
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 16
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 84
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 69
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 30
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 26
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 195
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 20
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 15
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 8
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 172
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 88
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 7
21/03/14 15:01:56 INFO ContextCleaner: Cleaned shuffle 0
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 78
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 197
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 163
21/03/14 15:01:56 INFO ContextCleaner: Cleaned shuffle 1
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 135
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 92
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 98
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 127
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 132
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 181
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 115
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 79
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 174
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 112
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 130
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 159
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 22
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 11
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 24
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 109
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 138
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 106
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 18
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 17
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 166
21/03/14 15:01:56 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:61907 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 119
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 168
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 36
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 114
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 143
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 102
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 103
21/03/14 15:01:56 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 15:01:56 INFO MapPartitionsRDD: Removing RDD 22 from persistence list
21/03/14 15:01:56 INFO BlockManager: Removing RDD 22
21/03/14 15:01:56 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:01:56 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:01:56 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:01:56 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:01:56 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:01:56 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:01:56 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 284.5 KB, free 911.1 MB)
21/03/14 15:01:56 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.0 MB)
21/03/14 15:01:56 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:61907 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:01:56 INFO SparkContext: Created broadcast 11 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:01:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:01:56 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:01:56 INFO DAGScheduler: Registering RDD 46 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:01:56 INFO DAGScheduler: Got job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:01:56 INFO DAGScheduler: Final stage: ResultStage 9 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:01:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/03/14 15:01:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
21/03/14 15:01:56 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:01:56 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 25.9 KB, free 911.0 MB)
21/03/14 15:01:56 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 12.1 KB, free 911.0 MB)
21/03/14 15:01:56 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:61907 (size: 12.1 KB, free: 912.2 MB)
21/03/14 15:01:56 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:01:56 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 15:01:56 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:01:56 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/03/14 15:01:56 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpPg7xRc/file1593d65f40a27, range: 0-2539, partition values: [empty row]
21/03/14 15:01:56 INFO MemoryStore: Block rdd_41_0 stored as values in memory (estimated size 4.9 KB, free 911.0 MB)
21/03/14 15:01:56 INFO BlockManagerInfo: Added rdd_41_0 in memory on localhost:61907 (size: 4.9 KB, free: 912.2 MB)
21/03/14 15:01:56 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1871 bytes result sent to driver
21/03/14 15:01:56 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 36 ms on localhost (executor driver) (1/1)
21/03/14 15:01:56 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 15:01:56 INFO DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.048 s
21/03/14 15:01:56 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:01:56 INFO DAGScheduler: running: Set()
21/03/14 15:01:56 INFO DAGScheduler: waiting: Set(ResultStage 9)
21/03/14 15:01:56 INFO DAGScheduler: failed: Set()
21/03/14 15:01:56 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[49] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:01:56 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.1 KB, free 911.0 MB)
21/03/14 15:01:56 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.0 MB)
21/03/14 15:01:56 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:61907 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:01:56 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 15:01:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[49] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:01:56 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 15:01:56 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:01:56 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/03/14 15:01:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:01:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:01:56 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1782 bytes result sent to driver
21/03/14 15:01:56 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:01:56 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 15:01:56 INFO DAGScheduler: ResultStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.013 s
21/03/14 15:01:56 INFO DAGScheduler: Job 5 finished: count at NativeMethodAccessorImpl.java:0, took 0.069202 s
21/03/14 15:01:56 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:01:56 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:01:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:01:56 INFO MemoryStore: MemoryStore cleared
21/03/14 15:01:56 INFO BlockManager: BlockManager stopped
21/03/14 15:01:56 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:01:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:01:56 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:01:56 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:01:56 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-0ab24744-4da2-4b01-b648-75178a787993
21/03/14 15:01:56 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-b322dc0c-caa8-48c6-86de-591410b9a0f0
21/03/14 15:01:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:02:00 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:02:00 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:02:00 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:02:00 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:02:00 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:02:00 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:02:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:02:00 INFO Utils: Successfully started service 'sparkDriver' on port 62009.
21/03/14 15:02:00 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:02:00 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:02:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:02:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:02:00 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-09c68759-216a-42f1-9085-97ee454f06de
21/03/14 15:02:00 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:02:00 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:02:00 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:02:00 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:02:01 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:62009/jars/sparklyr-2.4-2.11.jar with timestamp 1615730521024
21/03/14 15:02:01 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:02:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62010.
21/03/14 15:02:01 INFO NettyBlockTransferService: Server created on localhost:62010
21/03/14 15:02:01 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:02:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 62010, None)
21/03/14 15:02:01 INFO BlockManagerMasterEndpoint: Registering block manager localhost:62010 with 912.3 MB RAM, BlockManagerId(driver, localhost, 62010, None)
21/03/14 15:02:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 62010, None)
21/03/14 15:02:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 62010, None)
21/03/14 15:02:01 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:02:01 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:02:01 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:02:02 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:02:05 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:02:06 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:02:06 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:02:06 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:02:06 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:02:08 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:02:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:02:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:02:10 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:02:10 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:02:10 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:02:10 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:02:10 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:02:10 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:02:11 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:02:11 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:02:11 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:02:11 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:02:11 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:02:11 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:02:11 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:02:11 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:02:11 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/32400e8c-fbb5-47ff-913a-d74d7e1c1fdf_resources
21/03/14 15:02:11 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/32400e8c-fbb5-47ff-913a-d74d7e1c1fdf
21/03/14 15:02:11 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/32400e8c-fbb5-47ff-913a-d74d7e1c1fdf
21/03/14 15:02:11 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/32400e8c-fbb5-47ff-913a-d74d7e1c1fdf/_tmp_space.db
21/03/14 15:02:11 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:02:11 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:02:11 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:02:11 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:11 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:12 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:02:12 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
21/03/14 15:02:12 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:02:12 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:02:12 INFO CodeGenerator: Code generated in 286.585573 ms
21/03/14 15:02:12 INFO CodeGenerator: Code generated in 33.553401 ms
21/03/14 15:02:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 284.3 KB, free 912.0 MB)
21/03/14 15:02:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.9 KB, free 912.0 MB)
21/03/14 15:02:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:62010 (size: 23.9 KB, free: 912.3 MB)
21/03/14 15:02:12 INFO SparkContext: Created broadcast 0 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:02:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:02:13 INFO SparkContext: Starting job: createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:02:13 INFO DAGScheduler: Got job 0 (createTable at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:02:13 INFO DAGScheduler: Final stage: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0)
21/03/14 15:02:13 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:02:13 INFO DAGScheduler: Missing parents: List()
21/03/14 15:02:13 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:02:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 912.0 MB)
21/03/14 15:02:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.0 MB)
21/03/14 15:02:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:62010 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:02:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:02:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8362 bytes)
21/03/14 15:02:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:02:13 INFO Executor: Fetching spark://localhost:62009/jars/sparklyr-2.4-2.11.jar with timestamp 1615730521024
21/03/14 15:02:13 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:62009 after 26 ms (0 ms spent in bootstraps)
21/03/14 15:02:13 INFO Utils: Fetching spark://localhost:62009/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-2b99b556-176d-4703-86f5-6ee23006ab80/userFiles-9f8a437f-f9c6-4606-be35-388657df9cc0/fetchFileTemp8941692473717287302.tmp
21/03/14 15:02:13 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-2b99b556-176d-4703-86f5-6ee23006ab80/userFiles-9f8a437f-f9c6-4606-be35-388657df9cc0/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:02:13 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpPg7xRc/file1593d5cd947c6, range: 0-1303, partition values: [empty row]
21/03/14 15:02:13 INFO CodeGenerator: Code generated in 15.181766 ms
21/03/14 15:02:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1329 bytes result sent to driver
21/03/14 15:02:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 357 ms on localhost (executor driver) (1/1)
21/03/14 15:02:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:02:13 INFO DAGScheduler: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0) finished in 0.470 s
21/03/14 15:02:13 INFO DAGScheduler: Job 0 finished: createTable at NativeMethodAccessorImpl.java:0, took 0.527661 s
21/03/14 15:02:13 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:02:13 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:02:13 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:02:13 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:02:13 INFO CodeGenerator: Code generated in 9.422676 ms
21/03/14 15:02:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 284.3 KB, free 911.7 MB)
21/03/14 15:02:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.7 MB)
21/03/14 15:02:13 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:62010 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:02:13 INFO SparkContext: Created broadcast 2 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:02:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:02:13 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:02:13 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:02:13 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:13 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:13 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:02:13 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:02:13 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:13 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:14 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `default`.`mtcars` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.
21/03/14 15:02:14 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:02:14 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:02:14 INFO HiveMetaStore: 0: create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615730524, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpPg7xRc/file1593d5cd947c6, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
21/03/14 15:02:14 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615730524, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpPg7xRc/file1593d5cd947c6, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
21/03/14 15:02:14 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__
21/03/14 15:02:14 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:02:14 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:02:14 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:02:14 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:14 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:15 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:15 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:15 INFO CodeGenerator: Code generated in 15.463761 ms
21/03/14 15:02:15 INFO CodeGenerator: Code generated in 20.159112 ms
21/03/14 15:02:15 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:02:15 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:02:15 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:02:15 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:02:15 INFO DAGScheduler: Missing parents: List()
21/03/14 15:02:15 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135), which has no missing parents
21/03/14 15:02:15 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.5 KB, free 911.7 MB)
21/03/14 15:02:15 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 15:02:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:62010 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:02:15 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:15 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:02:15 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:02:15 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:02:15 INFO CodeGenerator: Code generated in 9.482222 ms
21/03/14 15:02:15 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 15:02:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 32 ms on localhost (executor driver) (1/1)
21/03/14 15:02:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:02:15 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.041 s
21/03/14 15:02:15 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.045827 s
21/03/14 15:02:15 INFO CodeGenerator: Code generated in 19.415601 ms
21/03/14 15:02:15 INFO CodeGenerator: Code generated in 14.097205 ms
21/03/14 15:02:15 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:02:15 INFO DAGScheduler: Registering RDD 16 (count at utils.scala:135)
21/03/14 15:02:15 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:02:15 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:02:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:02:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:02:15 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135), which has no missing parents
21/03/14 15:02:15 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.4 KB, free 911.7 MB)
21/03/14 15:02:15 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.7 MB)
21/03/14 15:02:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:62010 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:02:15 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:15 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:02:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:02:15 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:02:15 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:02:15 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 66 ms on localhost (executor driver) (1/1)
21/03/14 15:02:15 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:02:15 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.085 s
21/03/14 15:02:15 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:02:15 INFO DAGScheduler: running: Set()
21/03/14 15:02:15 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:02:15 INFO DAGScheduler: failed: Set()
21/03/14 15:02:15 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135), which has no missing parents
21/03/14 15:02:15 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 15:02:15 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 15:02:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:62010 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:02:15 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:15 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:02:15 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:02:15 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:02:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:02:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
21/03/14 15:02:15 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:02:15 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 48 ms on localhost (executor driver) (1/1)
21/03/14 15:02:15 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:02:15 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.062 s
21/03/14 15:02:15 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.174923 s
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:16 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:02:16 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:02:16 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:02:16 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:16 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:16 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:16 INFO CodeGenerator: Code generated in 38.770955 ms
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 114
21/03/14 15:02:16 INFO CodeGenerator: Code generated in 14.888469 ms
21/03/14 15:02:16 INFO CodeGenerator: Code generated in 12.794878 ms
21/03/14 15:02:16 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:62010 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 29
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 67
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 26
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 128
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 21
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 92
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 37
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 10
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 90
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 17
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 121
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 28
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 113
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 13
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 99
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 110
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 108
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 68
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 126
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 88
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 124
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 69
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 73
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 6
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 15
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 85
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 91
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 94
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 86
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 78
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 81
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 102
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 119
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 106
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 22
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 72
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 75
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 123
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 71
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 101
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 16
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 66
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 100
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 20
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 76
21/03/14 15:02:16 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:62010 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 120
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 93
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 64
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 87
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 84
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 23
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 30
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 109
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 112
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 96
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 115
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 117
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 70
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 98
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 125
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 14
21/03/14 15:02:16 INFO ContextCleaner: Cleaned shuffle 0
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 80
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 36
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 9
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 18
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 79
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 107
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 12
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 24
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 11
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 27
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 65
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 95
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 82
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 104
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 77
21/03/14 15:02:16 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:62010 in memory (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 15:02:16 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:62010 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 7
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 116
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 122
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 127
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 74
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 111
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 25
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 103
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 89
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 19
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 105
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 8
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 83
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 97
21/03/14 15:02:16 INFO ContextCleaner: Cleaned accumulator 118
21/03/14 15:02:16 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:02:16 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135)
21/03/14 15:02:16 INFO DAGScheduler: Got job 3 (count at utils.scala:135) with 1 output partitions
21/03/14 15:02:16 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/03/14 15:02:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 15:02:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 15:02:16 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/03/14 15:02:16 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.9 KB, free 911.7 MB)
21/03/14 15:02:16 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.2 KB, free 911.7 MB)
21/03/14 15:02:16 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:62010 (size: 4.2 KB, free: 912.2 MB)
21/03/14 15:02:16 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:16 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:02:16 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 15:02:16 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:02:16 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1499 bytes result sent to driver
21/03/14 15:02:16 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 10 ms on localhost (executor driver) (1/1)
21/03/14 15:02:16 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:02:16 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.019 s
21/03/14 15:02:16 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:02:16 INFO DAGScheduler: running: Set()
21/03/14 15:02:16 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 15:02:16 INFO DAGScheduler: failed: Set()
21/03/14 15:02:16 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/03/14 15:02:16 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 15:02:16 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 15:02:16 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:62010 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:02:16 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:16 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:02:16 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:02:16 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:02:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:02:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:02:16 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1825 bytes result sent to driver
21/03/14 15:02:16 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:02:16 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:02:16 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.015 s
21/03/14 15:02:16 INFO DAGScheduler: Job 3 finished: count at utils.scala:135, took 0.038765 s
21/03/14 15:02:17 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:17 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:17 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:02:17 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:02:17 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:17 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:17 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:17 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:17 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:17 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:17 INFO HiveMetaStore: 0: get_table : db=default tbl=fake_table
21/03/14 15:02:17 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=fake_table	
21/03/14 15:02:17 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:17 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:17 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:17 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:17 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:17 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:17 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:02:17 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:02:17 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:02:17 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:02:17 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:17 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:17 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:02:17 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:02:17 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:02:17 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:02:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:02:17 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:02:17 INFO CodeGenerator: Code generated in 9.900949 ms
21/03/14 15:02:17 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 15:02:17 INFO DAGScheduler: Got job 4 (collect at utils.scala:61) with 1 output partitions
21/03/14 15:02:17 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:61)
21/03/14 15:02:17 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:02:17 INFO DAGScheduler: Missing parents: List()
21/03/14 15:02:17 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[31] at map at utils.scala:54), which has no missing parents
21/03/14 15:02:17 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 6.0 KB, free 911.7 MB)
21/03/14 15:02:17 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.4 KB, free 911.7 MB)
21/03/14 15:02:17 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:62010 (size: 3.4 KB, free: 912.2 MB)
21/03/14 15:02:17 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[31] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:17 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:02:17 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
21/03/14 15:02:17 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:02:17 INFO CodeGenerator: Code generated in 8.380584 ms
21/03/14 15:02:17 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 979 bytes result sent to driver
21/03/14 15:02:17 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 19 ms on localhost (executor driver) (1/1)
21/03/14 15:02:17 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:02:17 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:61) finished in 0.025 s
21/03/14 15:02:17 INFO DAGScheduler: Job 4 finished: collect at utils.scala:61, took 0.027356 s
21/03/14 15:02:17 INFO CodeGenerator: Code generated in 10.80012 ms
21/03/14 15:02:17 INFO CodeGenerator: Code generated in 8.879645 ms
21/03/14 15:02:17 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:02:17 INFO DAGScheduler: Got job 5 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:02:17 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:135)
21/03/14 15:02:17 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:02:17 INFO DAGScheduler: Missing parents: List()
21/03/14 15:02:17 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[35] at collect at utils.scala:135), which has no missing parents
21/03/14 15:02:17 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 6.3 KB, free 911.7 MB)
21/03/14 15:02:17 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 15:02:17 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:62010 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:02:17 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:17 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/14 15:02:17 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:02:17 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 15:02:17 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1286 bytes result sent to driver
21/03/14 15:02:17 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 9 ms on localhost (executor driver) (1/1)
21/03/14 15:02:17 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 15:02:17 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:135) finished in 0.016 s
21/03/14 15:02:17 INFO DAGScheduler: Job 5 finished: collect at utils.scala:135, took 0.018316 s
21/03/14 15:02:17 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:02:17 INFO DAGScheduler: Registering RDD 38 (count at utils.scala:135)
21/03/14 15:02:17 INFO DAGScheduler: Got job 6 (count at utils.scala:135) with 1 output partitions
21/03/14 15:02:17 INFO DAGScheduler: Final stage: ResultStage 9 (count at utils.scala:135)
21/03/14 15:02:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/03/14 15:02:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
21/03/14 15:02:17 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[38] at count at utils.scala:135), which has no missing parents
21/03/14 15:02:17 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.4 KB, free 911.6 MB)
21/03/14 15:02:17 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.6 MB)
21/03/14 15:02:17 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:62010 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:02:17 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[38] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:17 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 15:02:17 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:02:17 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/03/14 15:02:17 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1499 bytes result sent to driver
21/03/14 15:02:17 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 11 ms on localhost (executor driver) (1/1)
21/03/14 15:02:17 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 15:02:17 INFO DAGScheduler: ShuffleMapStage 8 (count at utils.scala:135) finished in 0.019 s
21/03/14 15:02:17 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:02:17 INFO DAGScheduler: running: Set()
21/03/14 15:02:17 INFO DAGScheduler: waiting: Set(ResultStage 9)
21/03/14 15:02:17 INFO DAGScheduler: failed: Set()
21/03/14 15:02:17 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[41] at count at utils.scala:135), which has no missing parents
21/03/14 15:02:17 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 15:02:17 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 15:02:17 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:62010 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:02:17 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[41] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:17 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 15:02:17 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:02:17 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/03/14 15:02:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:02:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:02:17 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1782 bytes result sent to driver
21/03/14 15:02:17 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:02:17 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 15:02:17 INFO DAGScheduler: ResultStage 9 (count at utils.scala:135) finished in 0.015 s
21/03/14 15:02:17 INFO DAGScheduler: Job 6 finished: count at utils.scala:135, took 0.040323 s
21/03/14 15:02:18 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:02:18 INFO DAGScheduler: Got job 7 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:02:18 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:135)
21/03/14 15:02:18 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:02:18 INFO DAGScheduler: Missing parents: List()
21/03/14 15:02:18 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[44] at collect at utils.scala:135), which has no missing parents
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 6.3 KB, free 911.6 MB)
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.6 MB)
21/03/14 15:02:18 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:62010 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:02:18 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[44] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:18 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/03/14 15:02:18 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:02:18 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/03/14 15:02:18 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1286 bytes result sent to driver
21/03/14 15:02:18 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
21/03/14 15:02:18 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/03/14 15:02:18 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:135) finished in 0.013 s
21/03/14 15:02:18 INFO DAGScheduler: Job 7 finished: collect at utils.scala:135, took 0.016025 s
21/03/14 15:02:18 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:02:18 INFO DAGScheduler: Registering RDD 47 (count at utils.scala:135)
21/03/14 15:02:18 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/03/14 15:02:18 INFO DAGScheduler: Final stage: ResultStage 12 (count at utils.scala:135)
21/03/14 15:02:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
21/03/14 15:02:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
21/03/14 15:02:18 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[47] at count at utils.scala:135), which has no missing parents
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.4 KB, free 911.6 MB)
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.6 MB)
21/03/14 15:02:18 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:62010 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:02:18 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[47] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:18 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/03/14 15:02:18 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:02:18 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/03/14 15:02:18 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1499 bytes result sent to driver
21/03/14 15:02:18 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 9 ms on localhost (executor driver) (1/1)
21/03/14 15:02:18 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/03/14 15:02:18 INFO DAGScheduler: ShuffleMapStage 11 (count at utils.scala:135) finished in 0.016 s
21/03/14 15:02:18 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:02:18 INFO DAGScheduler: running: Set()
21/03/14 15:02:18 INFO DAGScheduler: waiting: Set(ResultStage 12)
21/03/14 15:02:18 INFO DAGScheduler: failed: Set()
21/03/14 15:02:18 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[50] at count at utils.scala:135), which has no missing parents
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 15:02:18 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:62010 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:02:18 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[50] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:18 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/03/14 15:02:18 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:02:18 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/03/14 15:02:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:02:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:02:18 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1782 bytes result sent to driver
21/03/14 15:02:18 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 10 ms on localhost (executor driver) (1/1)
21/03/14 15:02:18 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/03/14 15:02:18 INFO DAGScheduler: ResultStage 12 (count at utils.scala:135) finished in 0.017 s
21/03/14 15:02:18 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.038887 s
21/03/14 15:02:18 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:18 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:18 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:18 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:02:18 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:02:18 INFO FileSourceStrategy: Output Data Schema: struct<>
21/03/14 15:02:18 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:02:18 INFO CodeGenerator: Code generated in 12.866576 ms
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 284.5 KB, free 911.3 MB)
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.3 MB)
21/03/14 15:02:18 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:62010 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:02:18 INFO SparkContext: Created broadcast 15 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:02:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:02:18 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:02:18 INFO DAGScheduler: Registering RDD 53 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:02:18 INFO DAGScheduler: Got job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:02:18 INFO DAGScheduler: Final stage: ResultStage 14 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:02:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/03/14 15:02:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/03/14 15:02:18 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 14.2 KB, free 911.3 MB)
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.3 MB)
21/03/14 15:02:18 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:62010 (size: 8.0 KB, free: 912.2 MB)
21/03/14 15:02:18 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:18 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/03/14 15:02:18 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:02:18 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/03/14 15:02:18 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpPg7xRc/file1593d5cd947c6, range: 0-1303, partition values: [empty row]
21/03/14 15:02:18 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1585 bytes result sent to driver
21/03/14 15:02:18 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 43 ms on localhost (executor driver) (1/1)
21/03/14 15:02:18 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/03/14 15:02:18 INFO DAGScheduler: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.063 s
21/03/14 15:02:18 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:02:18 INFO DAGScheduler: running: Set()
21/03/14 15:02:18 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/03/14 15:02:18 INFO DAGScheduler: failed: Set()
21/03/14 15:02:18 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 15:02:18 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:62010 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:02:18 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:18 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/03/14 15:02:18 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:02:18 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/03/14 15:02:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:02:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:02:18 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1782 bytes result sent to driver
21/03/14 15:02:18 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:02:18 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/03/14 15:02:18 INFO DAGScheduler: ResultStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0.012 s
21/03/14 15:02:18 INFO DAGScheduler: Job 9 finished: count at NativeMethodAccessorImpl.java:0, took 0.079693 s
21/03/14 15:02:18 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:02:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:02:18 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:18 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:18 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:18 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:18 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:02:18 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:02:18 INFO FileSourceStrategy: Output Data Schema: struct<>
21/03/14 15:02:18 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 284.5 KB, free 911.0 MB)
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.0 MB)
21/03/14 15:02:18 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:62010 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:02:18 INFO SparkContext: Created broadcast 18 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:02:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:02:18 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:02:18 INFO DAGScheduler: Registering RDD 59 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:02:18 INFO DAGScheduler: Got job 10 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:02:18 INFO DAGScheduler: Final stage: ResultStage 16 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:02:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
21/03/14 15:02:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
21/03/14 15:02:18 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 14.2 KB, free 911.0 MB)
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.9 MB)
21/03/14 15:02:18 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:62010 (size: 8.0 KB, free: 912.2 MB)
21/03/14 15:02:18 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:18 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/03/14 15:02:18 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:02:18 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/03/14 15:02:18 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpPg7xRc/file1593d5cd947c6, range: 0-2539, partition values: [empty row]
21/03/14 15:02:18 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1585 bytes result sent to driver
21/03/14 15:02:18 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 15 ms on localhost (executor driver) (1/1)
21/03/14 15:02:18 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/03/14 15:02:18 INFO DAGScheduler: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.026 s
21/03/14 15:02:18 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:02:18 INFO DAGScheduler: running: Set()
21/03/14 15:02:18 INFO DAGScheduler: waiting: Set(ResultStage 16)
21/03/14 15:02:18 INFO DAGScheduler: failed: Set()
21/03/14 15:02:18 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.1 KB, free 910.9 MB)
21/03/14 15:02:18 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.8 KB, free 910.9 MB)
21/03/14 15:02:18 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:62010 (size: 3.8 KB, free: 912.1 MB)
21/03/14 15:02:18 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:18 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/03/14 15:02:18 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:02:18 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/03/14 15:02:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:02:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:02:18 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1782 bytes result sent to driver
21/03/14 15:02:18 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 6 ms on localhost (executor driver) (1/1)
21/03/14 15:02:18 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/03/14 15:02:18 INFO DAGScheduler: ResultStage 16 (count at NativeMethodAccessorImpl.java:0) finished in 0.013 s
21/03/14 15:02:18 INFO DAGScheduler: Job 10 finished: count at NativeMethodAccessorImpl.java:0, took 0.043504 s
21/03/14 15:02:18 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:02:19 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:02:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:02:19 INFO MemoryStore: MemoryStore cleared
21/03/14 15:02:19 INFO BlockManager: BlockManager stopped
21/03/14 15:02:19 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:02:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:02:19 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:02:19 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:02:19 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-2312b9eb-1ea6-405b-af0b-5085c7973917
21/03/14 15:02:19 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-2b99b556-176d-4703-86f5-6ee23006ab80
21/03/14 15:02:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:02:22 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:02:22 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:02:22 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:02:22 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:02:22 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:02:22 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:02:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:02:22 INFO Utils: Successfully started service 'sparkDriver' on port 62029.
21/03/14 15:02:22 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:02:22 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:02:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:02:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:02:23 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-787112f0-5171-43ef-a61d-5a4d2c742a43
21/03/14 15:02:23 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:02:23 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:02:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:02:23 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:02:23 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:62029/jars/sparklyr-2.4-2.11.jar with timestamp 1615730543359
21/03/14 15:02:23 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:02:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62030.
21/03/14 15:02:23 INFO NettyBlockTransferService: Server created on localhost:62030
21/03/14 15:02:23 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:02:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 62030, None)
21/03/14 15:02:23 INFO BlockManagerMasterEndpoint: Registering block manager localhost:62030 with 912.3 MB RAM, BlockManagerId(driver, localhost, 62030, None)
21/03/14 15:02:23 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 62030, None)
21/03/14 15:02:23 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 62030, None)
21/03/14 15:02:24 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:02:24 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:02:24 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:02:24 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:02:27 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:02:28 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:02:28 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:02:28 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:02:28 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:02:30 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:02:31 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:02:31 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:02:32 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:02:32 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:02:32 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:02:32 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:02:33 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:02:33 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:02:33 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:02:33 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:02:33 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:02:33 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:02:33 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:02:33 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:02:33 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:02:33 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:02:33 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/e5a19775-a8f5-4018-b63e-2101e8765b31_resources
21/03/14 15:02:33 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/e5a19775-a8f5-4018-b63e-2101e8765b31
21/03/14 15:02:33 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/e5a19775-a8f5-4018-b63e-2101e8765b31
21/03/14 15:02:33 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/e5a19775-a8f5-4018-b63e-2101e8765b31/_tmp_space.db
21/03/14 15:02:33 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:02:33 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:02:33 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:02:33 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:02:33 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:02:33 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:02:33 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:02:33 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:02:33 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:02:33 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:02:33 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:02:33 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:02:34 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 15:02:34 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/03/14 15:02:34 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/03/14 15:02:34 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:02:34 INFO DAGScheduler: Missing parents: List()
21/03/14 15:02:34 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/03/14 15:02:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/03/14 15:02:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/03/14 15:02:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:62030 (size: 3.4 KB, free: 912.3 MB)
21/03/14 15:02:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:02:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/03/14 15:02:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:02:34 INFO Executor: Fetching spark://localhost:62029/jars/sparklyr-2.4-2.11.jar with timestamp 1615730543359
21/03/14 15:02:34 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:62029 after 29 ms (0 ms spent in bootstraps)
21/03/14 15:02:34 INFO Utils: Fetching spark://localhost:62029/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-3fa45f3f-4eee-44a0-99b3-a477bd6d8bc8/userFiles-3e73a542-4aee-46d7-9eb3-2729fd883391/fetchFileTemp4022299424634831111.tmp
21/03/14 15:02:35 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-3fa45f3f-4eee-44a0-99b3-a477bd6d8bc8/userFiles-3e73a542-4aee-46d7-9eb3-2729fd883391/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:02:35 INFO CodeGenerator: Code generated in 326.509922 ms
21/03/14 15:02:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
21/03/14 15:02:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 822 ms on localhost (executor driver) (1/1)
21/03/14 15:02:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:02:35 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 1.201 s
21/03/14 15:02:35 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 1.270537 s
21/03/14 15:02:35 INFO ContextCleaner: Cleaned accumulator 0
21/03/14 15:02:35 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:62030 in memory (size: 3.4 KB, free: 912.3 MB)
21/03/14 15:02:36 INFO CodeGenerator: Code generated in 33.657943 ms
21/03/14 15:02:36 INFO CodeGenerator: Code generated in 27.568455 ms
21/03/14 15:02:36 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:02:36 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:02:36 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:02:36 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:02:36 INFO DAGScheduler: Missing parents: List()
21/03/14 15:02:36 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/03/14 15:02:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 15:02:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 15:02:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:62030 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:02:36 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:02:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:02:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:02:36 INFO CodeGenerator: Code generated in 9.563483 ms
21/03/14 15:02:36 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1286 bytes result sent to driver
21/03/14 15:02:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on localhost (executor driver) (1/1)
21/03/14 15:02:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:02:36 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.047 s
21/03/14 15:02:36 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.051028 s
21/03/14 15:02:36 INFO CodeGenerator: Code generated in 16.453854 ms
21/03/14 15:02:36 INFO CodeGenerator: Code generated in 15.722258 ms
21/03/14 15:02:36 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:02:36 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/03/14 15:02:36 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:02:36 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:02:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:02:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:02:36 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/03/14 15:02:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/03/14 15:02:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/03/14 15:02:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:62030 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:02:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:02:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:02:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:02:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:02:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 63 ms on localhost (executor driver) (1/1)
21/03/14 15:02:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:02:36 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.080 s
21/03/14 15:02:37 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:02:37 INFO DAGScheduler: running: Set()
21/03/14 15:02:37 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:02:37 INFO DAGScheduler: failed: Set()
21/03/14 15:02:37 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/03/14 15:02:37 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:02:37 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:02:37 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:62030 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:02:37 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:37 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:02:37 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:02:37 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:02:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
21/03/14 15:02:37 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:02:37 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 70 ms on localhost (executor driver) (1/1)
21/03/14 15:02:37 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:02:37 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.082 s
21/03/14 15:02:37 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.191962 s
21/03/14 15:02:37 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:02:37 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:02:37 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/03/14 15:02:37 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:02:37 INFO DAGScheduler: Missing parents: List()
21/03/14 15:02:37 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135), which has no missing parents
21/03/14 15:02:37 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 15:02:37 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 15:02:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:62030 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:02:37 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:37 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:02:37 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:02:37 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:02:37 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/03/14 15:02:37 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:02:37 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:02:37 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.017 s
21/03/14 15:02:37 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.020310 s
21/03/14 15:02:37 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:02:37 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:135)
21/03/14 15:02:37 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/14 15:02:37 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/03/14 15:02:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/03/14 15:02:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/03/14 15:02:37 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/03/14 15:02:37 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/03/14 15:02:37 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/03/14 15:02:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:62030 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:02:37 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:37 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:02:37 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:02:37 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:02:37 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/03/14 15:02:37 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 11 ms on localhost (executor driver) (1/1)
21/03/14 15:02:37 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:02:37 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.032 s
21/03/14 15:02:37 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:02:37 INFO DAGScheduler: running: Set()
21/03/14 15:02:37 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/03/14 15:02:37 INFO DAGScheduler: failed: Set()
21/03/14 15:02:37 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/03/14 15:02:37 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 15:02:37 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 15:02:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:62030 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:02:37 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 15:02:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:02:37 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:02:37 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:02:37 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:02:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:02:37 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/03/14 15:02:37 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:02:37 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:02:37 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.016 s
21/03/14 15:02:37 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.053900 s
21/03/14 15:02:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:02:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:02:37 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:02:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:02:37 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:02:37 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:02:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:02:38 INFO MemoryStore: MemoryStore cleared
21/03/14 15:02:38 INFO BlockManager: BlockManager stopped
21/03/14 15:02:38 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:02:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:02:38 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:02:38 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:02:38 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-4b9b12c4-d0d4-4731-b549-7636be8adca9
21/03/14 15:02:38 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-3fa45f3f-4eee-44a0-99b3-a477bd6d8bc8
21/03/14 15:04:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:04:23 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:04:23 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:04:23 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:04:23 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:04:23 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:04:23 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:04:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:04:23 INFO Utils: Successfully started service 'sparkDriver' on port 62249.
21/03/14 15:04:23 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:04:23 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:04:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:04:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:04:23 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-30003037-4ba8-4c06-b853-651f3292d3e7
21/03/14 15:04:23 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:04:23 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:04:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:04:23 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:04:23 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:62249/jars/sparklyr-2.4-2.11.jar with timestamp 1615730663812
21/03/14 15:04:23 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:04:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62253.
21/03/14 15:04:24 INFO NettyBlockTransferService: Server created on localhost:62253
21/03/14 15:04:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:04:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 62253, None)
21/03/14 15:04:24 INFO BlockManagerMasterEndpoint: Registering block manager localhost:62253 with 912.3 MB RAM, BlockManagerId(driver, localhost, 62253, None)
21/03/14 15:04:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 62253, None)
21/03/14 15:04:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 62253, None)
21/03/14 15:04:24 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:04:24 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:04:24 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:04:25 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:04:28 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:04:29 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:04:29 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:04:29 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:04:29 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:04:30 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:04:32 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:04:32 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:04:33 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:04:33 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:04:33 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:04:33 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:04:33 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:04:33 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:04:33 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:04:33 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:04:34 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:04:34 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:04:34 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:04:34 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:04:34 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:04:34 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:04:34 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/668d32d0-acb5-45c4-be3d-253f1bd4a767_resources
21/03/14 15:04:34 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/668d32d0-acb5-45c4-be3d-253f1bd4a767
21/03/14 15:04:34 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/668d32d0-acb5-45c4-be3d-253f1bd4a767
21/03/14 15:04:34 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/668d32d0-acb5-45c4-be3d-253f1bd4a767/_tmp_space.db
21/03/14 15:04:34 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:04:34 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:04:34 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:04:34 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:34 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:35 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:04:35 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
21/03/14 15:04:35 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:04:35 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:04:35 INFO CodeGenerator: Code generated in 228.551726 ms
21/03/14 15:04:35 INFO CodeGenerator: Code generated in 22.586263 ms
21/03/14 15:04:35 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 284.3 KB, free 912.0 MB)
21/03/14 15:04:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.9 KB, free 912.0 MB)
21/03/14 15:04:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:62253 (size: 23.9 KB, free: 912.3 MB)
21/03/14 15:04:36 INFO SparkContext: Created broadcast 0 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:04:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:04:36 INFO SparkContext: Starting job: createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:04:36 INFO DAGScheduler: Got job 0 (createTable at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:04:36 INFO DAGScheduler: Final stage: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0)
21/03/14 15:04:36 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:04:36 INFO DAGScheduler: Missing parents: List()
21/03/14 15:04:36 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:04:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 912.0 MB)
21/03/14 15:04:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.0 MB)
21/03/14 15:04:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:62253 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:04:36 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:04:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:04:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:04:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8362 bytes)
21/03/14 15:04:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:04:36 INFO Executor: Fetching spark://localhost:62249/jars/sparklyr-2.4-2.11.jar with timestamp 1615730663812
21/03/14 15:04:36 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:62249 after 27 ms (0 ms spent in bootstraps)
21/03/14 15:04:36 INFO Utils: Fetching spark://localhost:62249/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-4e4d4ac2-3b9b-492a-88b2-24eb7a847434/userFiles-34035cd4-0e2e-49a1-8954-a0ed175af6fe/fetchFileTemp1133477792311888570.tmp
21/03/14 15:04:36 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-4e4d4ac2-3b9b-492a-88b2-24eb7a847434/userFiles-34035cd4-0e2e-49a1-8954-a0ed175af6fe/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:04:36 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpOSqUuc/file15b495baa073a, range: 0-1303, partition values: [empty row]
21/03/14 15:04:36 INFO CodeGenerator: Code generated in 13.574511 ms
21/03/14 15:04:36 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1329 bytes result sent to driver
21/03/14 15:04:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 324 ms on localhost (executor driver) (1/1)
21/03/14 15:04:36 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:04:37 INFO DAGScheduler: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0) finished in 0.448 s
21/03/14 15:04:37 INFO DAGScheduler: Job 0 finished: createTable at NativeMethodAccessorImpl.java:0, took 0.524878 s
21/03/14 15:04:37 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:04:37 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:04:37 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:04:37 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:04:37 INFO CodeGenerator: Code generated in 8.478072 ms
21/03/14 15:04:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 284.3 KB, free 911.7 MB)
21/03/14 15:04:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.7 MB)
21/03/14 15:04:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:62253 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:04:37 INFO SparkContext: Created broadcast 2 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:04:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:04:37 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:04:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:04:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:37 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:04:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:04:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:37 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `default`.`mtcars` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.
21/03/14 15:04:37 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:04:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:04:37 INFO HiveMetaStore: 0: create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615730667, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpOSqUuc/file15b495baa073a, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
21/03/14 15:04:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615730667, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpOSqUuc/file15b495baa073a, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
21/03/14 15:04:37 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__
21/03/14 15:04:37 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:04:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:04:37 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:04:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:38 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:38 INFO CodeGenerator: Code generated in 18.424126 ms
21/03/14 15:04:38 INFO CodeGenerator: Code generated in 15.011456 ms
21/03/14 15:04:38 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:04:38 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:04:38 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:04:38 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:04:38 INFO DAGScheduler: Missing parents: List()
21/03/14 15:04:38 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135), which has no missing parents
21/03/14 15:04:38 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.5 KB, free 911.7 MB)
21/03/14 15:04:38 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 15:04:38 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:62253 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:04:38 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:04:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:04:38 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:04:38 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:04:38 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:04:38 INFO CodeGenerator: Code generated in 7.408975 ms
21/03/14 15:04:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 15:04:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 27 ms on localhost (executor driver) (1/1)
21/03/14 15:04:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:04:38 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.035 s
21/03/14 15:04:38 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.039721 s
21/03/14 15:04:38 INFO CodeGenerator: Code generated in 18.889201 ms
21/03/14 15:04:38 INFO CodeGenerator: Code generated in 13.310491 ms
21/03/14 15:04:38 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:04:38 INFO DAGScheduler: Registering RDD 16 (count at utils.scala:135)
21/03/14 15:04:38 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:04:38 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:04:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:04:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:04:38 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135), which has no missing parents
21/03/14 15:04:38 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.4 KB, free 911.7 MB)
21/03/14 15:04:38 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.7 MB)
21/03/14 15:04:38 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:62253 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:04:38 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:04:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:04:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:04:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:04:38 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:04:38 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:04:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 58 ms on localhost (executor driver) (1/1)
21/03/14 15:04:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:04:38 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.071 s
21/03/14 15:04:38 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:04:38 INFO DAGScheduler: running: Set()
21/03/14 15:04:38 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:04:38 INFO DAGScheduler: failed: Set()
21/03/14 15:04:38 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135), which has no missing parents
21/03/14 15:04:38 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 15:04:38 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 15:04:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:62253 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:04:38 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:04:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:04:38 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:04:38 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:04:38 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:04:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:04:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
21/03/14 15:04:38 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:04:38 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 50 ms on localhost (executor driver) (1/1)
21/03/14 15:04:38 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:04:38 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.061 s
21/03/14 15:04:38 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.156635 s
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:39 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:04:39 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:04:39 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:04:39 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:39 INFO CodeGenerator: Code generated in 45.974034 ms
21/03/14 15:04:39 INFO CodeGenerator: Code generated in 16.452336 ms
21/03/14 15:04:39 INFO CodeGenerator: Code generated in 11.317996 ms
21/03/14 15:04:39 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:04:39 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135)
21/03/14 15:04:39 INFO DAGScheduler: Got job 3 (count at utils.scala:135) with 1 output partitions
21/03/14 15:04:39 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/03/14 15:04:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 15:04:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 15:04:39 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/03/14 15:04:39 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.9 KB, free 911.6 MB)
21/03/14 15:04:39 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.2 KB, free 911.6 MB)
21/03/14 15:04:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:62253 (size: 4.2 KB, free: 912.2 MB)
21/03/14 15:04:39 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 15:04:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:04:39 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:04:39 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 15:04:39 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:04:39 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1499 bytes result sent to driver
21/03/14 15:04:39 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 11 ms on localhost (executor driver) (1/1)
21/03/14 15:04:39 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:04:39 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.019 s
21/03/14 15:04:39 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:04:39 INFO DAGScheduler: running: Set()
21/03/14 15:04:39 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 15:04:39 INFO DAGScheduler: failed: Set()
21/03/14 15:04:39 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/03/14 15:04:39 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 15:04:39 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 15:04:39 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:62253 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:04:39 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 15:04:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:04:39 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:04:39 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:04:39 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:04:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:04:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:04:39 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1782 bytes result sent to driver
21/03/14 15:04:39 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:04:39 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:04:39 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.015 s
21/03/14 15:04:39 INFO DAGScheduler: Job 3 finished: count at utils.scala:135, took 0.040589 s
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:04:39 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:40 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:40 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:40 INFO HiveMetaStore: 0: get_table : db=default tbl=fake_table
21/03/14 15:04:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=fake_table	
21/03/14 15:04:40 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:40 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:40 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:40 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:04:40 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:04:40 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:04:40 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:04:40 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 169
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 121
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 12
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 7
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 74
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 83
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 131
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 70
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 136
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 130
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 146
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 141
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 160
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 152
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 95
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 134
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 176
21/03/14 15:04:40 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 133
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 26
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 114
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 106
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 155
21/03/14 15:04:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:04:40 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:04:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:04:40 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:04:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:04:40 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:62253 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 194
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 64
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 97
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 22
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 168
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 190
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 132
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 68
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 187
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 66
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 189
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 19
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 150
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 108
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 16
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 179
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 29
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 65
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 184
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 115
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 127
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 72
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 69
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 82
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 79
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 73
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 102
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 128
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 178
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 159
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 142
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 164
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 185
21/03/14 15:04:40 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:62253 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 126
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 107
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 13
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 9
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 81
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 104
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 173
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 140
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 17
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 30
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 135
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 103
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 109
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 85
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 100
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 15
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 67
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 170
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 145
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 21
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 37
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 124
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 112
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 148
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 88
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 92
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 90
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 36
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 118
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 149
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 153
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 91
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 77
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 182
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 161
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 166
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 84
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 157
21/03/14 15:04:40 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:62253 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 10
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 98
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 174
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 110
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 181
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 122
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 117
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 180
21/03/14 15:04:40 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:62253 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 147
21/03/14 15:04:40 INFO ContextCleaner: Cleaned shuffle 0
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 120
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 123
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 23
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 6
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 144
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 138
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 177
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 105
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 80
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 28
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 96
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 111
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 171
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 186
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 76
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 101
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 99
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 188
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 86
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 183
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 162
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 116
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 78
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 129
21/03/14 15:04:40 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:62253 in memory (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 125
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 93
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 25
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 87
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 8
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 24
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 89
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 119
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 143
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 193
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 167
21/03/14 15:04:40 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:62253 in memory (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 175
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 113
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 158
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 75
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 191
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 11
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 139
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 192
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 165
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 137
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 14
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 156
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 94
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 71
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 18
21/03/14 15:04:40 INFO ContextCleaner: Cleaned shuffle 1
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 151
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 172
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 20
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 27
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 163
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 15:04:40 INFO ContextCleaner: Cleaned accumulator 154
21/03/14 15:04:40 INFO CodeGenerator: Code generated in 14.240496 ms
21/03/14 15:04:40 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 15:04:40 INFO DAGScheduler: Got job 4 (collect at utils.scala:61) with 1 output partitions
21/03/14 15:04:40 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:61)
21/03/14 15:04:40 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:04:40 INFO DAGScheduler: Missing parents: List()
21/03/14 15:04:40 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[31] at map at utils.scala:54), which has no missing parents
21/03/14 15:04:40 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 6.0 KB, free 911.7 MB)
21/03/14 15:04:40 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.4 KB, free 911.7 MB)
21/03/14 15:04:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:62253 (size: 3.4 KB, free: 912.3 MB)
21/03/14 15:04:40 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 15:04:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[31] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 15:04:40 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:04:40 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
21/03/14 15:04:40 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:04:40 INFO CodeGenerator: Code generated in 8.47872 ms
21/03/14 15:04:40 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 979 bytes result sent to driver
21/03/14 15:04:40 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 22 ms on localhost (executor driver) (1/1)
21/03/14 15:04:40 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:04:40 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:61) finished in 0.030 s
21/03/14 15:04:40 INFO DAGScheduler: Job 4 finished: collect at utils.scala:61, took 0.033449 s
21/03/14 15:04:40 INFO CodeGenerator: Code generated in 9.661109 ms
21/03/14 15:04:40 INFO CodeGenerator: Code generated in 14.011906 ms
21/03/14 15:04:40 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:04:40 INFO DAGScheduler: Got job 5 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:04:40 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:135)
21/03/14 15:04:40 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:04:40 INFO DAGScheduler: Missing parents: List()
21/03/14 15:04:40 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[35] at collect at utils.scala:135), which has no missing parents
21/03/14 15:04:40 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 6.3 KB, free 911.7 MB)
21/03/14 15:04:40 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 15:04:40 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:62253 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:04:40 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 15:04:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:04:40 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/14 15:04:40 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:04:40 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 15:04:40 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1286 bytes result sent to driver
21/03/14 15:04:40 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 10 ms on localhost (executor driver) (1/1)
21/03/14 15:04:40 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 15:04:40 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:135) finished in 0.018 s
21/03/14 15:04:40 INFO DAGScheduler: Job 5 finished: collect at utils.scala:135, took 0.021480 s
21/03/14 15:04:41 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:04:41 INFO DAGScheduler: Registering RDD 38 (count at utils.scala:135)
21/03/14 15:04:41 INFO DAGScheduler: Got job 6 (count at utils.scala:135) with 1 output partitions
21/03/14 15:04:41 INFO DAGScheduler: Final stage: ResultStage 9 (count at utils.scala:135)
21/03/14 15:04:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/03/14 15:04:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
21/03/14 15:04:41 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[38] at count at utils.scala:135), which has no missing parents
21/03/14 15:04:41 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.4 KB, free 911.7 MB)
21/03/14 15:04:41 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.7 MB)
21/03/14 15:04:41 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:62253 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:04:41 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 15:04:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[38] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:04:41 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 15:04:41 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:04:41 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/03/14 15:04:41 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1499 bytes result sent to driver
21/03/14 15:04:41 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 10 ms on localhost (executor driver) (1/1)
21/03/14 15:04:41 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 15:04:41 INFO DAGScheduler: ShuffleMapStage 8 (count at utils.scala:135) finished in 0.018 s
21/03/14 15:04:41 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:04:41 INFO DAGScheduler: running: Set()
21/03/14 15:04:41 INFO DAGScheduler: waiting: Set(ResultStage 9)
21/03/14 15:04:41 INFO DAGScheduler: failed: Set()
21/03/14 15:04:41 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[41] at count at utils.scala:135), which has no missing parents
21/03/14 15:04:41 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 15:04:41 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 15:04:41 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:62253 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:04:41 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
21/03/14 15:04:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[41] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:04:41 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 15:04:41 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:04:41 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/03/14 15:04:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:04:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:04:41 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1782 bytes result sent to driver
21/03/14 15:04:41 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:04:41 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 15:04:41 INFO DAGScheduler: ResultStage 9 (count at utils.scala:135) finished in 0.018 s
21/03/14 15:04:41 INFO DAGScheduler: Job 6 finished: count at utils.scala:135, took 0.041901 s
21/03/14 15:04:41 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:04:41 INFO DAGScheduler: Got job 7 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:04:41 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:135)
21/03/14 15:04:41 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:04:41 INFO DAGScheduler: Missing parents: List()
21/03/14 15:04:41 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[44] at collect at utils.scala:135), which has no missing parents
21/03/14 15:04:41 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 6.3 KB, free 911.7 MB)
21/03/14 15:04:41 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.6 MB)
21/03/14 15:04:41 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:62253 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:04:41 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 15:04:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[44] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:04:41 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/03/14 15:04:41 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:04:41 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/03/14 15:04:41 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1286 bytes result sent to driver
21/03/14 15:04:41 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 9 ms on localhost (executor driver) (1/1)
21/03/14 15:04:41 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/03/14 15:04:41 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:135) finished in 0.020 s
21/03/14 15:04:41 INFO DAGScheduler: Job 7 finished: collect at utils.scala:135, took 0.023065 s
21/03/14 15:04:41 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:04:41 INFO DAGScheduler: Registering RDD 47 (count at utils.scala:135)
21/03/14 15:04:41 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/03/14 15:04:41 INFO DAGScheduler: Final stage: ResultStage 12 (count at utils.scala:135)
21/03/14 15:04:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
21/03/14 15:04:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
21/03/14 15:04:41 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[47] at count at utils.scala:135), which has no missing parents
21/03/14 15:04:41 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.4 KB, free 911.6 MB)
21/03/14 15:04:41 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.6 MB)
21/03/14 15:04:41 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:62253 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:04:41 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 15:04:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[47] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:04:41 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/03/14 15:04:41 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:04:41 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/03/14 15:04:41 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1499 bytes result sent to driver
21/03/14 15:04:41 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 11 ms on localhost (executor driver) (1/1)
21/03/14 15:04:41 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/03/14 15:04:41 INFO DAGScheduler: ShuffleMapStage 11 (count at utils.scala:135) finished in 0.020 s
21/03/14 15:04:41 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:04:41 INFO DAGScheduler: running: Set()
21/03/14 15:04:41 INFO DAGScheduler: waiting: Set(ResultStage 12)
21/03/14 15:04:41 INFO DAGScheduler: failed: Set()
21/03/14 15:04:41 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[50] at count at utils.scala:135), which has no missing parents
21/03/14 15:04:41 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 15:04:41 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 15:04:41 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:62253 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:04:41 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
21/03/14 15:04:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[50] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:04:41 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/03/14 15:04:41 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:04:41 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/03/14 15:04:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:04:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:04:41 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1782 bytes result sent to driver
21/03/14 15:04:41 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:04:41 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/03/14 15:04:41 INFO DAGScheduler: ResultStage 12 (count at utils.scala:135) finished in 0.014 s
21/03/14 15:04:41 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.039443 s
21/03/14 15:04:41 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:41 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:41 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:41 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:42 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:42 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:04:42 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:04:42 INFO FileSourceStrategy: Output Data Schema: struct<>
21/03/14 15:04:42 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:04:42 INFO CodeGenerator: Code generated in 23.619421 ms
21/03/14 15:04:42 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 284.5 KB, free 911.3 MB)
21/03/14 15:04:42 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.3 MB)
21/03/14 15:04:42 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:62253 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:04:42 INFO SparkContext: Created broadcast 15 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:04:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:04:42 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:04:42 INFO DAGScheduler: Registering RDD 53 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:04:42 INFO DAGScheduler: Got job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:04:42 INFO DAGScheduler: Final stage: ResultStage 14 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:04:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/03/14 15:04:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/03/14 15:04:42 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:04:42 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 14.2 KB, free 911.3 MB)
21/03/14 15:04:42 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.3 MB)
21/03/14 15:04:42 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:62253 (size: 8.0 KB, free: 912.2 MB)
21/03/14 15:04:42 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1161
21/03/14 15:04:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:04:42 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/03/14 15:04:42 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:04:42 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/03/14 15:04:42 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpOSqUuc/file15b495baa073a, range: 0-1303, partition values: [empty row]
21/03/14 15:04:42 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1585 bytes result sent to driver
21/03/14 15:04:42 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 55 ms on localhost (executor driver) (1/1)
21/03/14 15:04:42 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/03/14 15:04:42 INFO DAGScheduler: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.077 s
21/03/14 15:04:42 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:04:42 INFO DAGScheduler: running: Set()
21/03/14 15:04:42 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/03/14 15:04:42 INFO DAGScheduler: failed: Set()
21/03/14 15:04:42 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:04:42 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 15:04:42 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 15:04:42 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:62253 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:04:42 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1161
21/03/14 15:04:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:04:42 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/03/14 15:04:42 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:04:42 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/03/14 15:04:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:04:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:04:42 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1782 bytes result sent to driver
21/03/14 15:04:42 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:04:42 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/03/14 15:04:42 INFO DAGScheduler: ResultStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0.012 s
21/03/14 15:04:42 INFO DAGScheduler: Job 9 finished: count at NativeMethodAccessorImpl.java:0, took 0.094255 s
21/03/14 15:04:42 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:04:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:04:42 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:42 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:42 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:42 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:04:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:04:42 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:04:42 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:04:42 INFO FileSourceStrategy: Output Data Schema: struct<>
21/03/14 15:04:42 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:04:42 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 284.5 KB, free 911.0 MB)
21/03/14 15:04:42 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.0 MB)
21/03/14 15:04:42 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:62253 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:04:42 INFO SparkContext: Created broadcast 18 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:04:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:04:42 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:04:42 INFO DAGScheduler: Registering RDD 59 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:04:42 INFO DAGScheduler: Got job 10 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:04:42 INFO DAGScheduler: Final stage: ResultStage 16 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:04:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
21/03/14 15:04:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
21/03/14 15:04:42 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:04:42 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 14.2 KB, free 911.0 MB)
21/03/14 15:04:42 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
21/03/14 15:04:42 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:62253 (size: 8.0 KB, free: 912.2 MB)
21/03/14 15:04:42 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1161
21/03/14 15:04:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:04:42 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/03/14 15:04:42 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:04:42 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/03/14 15:04:42 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpOSqUuc/file15b495baa073a, range: 0-2539, partition values: [empty row]
21/03/14 15:04:42 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1628 bytes result sent to driver
21/03/14 15:04:42 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 17 ms on localhost (executor driver) (1/1)
21/03/14 15:04:42 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/03/14 15:04:42 INFO DAGScheduler: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.029 s
21/03/14 15:04:42 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:04:42 INFO DAGScheduler: running: Set()
21/03/14 15:04:42 INFO DAGScheduler: waiting: Set(ResultStage 16)
21/03/14 15:04:42 INFO DAGScheduler: failed: Set()
21/03/14 15:04:42 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:04:42 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.1 KB, free 911.0 MB)
21/03/14 15:04:42 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.0 MB)
21/03/14 15:04:42 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:62253 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:04:42 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1161
21/03/14 15:04:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:04:42 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/03/14 15:04:42 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:04:42 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/03/14 15:04:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:04:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:04:42 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1782 bytes result sent to driver
21/03/14 15:04:42 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 6 ms on localhost (executor driver) (1/1)
21/03/14 15:04:42 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/03/14 15:04:42 INFO DAGScheduler: ResultStage 16 (count at NativeMethodAccessorImpl.java:0) finished in 0.014 s
21/03/14 15:04:42 INFO DAGScheduler: Job 10 finished: count at NativeMethodAccessorImpl.java:0, took 0.048509 s
21/03/14 15:04:42 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:04:42 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:04:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:04:42 INFO MemoryStore: MemoryStore cleared
21/03/14 15:04:42 INFO BlockManager: BlockManager stopped
21/03/14 15:04:42 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:04:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:04:43 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:04:43 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:04:43 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-5d0253b3-efc4-4f7a-aa61-975e1a839c37
21/03/14 15:04:43 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-4e4d4ac2-3b9b-492a-88b2-24eb7a847434
21/03/14 15:05:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:05:08 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:05:08 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:05:08 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:05:08 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:05:08 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:05:08 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:05:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:05:08 INFO Utils: Successfully started service 'sparkDriver' on port 62363.
21/03/14 15:05:08 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:05:08 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:05:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:05:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:05:08 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-a0b33c20-854d-4ac6-b517-60875c3095ac
21/03/14 15:05:08 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:05:08 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:05:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:05:09 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:05:09 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:62363/jars/sparklyr-2.4-2.11.jar with timestamp 1615730709074
21/03/14 15:05:09 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:05:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62364.
21/03/14 15:05:09 INFO NettyBlockTransferService: Server created on localhost:62364
21/03/14 15:05:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:05:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 62364, None)
21/03/14 15:05:09 INFO BlockManagerMasterEndpoint: Registering block manager localhost:62364 with 912.3 MB RAM, BlockManagerId(driver, localhost, 62364, None)
21/03/14 15:05:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 62364, None)
21/03/14 15:05:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 62364, None)
21/03/14 15:05:09 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:05:09 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:05:09 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:05:10 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:05:13 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:05:13 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:05:13 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:05:14 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:05:14 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:05:15 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:05:16 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:05:16 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:05:17 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:05:17 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:05:18 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:05:18 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:05:18 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:05:18 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:05:18 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:05:18 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:05:18 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:05:19 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:05:19 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:05:19 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:05:19 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:05:19 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:05:19 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/9d74d8b1-c0e1-419d-9012-0c8a130276a4_resources
21/03/14 15:05:19 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/9d74d8b1-c0e1-419d-9012-0c8a130276a4
21/03/14 15:05:19 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/9d74d8b1-c0e1-419d-9012-0c8a130276a4
21/03/14 15:05:19 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/9d74d8b1-c0e1-419d-9012-0c8a130276a4/_tmp_space.db
21/03/14 15:05:19 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:05:19 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:05:19 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:05:19 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:05:19 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:05:19 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:05:19 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:05:19 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:05:19 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:05:19 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:05:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:05:19 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:05:20 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 15:05:20 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/03/14 15:05:20 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/03/14 15:05:20 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:05:20 INFO DAGScheduler: Missing parents: List()
21/03/14 15:05:20 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/03/14 15:05:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/03/14 15:05:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/03/14 15:05:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:62364 (size: 3.4 KB, free: 912.3 MB)
21/03/14 15:05:20 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 15:05:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 15:05:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:05:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/03/14 15:05:20 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:05:20 INFO Executor: Fetching spark://localhost:62363/jars/sparklyr-2.4-2.11.jar with timestamp 1615730709074
21/03/14 15:05:20 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:62363 after 29 ms (0 ms spent in bootstraps)
21/03/14 15:05:20 INFO Utils: Fetching spark://localhost:62363/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-04a0d491-c665-4099-805e-439f16620365/userFiles-90cfc403-337e-4d54-93ba-8ce429b90a90/fetchFileTemp7014447480022423030.tmp
21/03/14 15:05:21 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-04a0d491-c665-4099-805e-439f16620365/userFiles-90cfc403-337e-4d54-93ba-8ce429b90a90/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:05:21 INFO CodeGenerator: Code generated in 387.57053 ms
21/03/14 15:05:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
21/03/14 15:05:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 913 ms on localhost (executor driver) (1/1)
21/03/14 15:05:21 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:05:21 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 1.328 s
21/03/14 15:05:21 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 1.417483 s
21/03/14 15:05:22 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:62364 in memory (size: 3.4 KB, free: 912.3 MB)
21/03/14 15:05:22 INFO ContextCleaner: Cleaned accumulator 0
21/03/14 15:05:22 INFO CodeGenerator: Code generated in 16.269571 ms
21/03/14 15:05:22 INFO CodeGenerator: Code generated in 16.547191 ms
21/03/14 15:05:22 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:05:22 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:05:22 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:05:22 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:05:22 INFO DAGScheduler: Missing parents: List()
21/03/14 15:05:22 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/03/14 15:05:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 15:05:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 15:05:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:62364 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:05:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:05:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:05:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:05:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:05:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:05:22 INFO CodeGenerator: Code generated in 9.74433 ms
21/03/14 15:05:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 15:05:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on localhost (executor driver) (1/1)
21/03/14 15:05:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:05:22 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.044 s
21/03/14 15:05:22 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.047985 s
21/03/14 15:05:22 INFO CodeGenerator: Code generated in 20.460943 ms
21/03/14 15:05:22 INFO CodeGenerator: Code generated in 14.581566 ms
21/03/14 15:05:22 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:05:22 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/03/14 15:05:22 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:05:22 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:05:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:05:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:05:22 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/03/14 15:05:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/03/14 15:05:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/03/14 15:05:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:62364 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:05:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 15:05:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:05:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:05:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:05:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:05:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:05:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 58 ms on localhost (executor driver) (1/1)
21/03/14 15:05:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:05:23 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.074 s
21/03/14 15:05:23 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:05:23 INFO DAGScheduler: running: Set()
21/03/14 15:05:23 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:05:23 INFO DAGScheduler: failed: Set()
21/03/14 15:05:23 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/03/14 15:05:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:05:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:05:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:62364 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:05:23 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:05:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:05:23 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:05:23 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:05:23 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:05:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:05:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
21/03/14 15:05:23 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:05:23 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 55 ms on localhost (executor driver) (1/1)
21/03/14 15:05:23 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:05:23 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.065 s
21/03/14 15:05:23 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.163498 s
21/03/14 15:05:23 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:05:23 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:05:23 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/03/14 15:05:23 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:05:23 INFO DAGScheduler: Missing parents: List()
21/03/14 15:05:23 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135), which has no missing parents
21/03/14 15:05:23 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 15:05:23 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 15:05:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:62364 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:05:23 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:05:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:05:23 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:05:23 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:05:23 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:05:23 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/03/14 15:05:23 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:05:23 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:05:23 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.014 s
21/03/14 15:05:23 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.017477 s
21/03/14 15:05:23 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:05:23 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:135)
21/03/14 15:05:23 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/14 15:05:23 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/03/14 15:05:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/03/14 15:05:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/03/14 15:05:23 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/03/14 15:05:23 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/03/14 15:05:23 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/03/14 15:05:23 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:62364 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:05:23 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:05:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:05:23 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:05:23 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:05:23 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:05:23 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/03/14 15:05:23 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 10 ms on localhost (executor driver) (1/1)
21/03/14 15:05:23 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:05:23 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.018 s
21/03/14 15:05:23 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:05:23 INFO DAGScheduler: running: Set()
21/03/14 15:05:23 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/03/14 15:05:23 INFO DAGScheduler: failed: Set()
21/03/14 15:05:23 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/03/14 15:05:23 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 15:05:23 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 15:05:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:62364 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:05:23 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 15:05:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:05:23 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:05:23 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:05:23 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:05:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:05:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:05:23 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/03/14 15:05:23 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:05:23 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:05:23 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.014 s
21/03/14 15:05:23 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.037175 s
21/03/14 15:05:24 INFO CodeGenerator: Code generated in 38.635922 ms
21/03/14 15:05:24 INFO CodeGenerator: Code generated in 14.927939 ms
21/03/14 15:05:24 INFO CodeGenerator: Code generated in 12.485163 ms
21/03/14 15:05:24 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:05:24 INFO DAGScheduler: Registering RDD 28 (count at utils.scala:135)
21/03/14 15:05:24 INFO DAGScheduler: Got job 5 (count at utils.scala:135) with 1 output partitions
21/03/14 15:05:24 INFO DAGScheduler: Final stage: ResultStage 8 (count at utils.scala:135)
21/03/14 15:05:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
21/03/14 15:05:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
21/03/14 15:05:24 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135), which has no missing parents
21/03/14 15:05:24 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 15:05:24 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 15:05:24 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:62364 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:05:24 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 15:05:24 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/03/14 15:05:24 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
21/03/14 15:05:24 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8034 bytes)
21/03/14 15:05:24 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 8, localhost, executor driver, partition 1, PROCESS_LOCAL, 8051 bytes)
21/03/14 15:05:24 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 9, localhost, executor driver, partition 2, PROCESS_LOCAL, 8051 bytes)
21/03/14 15:05:24 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 10, localhost, executor driver, partition 3, PROCESS_LOCAL, 8051 bytes)
21/03/14 15:05:24 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 15:05:24 INFO Executor: Running task 1.0 in stage 7.0 (TID 8)
21/03/14 15:05:24 INFO Executor: Running task 2.0 in stage 7.0 (TID 9)
21/03/14 15:05:24 INFO Executor: Running task 3.0 in stage 7.0 (TID 10)
21/03/14 15:05:24 INFO Executor: Finished task 2.0 in stage 7.0 (TID 9). 1499 bytes result sent to driver
21/03/14 15:05:24 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1499 bytes result sent to driver
21/03/14 15:05:24 INFO Executor: Finished task 1.0 in stage 7.0 (TID 8). 1542 bytes result sent to driver
21/03/14 15:05:24 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 9) in 17 ms on localhost (executor driver) (1/4)
21/03/14 15:05:24 INFO Executor: Finished task 3.0 in stage 7.0 (TID 10). 1499 bytes result sent to driver
21/03/14 15:05:24 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 20 ms on localhost (executor driver) (2/4)
21/03/14 15:05:24 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 8) in 20 ms on localhost (executor driver) (3/4)
21/03/14 15:05:24 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 10) in 20 ms on localhost (executor driver) (4/4)
21/03/14 15:05:24 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 15:05:24 INFO DAGScheduler: ShuffleMapStage 7 (count at utils.scala:135) finished in 0.032 s
21/03/14 15:05:24 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:05:24 INFO DAGScheduler: running: Set()
21/03/14 15:05:24 INFO DAGScheduler: waiting: Set(ResultStage 8)
21/03/14 15:05:24 INFO DAGScheduler: failed: Set()
21/03/14 15:05:24 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135), which has no missing parents
21/03/14 15:05:24 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 15:05:24 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 15:05:24 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:62364 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:05:24 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 15:05:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:05:24 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 15:05:24 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:05:24 INFO Executor: Running task 0.0 in stage 8.0 (TID 11)
21/03/14 15:05:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
21/03/14 15:05:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:05:24 INFO Executor: Finished task 0.0 in stage 8.0 (TID 11). 1782 bytes result sent to driver
21/03/14 15:05:24 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 11) in 11 ms on localhost (executor driver) (1/1)
21/03/14 15:05:24 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 15:05:24 INFO DAGScheduler: ResultStage 8 (count at utils.scala:135) finished in 0.018 s
21/03/14 15:05:24 INFO DAGScheduler: Job 5 finished: count at utils.scala:135, took 0.055379 s
21/03/14 15:05:24 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:05:24 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:05:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:05:24 INFO MemoryStore: MemoryStore cleared
21/03/14 15:05:24 INFO BlockManager: BlockManager stopped
21/03/14 15:05:24 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:05:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:05:24 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:05:24 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:05:24 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-f66f9ed2-5bda-4bff-931d-60d621fa4f17
21/03/14 15:05:24 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-04a0d491-c665-4099-805e-439f16620365
21/03/14 15:05:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:05:28 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:05:28 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:05:28 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:05:28 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:05:28 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:05:28 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:05:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:05:28 INFO Utils: Successfully started service 'sparkDriver' on port 62467.
21/03/14 15:05:28 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:05:28 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:05:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:05:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:05:28 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-290ec10e-582b-4555-8121-3f1242c805dd
21/03/14 15:05:28 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:05:28 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:05:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:05:29 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:05:29 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:62467/jars/sparklyr-2.4-2.11.jar with timestamp 1615730729266
21/03/14 15:05:29 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:05:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62468.
21/03/14 15:05:29 INFO NettyBlockTransferService: Server created on localhost:62468
21/03/14 15:05:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:05:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 62468, None)
21/03/14 15:05:29 INFO BlockManagerMasterEndpoint: Registering block manager localhost:62468 with 912.3 MB RAM, BlockManagerId(driver, localhost, 62468, None)
21/03/14 15:05:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 62468, None)
21/03/14 15:05:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 62468, None)
21/03/14 15:05:29 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:05:29 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:05:29 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:05:30 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:05:32 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:05:33 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:05:33 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:05:33 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:05:33 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:05:35 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:05:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:05:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:05:37 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:05:37 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:05:37 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:05:37 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:05:37 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:05:38 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:05:38 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:05:38 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:05:38 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:05:38 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:05:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:05:38 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:05:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:05:38 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:05:38 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/d238dfa2-0a3a-4a17-ad5f-f4d85eb6d793_resources
21/03/14 15:05:38 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/d238dfa2-0a3a-4a17-ad5f-f4d85eb6d793
21/03/14 15:05:38 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/d238dfa2-0a3a-4a17-ad5f-f4d85eb6d793
21/03/14 15:05:38 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/d238dfa2-0a3a-4a17-ad5f-f4d85eb6d793/_tmp_space.db
21/03/14 15:05:38 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:05:38 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:05:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:05:38 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:05:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:05:38 INFO HiveMetaStore: 0: get_database: fake_database
21/03/14 15:05:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: fake_database	
21/03/14 15:05:38 WARN ObjectStore: Failed to get database fake_database, returning NoSuchObjectException
21/03/14 15:05:38 INFO HiveMetaStore: 0: get_databases: *
21/03/14 15:05:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_databases: *	
21/03/14 15:05:38 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:05:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:05:38 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:05:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:05:39 INFO CodeGenerator: Code generated in 359.039839 ms
21/03/14 15:05:40 INFO CodeGenerator: Code generated in 24.128363 ms
21/03/14 15:05:40 INFO CodeGenerator: Code generated in 17.767401 ms
21/03/14 15:05:41 INFO CodeGenerator: Code generated in 25.084422 ms
21/03/14 15:05:41 INFO CodeGenerator: Code generated in 14.667351 ms
21/03/14 15:05:41 INFO CodeGenerator: Code generated in 17.487852 ms
21/03/14 15:05:41 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:05:41 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:135)
21/03/14 15:05:41 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/03/14 15:05:41 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/03/14 15:05:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/03/14 15:05:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/03/14 15:05:41 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135), which has no missing parents
21/03/14 15:05:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 15:05:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 15:05:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:62468 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:05:41 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 15:05:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:05:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:05:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 15:05:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:05:41 INFO Executor: Fetching spark://localhost:62467/jars/sparklyr-2.4-2.11.jar with timestamp 1615730729266
21/03/14 15:05:41 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:62467 after 21 ms (0 ms spent in bootstraps)
21/03/14 15:05:41 INFO Utils: Fetching spark://localhost:62467/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-887f14c7-68a7-4c30-92ba-1454233be0df/userFiles-bd2b30c2-a274-4702-bbcd-60c3eb052434/fetchFileTemp1617248784833366787.tmp
21/03/14 15:05:41 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-887f14c7-68a7-4c30-92ba-1454233be0df/userFiles-bd2b30c2-a274-4702-bbcd-60c3eb052434/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:05:41 INFO ContextCleaner: Cleaned accumulator 1
21/03/14 15:05:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1585 bytes result sent to driver
21/03/14 15:05:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 428 ms on localhost (executor driver) (1/1)
21/03/14 15:05:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:05:41 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:135) finished in 0.675 s
21/03/14 15:05:41 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:05:41 INFO DAGScheduler: running: Set()
21/03/14 15:05:41 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/03/14 15:05:41 INFO DAGScheduler: failed: Set()
21/03/14 15:05:41 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135), which has no missing parents
21/03/14 15:05:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:05:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:05:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:62468 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:05:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:05:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:05:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:05:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:05:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:05:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:05:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
21/03/14 15:05:42 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1825 bytes result sent to driver
21/03/14 15:05:42 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 49 ms on localhost (executor driver) (1/1)
21/03/14 15:05:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:05:42 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.065 s
21/03/14 15:05:42 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.815868 s
21/03/14 15:05:42 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:05:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:05:42 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:05:42 INFO HiveMetaStore: 0: create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})
21/03/14 15:05:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})	
21/03/14 15:05:42 WARN ObjectStore: Failed to get database catalog_test_database_db, returning NoSuchObjectException
21/03/14 15:05:42 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 15:05:42 INFO CodeGenerator: Code generated in 11.079081 ms
21/03/14 15:05:42 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:05:42 INFO DAGScheduler: Registering RDD 10 (count at utils.scala:135)
21/03/14 15:05:42 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/03/14 15:05:42 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:05:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:05:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:05:42 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[10] at count at utils.scala:135), which has no missing parents
21/03/14 15:05:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 15:05:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 15:05:42 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:62468 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:05:42 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 15:05:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[10] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:05:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:05:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 15:05:42 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:05:42 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1499 bytes result sent to driver
21/03/14 15:05:42 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 11 ms on localhost (executor driver) (1/1)
21/03/14 15:05:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:05:42 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.020 s
21/03/14 15:05:42 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:05:42 INFO DAGScheduler: running: Set()
21/03/14 15:05:42 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:05:42 INFO DAGScheduler: failed: Set()
21/03/14 15:05:42 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[13] at count at utils.scala:135), which has no missing parents
21/03/14 15:05:42 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:05:42 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:05:42 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:62468 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:05:42 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:05:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:05:42 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:05:42 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:05:42 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:05:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:05:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:05:42 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1775 bytes result sent to driver
21/03/14 15:05:42 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 9 ms on localhost (executor driver) (1/1)
21/03/14 15:05:42 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:05:42 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.016 s
21/03/14 15:05:42 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.044174 s
21/03/14 15:05:42 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 15:05:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 15:05:42 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 15:05:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 15:05:42 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 15:05:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 15:05:42 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:05:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:05:42 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:05:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:05:42 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:05:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:05:42 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 15:05:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 15:05:42 INFO HiveMetaStore: 0: drop_database: catalog_test_database_db
21/03/14 15:05:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=drop_database: catalog_test_database_db	
21/03/14 15:05:42 INFO HiveMetaStore: 0: get_all_tables: db=catalog_test_database_db
21/03/14 15:05:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_tables: db=catalog_test_database_db	
21/03/14 15:05:42 INFO HiveMetaStore: 0: get_functions: db=catalog_test_database_db pat=*
21/03/14 15:05:42 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=catalog_test_database_db pat=*	
21/03/14 15:05:42 INFO ObjectStore: Dropping database catalog_test_database_db along with all tables
21/03/14 15:05:42 INFO hivemetastoressimpl: deleting  file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 15:05:42 INFO deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
21/03/14 15:05:42 INFO TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
21/03/14 15:05:42 INFO hivemetastoressimpl: Deleted the diretory file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 15:05:42 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:05:42 INFO DAGScheduler: Registering RDD 17 (count at utils.scala:135)
21/03/14 15:05:42 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:05:42 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/03/14 15:05:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 15:05:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 15:05:42 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at count at utils.scala:135), which has no missing parents
21/03/14 15:05:42 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 15:05:42 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 15:05:42 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:62468 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:05:42 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:05:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:05:42 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:05:42 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 15:05:42 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:05:42 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1499 bytes result sent to driver
21/03/14 15:05:42 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 10 ms on localhost (executor driver) (1/1)
21/03/14 15:05:42 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:05:42 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.018 s
21/03/14 15:05:42 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:05:42 INFO DAGScheduler: running: Set()
21/03/14 15:05:42 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 15:05:42 INFO DAGScheduler: failed: Set()
21/03/14 15:05:42 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[20] at count at utils.scala:135), which has no missing parents
21/03/14 15:05:42 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 15:05:42 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 15:05:42 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:62468 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:05:42 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:05:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:05:42 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:05:42 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:05:42 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:05:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:05:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:05:42 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1775 bytes result sent to driver
21/03/14 15:05:42 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:05:42 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:05:42 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.014 s
21/03/14 15:05:42 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.038023 s
21/03/14 15:05:42 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:05:42 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:05:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:05:43 INFO MemoryStore: MemoryStore cleared
21/03/14 15:05:43 INFO BlockManager: BlockManager stopped
21/03/14 15:05:43 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:05:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:05:43 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:05:43 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:05:43 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-887f14c7-68a7-4c30-92ba-1454233be0df
21/03/14 15:05:43 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-c128266c-eef1-4592-b9b8-990203857a97
21/03/14 15:05:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:05:46 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:05:46 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:05:46 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:05:46 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:05:46 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:05:46 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:05:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:05:46 INFO Utils: Successfully started service 'sparkDriver' on port 62489.
21/03/14 15:05:46 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:05:46 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:05:46 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:05:46 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:05:46 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-dca0c67e-bc8f-4603-a917-68598d10eab4
21/03/14 15:05:47 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:05:47 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:05:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:05:47 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:05:47 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:62489/jars/sparklyr-2.4-2.11.jar with timestamp 1615730747501
21/03/14 15:05:47 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:05:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62491.
21/03/14 15:05:47 INFO NettyBlockTransferService: Server created on localhost:62491
21/03/14 15:05:47 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:05:47 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 62491, None)
21/03/14 15:05:47 INFO BlockManagerMasterEndpoint: Registering block manager localhost:62491 with 912.3 MB RAM, BlockManagerId(driver, localhost, 62491, None)
21/03/14 15:05:47 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 62491, None)
21/03/14 15:05:47 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 62491, None)
21/03/14 15:05:48 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:05:48 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:05:48 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:05:49 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:05:54 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:05:56 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:05:56 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:05:57 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:05:57 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:06:00 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:06:01 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:06:01 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:06:02 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:06:02 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:06:03 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:06:03 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:06:03 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:06:03 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:06:03 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:06:03 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:06:03 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:06:03 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:06:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:06:03 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:06:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:06:03 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:06:03 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/d939a85f-5fc8-43cc-9d80-b6ebf8f1a407_resources
21/03/14 15:06:03 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/d939a85f-5fc8-43cc-9d80-b6ebf8f1a407
21/03/14 15:06:03 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/d939a85f-5fc8-43cc-9d80-b6ebf8f1a407
21/03/14 15:06:03 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/d939a85f-5fc8-43cc-9d80-b6ebf8f1a407/_tmp_space.db
21/03/14 15:06:03 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:06:03 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:04 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:04 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:04 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:04 INFO HiveMetaStore: 0: get_function: default.catalog_fake_function
21/03/14 15:06:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_function: default.catalog_fake_function	
21/03/14 15:06:04 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:04 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:04 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:04 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:06:04 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:06:05 INFO CodeGenerator: Code generated in 408.692802 ms
21/03/14 15:06:06 INFO CodeGenerator: Code generated in 29.352224 ms
21/03/14 15:06:06 INFO CodeGenerator: Code generated in 26.808942 ms
21/03/14 15:06:07 INFO CodeGenerator: Code generated in 27.018075 ms
21/03/14 15:06:07 INFO CodeGenerator: Code generated in 18.889611 ms
21/03/14 15:06:07 INFO CodeGenerator: Code generated in 8.203031 ms
21/03/14 15:06:07 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:06:07 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:135)
21/03/14 15:06:07 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/03/14 15:06:07 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/03/14 15:06:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/03/14 15:06:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/03/14 15:06:07 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135), which has no missing parents
21/03/14 15:06:07 INFO ContextCleaner: Cleaned accumulator 1
21/03/14 15:06:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 15:06:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 15:06:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:62491 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:06:08 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:08 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/03/14 15:06:08 INFO TaskSchedulerImpl: Adding task set 0.0 with 4 tasks
21/03/14 15:06:08 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 9258 bytes)
21/03/14 15:06:08 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 9275 bytes)
21/03/14 15:06:08 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 9258 bytes)
21/03/14 15:06:08 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 9275 bytes)
21/03/14 15:06:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:06:08 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
21/03/14 15:06:08 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
21/03/14 15:06:08 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
21/03/14 15:06:08 INFO Executor: Fetching spark://localhost:62489/jars/sparklyr-2.4-2.11.jar with timestamp 1615730747501
21/03/14 15:06:08 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:62489 after 24 ms (0 ms spent in bootstraps)
21/03/14 15:06:08 INFO Utils: Fetching spark://localhost:62489/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-6f6a0328-b772-4065-b624-2265fb1a2173/userFiles-2493cc71-f688-4b14-9884-b48bc01263ad/fetchFileTemp5648847902414601784.tmp
21/03/14 15:06:08 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-6f6a0328-b772-4065-b624-2265fb1a2173/userFiles-2493cc71-f688-4b14-9884-b48bc01263ad/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:06:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1542 bytes result sent to driver
21/03/14 15:06:08 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1542 bytes result sent to driver
21/03/14 15:06:08 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1542 bytes result sent to driver
21/03/14 15:06:08 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:06:08 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 316 ms on localhost (executor driver) (1/4)
21/03/14 15:06:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 344 ms on localhost (executor driver) (2/4)
21/03/14 15:06:08 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 323 ms on localhost (executor driver) (3/4)
21/03/14 15:06:08 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 324 ms on localhost (executor driver) (4/4)
21/03/14 15:06:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:06:08 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:135) finished in 0.828 s
21/03/14 15:06:08 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:06:08 INFO DAGScheduler: running: Set()
21/03/14 15:06:08 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/03/14 15:06:08 INFO DAGScheduler: failed: Set()
21/03/14 15:06:08 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135), which has no missing parents
21/03/14 15:06:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:06:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:06:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:62491 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:06:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:06:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:06:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 4)
21/03/14 15:06:08 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
21/03/14 15:06:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 23 ms
21/03/14 15:06:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 4). 1825 bytes result sent to driver
21/03/14 15:06:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 4) in 117 ms on localhost (executor driver) (1/1)
21/03/14 15:06:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:06:08 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.142 s
21/03/14 15:06:08 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 1.111207 s
21/03/14 15:06:08 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:06:08 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:06:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:06:08 INFO MemoryStore: MemoryStore cleared
21/03/14 15:06:08 INFO BlockManager: BlockManager stopped
21/03/14 15:06:08 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:06:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:06:08 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:06:08 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:06:08 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-7a03e5f5-b910-41b5-9c4d-526b68f90658
21/03/14 15:06:08 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-6f6a0328-b772-4065-b624-2265fb1a2173
21/03/14 15:06:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:06:13 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:06:13 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:06:13 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:06:13 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:06:13 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:06:13 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:06:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:06:13 INFO Utils: Successfully started service 'sparkDriver' on port 62593.
21/03/14 15:06:13 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:06:13 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:06:13 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:06:13 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:06:13 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-177a0427-2499-4a4b-8a13-031c5d43d615
21/03/14 15:06:13 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:06:13 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:06:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:06:13 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:06:13 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:62593/jars/sparklyr-2.4-2.11.jar with timestamp 1615730773971
21/03/14 15:06:14 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:06:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62594.
21/03/14 15:06:14 INFO NettyBlockTransferService: Server created on localhost:62594
21/03/14 15:06:14 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:06:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 62594, None)
21/03/14 15:06:14 INFO BlockManagerMasterEndpoint: Registering block manager localhost:62594 with 912.3 MB RAM, BlockManagerId(driver, localhost, 62594, None)
21/03/14 15:06:14 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 62594, None)
21/03/14 15:06:14 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 62594, None)
21/03/14 15:06:15 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:06:15 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:06:15 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:06:16 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:06:20 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:06:20 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:06:21 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:06:21 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:06:21 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:06:23 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:06:24 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:06:24 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:06:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:06:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:06:25 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:06:25 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:06:25 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:06:26 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:06:26 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:06:26 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:06:26 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:06:26 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:06:26 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:06:26 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:06:26 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:06:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:06:26 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/fe8365a3-5fed-46ad-aa22-091a2d985bd7_resources
21/03/14 15:06:26 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/fe8365a3-5fed-46ad-aa22-091a2d985bd7
21/03/14 15:06:26 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/fe8365a3-5fed-46ad-aa22-091a2d985bd7
21/03/14 15:06:26 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/fe8365a3-5fed-46ad-aa22-091a2d985bd7/_tmp_space.db
21/03/14 15:06:26 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:06:26 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:26 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:26 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:26 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:27 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:06:27 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
21/03/14 15:06:27 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:06:27 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:06:27 INFO CodeGenerator: Code generated in 288.642523 ms
21/03/14 15:06:27 INFO CodeGenerator: Code generated in 25.421331 ms
21/03/14 15:06:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 284.3 KB, free 912.0 MB)
21/03/14 15:06:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.9 KB, free 912.0 MB)
21/03/14 15:06:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:62594 (size: 23.9 KB, free: 912.3 MB)
21/03/14 15:06:28 INFO SparkContext: Created broadcast 0 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:06:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:06:28 INFO SparkContext: Starting job: createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:06:28 INFO DAGScheduler: Got job 0 (createTable at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:06:28 INFO DAGScheduler: Final stage: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0)
21/03/14 15:06:28 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:06:28 INFO DAGScheduler: Missing parents: List()
21/03/14 15:06:28 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:06:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 912.0 MB)
21/03/14 15:06:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.0 MB)
21/03/14 15:06:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:62594 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:06:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:06:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8362 bytes)
21/03/14 15:06:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:06:28 INFO Executor: Fetching spark://localhost:62593/jars/sparklyr-2.4-2.11.jar with timestamp 1615730773971
21/03/14 15:06:28 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:62593 after 28 ms (0 ms spent in bootstraps)
21/03/14 15:06:28 INFO Utils: Fetching spark://localhost:62593/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-5630aa02-a691-43ee-a7e9-dd3b1a750baf/userFiles-75a36d48-2278-4110-9f00-ec751845d274/fetchFileTemp1431111758023712692.tmp
21/03/14 15:06:28 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-5630aa02-a691-43ee-a7e9-dd3b1a750baf/userFiles-75a36d48-2278-4110-9f00-ec751845d274/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:06:28 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpgN1JNt/file15bb07685dcfd, range: 0-1303, partition values: [empty row]
21/03/14 15:06:28 INFO CodeGenerator: Code generated in 17.895798 ms
21/03/14 15:06:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1329 bytes result sent to driver
21/03/14 15:06:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 393 ms on localhost (executor driver) (1/1)
21/03/14 15:06:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:06:29 INFO DAGScheduler: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0) finished in 0.541 s
21/03/14 15:06:29 INFO DAGScheduler: Job 0 finished: createTable at NativeMethodAccessorImpl.java:0, took 0.602312 s
21/03/14 15:06:29 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:06:29 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:06:29 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:06:29 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:06:29 INFO CodeGenerator: Code generated in 12.470836 ms
21/03/14 15:06:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 284.3 KB, free 911.7 MB)
21/03/14 15:06:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.7 MB)
21/03/14 15:06:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:62594 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:06:29 INFO SparkContext: Created broadcast 2 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:06:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:06:29 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:29 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:29 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `default`.`mtcars` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.
21/03/14 15:06:29 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:29 INFO HiveMetaStore: 0: create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615730778, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpgN1JNt/file15bb07685dcfd, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
21/03/14 15:06:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615730778, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpgN1JNt/file15bb07685dcfd, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
21/03/14 15:06:29 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__
21/03/14 15:06:30 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:06:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:06:30 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:06:30 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:30 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:30 INFO ContextCleaner: Cleaned accumulator 15
21/03/14 15:06:30 INFO ContextCleaner: Cleaned accumulator 11
21/03/14 15:06:30 INFO ContextCleaner: Cleaned accumulator 21
21/03/14 15:06:30 INFO ContextCleaner: Cleaned accumulator 26
21/03/14 15:06:30 INFO ContextCleaner: Cleaned accumulator 16
21/03/14 15:06:30 INFO ContextCleaner: Cleaned accumulator 19
21/03/14 15:06:30 INFO ContextCleaner: Cleaned accumulator 23
21/03/14 15:06:30 INFO ContextCleaner: Cleaned accumulator 14
21/03/14 15:06:30 INFO ContextCleaner: Cleaned accumulator 27
21/03/14 15:06:30 INFO ContextCleaner: Cleaned accumulator 25
21/03/14 15:06:30 INFO ContextCleaner: Cleaned accumulator 8
21/03/14 15:06:30 INFO ContextCleaner: Cleaned accumulator 24
21/03/14 15:06:30 INFO ContextCleaner: Cleaned accumulator 7
21/03/14 15:06:30 INFO ContextCleaner: Cleaned accumulator 6
21/03/14 15:06:30 INFO ContextCleaner: Cleaned accumulator 13
21/03/14 15:06:30 INFO ContextCleaner: Cleaned accumulator 20
21/03/14 15:06:30 INFO ContextCleaner: Cleaned accumulator 22
21/03/14 15:06:31 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:62594 in memory (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:06:31 INFO ContextCleaner: Cleaned accumulator 17
21/03/14 15:06:31 INFO ContextCleaner: Cleaned accumulator 29
21/03/14 15:06:31 INFO ContextCleaner: Cleaned accumulator 10
21/03/14 15:06:31 INFO ContextCleaner: Cleaned accumulator 9
21/03/14 15:06:31 INFO ContextCleaner: Cleaned accumulator 28
21/03/14 15:06:31 INFO ContextCleaner: Cleaned accumulator 12
21/03/14 15:06:31 INFO ContextCleaner: Cleaned accumulator 18
21/03/14 15:06:31 INFO ContextCleaner: Cleaned accumulator 30
21/03/14 15:06:31 INFO CodeGenerator: Code generated in 16.595783 ms
21/03/14 15:06:31 INFO CodeGenerator: Code generated in 14.706826 ms
21/03/14 15:06:31 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:06:31 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:06:31 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:06:31 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:06:31 INFO DAGScheduler: Missing parents: List()
21/03/14 15:06:31 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135), which has no missing parents
21/03/14 15:06:31 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.5 KB, free 911.7 MB)
21/03/14 15:06:31 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 15:06:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:62594 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:06:31 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:06:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:06:31 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:06:31 INFO CodeGenerator: Code generated in 6.875825 ms
21/03/14 15:06:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 15:06:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 24 ms on localhost (executor driver) (1/1)
21/03/14 15:06:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:06:31 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.030 s
21/03/14 15:06:31 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.035422 s
21/03/14 15:06:31 INFO CodeGenerator: Code generated in 21.003647 ms
21/03/14 15:06:31 INFO CodeGenerator: Code generated in 40.454958 ms
21/03/14 15:06:31 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:06:31 INFO DAGScheduler: Registering RDD 16 (count at utils.scala:135)
21/03/14 15:06:31 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:06:31 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:06:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:06:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:06:31 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135), which has no missing parents
21/03/14 15:06:31 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.4 KB, free 911.7 MB)
21/03/14 15:06:31 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.7 MB)
21/03/14 15:06:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:62594 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:06:31 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:06:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:06:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:06:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:06:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 68 ms on localhost (executor driver) (1/1)
21/03/14 15:06:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:06:31 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.083 s
21/03/14 15:06:31 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:06:31 INFO DAGScheduler: running: Set()
21/03/14 15:06:31 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:06:31 INFO DAGScheduler: failed: Set()
21/03/14 15:06:31 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135), which has no missing parents
21/03/14 15:06:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 15:06:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 15:06:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:62594 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:06:31 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:31 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:06:31 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:06:31 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:06:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:06:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
21/03/14 15:06:31 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:06:31 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 61 ms on localhost (executor driver) (1/1)
21/03/14 15:06:31 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:06:31 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.074 s
21/03/14 15:06:31 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.188683 s
21/03/14 15:06:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:31 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:06:31 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:06:31 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:06:31 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:06:32 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:32 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:32 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 284.5 KB, free 911.4 MB)
21/03/14 15:06:32 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.4 MB)
21/03/14 15:06:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:62594 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:06:32 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:06:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:06:32 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:06:32 INFO DAGScheduler: Registering RDD 27 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:06:32 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:06:32 INFO DAGScheduler: Final stage: ResultStage 5 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:06:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 15:06:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 15:06:32 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:06:32 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 911.3 MB)
21/03/14 15:06:32 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 12.2 KB, free 911.3 MB)
21/03/14 15:06:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:62594 (size: 12.2 KB, free: 912.2 MB)
21/03/14 15:06:32 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:32 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:06:32 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:06:32 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:06:32 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpgN1JNt/file15bb07685dcfd, range: 0-1303, partition values: [empty row]
21/03/14 15:06:32 INFO CodeGenerator: Code generated in 19.492222 ms
21/03/14 15:06:32 INFO MemoryStore: Block rdd_22_0 stored as values in memory (estimated size 4.1 KB, free 911.3 MB)
21/03/14 15:06:32 INFO BlockManagerInfo: Added rdd_22_0 in memory on localhost:62594 (size: 4.1 KB, free: 912.2 MB)
21/03/14 15:06:32 INFO CodeGenerator: Code generated in 5.749571 ms
21/03/14 15:06:32 INFO CodeGenerator: Code generated in 19.33708 ms
21/03/14 15:06:32 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1871 bytes result sent to driver
21/03/14 15:06:32 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 191 ms on localhost (executor driver) (1/1)
21/03/14 15:06:32 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:06:32 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.241 s
21/03/14 15:06:32 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:06:32 INFO DAGScheduler: running: Set()
21/03/14 15:06:32 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 15:06:32 INFO DAGScheduler: failed: Set()
21/03/14 15:06:32 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:06:32 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 15:06:32 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 15:06:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:62594 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:06:32 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:32 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:06:32 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:06:32 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:06:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:06:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:06:32 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1782 bytes result sent to driver
21/03/14 15:06:32 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:06:32 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:06:32 INFO DAGScheduler: ResultStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.015 s
21/03/14 15:06:32 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.267226 s
21/03/14 15:06:32 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:32 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:06:32 INFO DAGScheduler: Registering RDD 35 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:06:32 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:06:32 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:06:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
21/03/14 15:06:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
21/03/14 15:06:32 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:06:32 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 25.9 KB, free 911.3 MB)
21/03/14 15:06:32 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.1 KB, free 911.3 MB)
21/03/14 15:06:32 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:62594 (size: 12.1 KB, free: 912.2 MB)
21/03/14 15:06:32 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:32 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:06:32 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:06:32 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:06:32 INFO BlockManager: Found block rdd_22_0 locally
21/03/14 15:06:32 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1871 bytes result sent to driver
21/03/14 15:06:32 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 15 ms on localhost (executor driver) (1/1)
21/03/14 15:06:32 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:06:32 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.031 s
21/03/14 15:06:32 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:06:32 INFO DAGScheduler: running: Set()
21/03/14 15:06:32 INFO DAGScheduler: waiting: Set(ResultStage 7)
21/03/14 15:06:32 INFO DAGScheduler: failed: Set()
21/03/14 15:06:32 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:06:32 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 15:06:32 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 15:06:32 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:62594 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:06:32 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:32 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/14 15:06:32 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:06:32 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 15:06:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:06:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:06:32 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1782 bytes result sent to driver
21/03/14 15:06:32 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:06:32 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 15:06:32 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.016 s
21/03/14 15:06:32 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.057881 s
21/03/14 15:06:32 INFO MapPartitionsRDD: Removing RDD 22 from persistence list
21/03/14 15:06:32 INFO BlockManager: Removing RDD 22
21/03/14 15:06:32 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:06:32 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:06:32 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:06:32 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:06:32 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:32 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 284.5 KB, free 911.0 MB)
21/03/14 15:06:32 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.0 MB)
21/03/14 15:06:32 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:62594 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:06:32 INFO SparkContext: Created broadcast 11 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:06:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:06:32 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:06:32 INFO DAGScheduler: Registering RDD 46 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:06:32 INFO DAGScheduler: Got job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:06:32 INFO DAGScheduler: Final stage: ResultStage 9 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:06:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/03/14 15:06:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
21/03/14 15:06:32 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:06:32 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 25.9 KB, free 910.9 MB)
21/03/14 15:06:32 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 12.1 KB, free 910.9 MB)
21/03/14 15:06:32 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:62594 (size: 12.1 KB, free: 912.2 MB)
21/03/14 15:06:32 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:32 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 15:06:32 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:06:32 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/03/14 15:06:32 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpgN1JNt/file15bb07685dcfd, range: 0-2539, partition values: [empty row]
21/03/14 15:06:32 INFO MemoryStore: Block rdd_41_0 stored as values in memory (estimated size 4.9 KB, free 910.9 MB)
21/03/14 15:06:32 INFO BlockManagerInfo: Added rdd_41_0 in memory on localhost:62594 (size: 4.9 KB, free: 912.1 MB)
21/03/14 15:06:32 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1871 bytes result sent to driver
21/03/14 15:06:32 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 47 ms on localhost (executor driver) (1/1)
21/03/14 15:06:32 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 15:06:32 INFO DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.060 s
21/03/14 15:06:32 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:06:32 INFO DAGScheduler: running: Set()
21/03/14 15:06:32 INFO DAGScheduler: waiting: Set(ResultStage 9)
21/03/14 15:06:32 INFO DAGScheduler: failed: Set()
21/03/14 15:06:32 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[49] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:06:32 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.1 KB, free 910.9 MB)
21/03/14 15:06:32 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.8 KB, free 910.9 MB)
21/03/14 15:06:32 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:62594 (size: 3.8 KB, free: 912.1 MB)
21/03/14 15:06:32 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[49] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:32 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 15:06:32 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:06:32 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/03/14 15:06:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:06:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:06:32 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1782 bytes result sent to driver
21/03/14 15:06:32 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 5 ms on localhost (executor driver) (1/1)
21/03/14 15:06:32 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 15:06:32 INFO DAGScheduler: ResultStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.012 s
21/03/14 15:06:32 INFO DAGScheduler: Job 5 finished: count at NativeMethodAccessorImpl.java:0, took 0.078968 s
21/03/14 15:06:33 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 106
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 323
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 105
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 303
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 168
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 177
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 76
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 239
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 102
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 245
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 251
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 274
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 203
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 64
21/03/14 15:06:33 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:62594 in memory (size: 12.1 KB, free: 912.2 MB)
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 243
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 68
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 305
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 121
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 37
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 67
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 306
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 135
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 127
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 200
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 288
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 89
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 90
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 225
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 130
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 254
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 107
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 195
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 240
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 156
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 122
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 125
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 277
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 332
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 281
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 160
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 84
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 226
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 312
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 278
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 322
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 74
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 85
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 120
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 211
21/03/14 15:06:33 INFO ContextCleaner: Cleaned shuffle 1
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 132
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 148
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 176
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 292
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 256
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 97
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 335
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 337
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 109
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 184
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 145
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 182
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 129
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 172
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 188
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 147
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 117
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 92
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 229
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 198
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 65
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 179
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 123
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 273
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 250
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 264
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 174
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 141
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 171
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 175
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 186
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 294
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 98
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 124
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 180
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 300
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 320
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 210
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 260
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 71
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 165
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 272
21/03/14 15:06:33 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:62594 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 299
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 301
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 244
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 116
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 192
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 314
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 214
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 149
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 279
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 236
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 157
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 269
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 257
21/03/14 15:06:33 INFO ContextCleaner: Cleaned shuffle 0
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 128
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 218
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 247
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 261
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 191
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 212
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 252
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 112
21/03/14 15:06:33 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:62594 in memory (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 249
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 329
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 110
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 169
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 143
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 80
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 221
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 237
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 319
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 324
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 151
21/03/14 15:06:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:62594 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 307
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 91
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 246
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 66
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 77
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 96
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 321
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 197
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 111
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 133
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 88
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 205
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 108
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 311
21/03/14 15:06:33 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 15:06:33 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:06:33 INFO BlockManager: Removing RDD 22
21/03/14 15:06:33 INFO ContextCleaner: Cleaned RDD 22
21/03/14 15:06:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:06:33 INFO MemoryStore: MemoryStore cleared
21/03/14 15:06:33 INFO BlockManager: BlockManager stopped
21/03/14 15:06:33 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:06:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:06:33 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:06:33 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:06:33 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-5630aa02-a691-43ee-a7e9-dd3b1a750baf
21/03/14 15:06:33 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-ee42f574-cefd-461c-bd7e-709c7da5b941
21/03/14 15:06:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:06:36 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:06:36 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:06:36 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:06:36 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:06:36 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:06:36 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:06:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:06:37 INFO Utils: Successfully started service 'sparkDriver' on port 62696.
21/03/14 15:06:37 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:06:37 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:06:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:06:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:06:37 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-f6ec208f-b644-442a-aadc-d368cd84987c
21/03/14 15:06:37 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:06:37 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:06:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:06:37 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:06:37 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:62696/jars/sparklyr-2.4-2.11.jar with timestamp 1615730797495
21/03/14 15:06:37 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:06:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62697.
21/03/14 15:06:37 INFO NettyBlockTransferService: Server created on localhost:62697
21/03/14 15:06:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:06:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 62697, None)
21/03/14 15:06:37 INFO BlockManagerMasterEndpoint: Registering block manager localhost:62697 with 912.3 MB RAM, BlockManagerId(driver, localhost, 62697, None)
21/03/14 15:06:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 62697, None)
21/03/14 15:06:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 62697, None)
21/03/14 15:06:38 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:06:38 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:06:38 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:06:38 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:06:42 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:06:42 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:06:42 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:06:43 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:06:43 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:06:45 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:06:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:06:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:06:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:06:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:06:47 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:06:47 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:06:47 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:06:48 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:06:48 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:06:48 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:06:48 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:06:48 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:06:48 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:06:48 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:06:48 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:06:48 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:06:48 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/b7380a6e-e377-40fd-a6ee-74868a191685_resources
21/03/14 15:06:48 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/b7380a6e-e377-40fd-a6ee-74868a191685
21/03/14 15:06:48 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/b7380a6e-e377-40fd-a6ee-74868a191685
21/03/14 15:06:48 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/b7380a6e-e377-40fd-a6ee-74868a191685/_tmp_space.db
21/03/14 15:06:48 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:06:48 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:48 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:48 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:48 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:49 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:06:49 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
21/03/14 15:06:49 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:06:49 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:06:50 INFO CodeGenerator: Code generated in 481.271726 ms
21/03/14 15:06:50 INFO CodeGenerator: Code generated in 21.67199 ms
21/03/14 15:06:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 284.3 KB, free 912.0 MB)
21/03/14 15:06:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.9 KB, free 912.0 MB)
21/03/14 15:06:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:62697 (size: 23.9 KB, free: 912.3 MB)
21/03/14 15:06:50 INFO SparkContext: Created broadcast 0 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:06:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:06:50 INFO SparkContext: Starting job: createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:06:51 INFO DAGScheduler: Got job 0 (createTable at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:06:51 INFO DAGScheduler: Final stage: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0)
21/03/14 15:06:51 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:06:51 INFO DAGScheduler: Missing parents: List()
21/03/14 15:06:51 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:06:51 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 912.0 MB)
21/03/14 15:06:51 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.0 MB)
21/03/14 15:06:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:62697 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:06:51 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:06:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8362 bytes)
21/03/14 15:06:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:06:51 INFO Executor: Fetching spark://localhost:62696/jars/sparklyr-2.4-2.11.jar with timestamp 1615730797495
21/03/14 15:06:51 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:62696 after 31 ms (0 ms spent in bootstraps)
21/03/14 15:06:51 INFO Utils: Fetching spark://localhost:62696/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-b241193d-4701-49d6-9745-0610eea0448f/userFiles-c7937930-ff6d-4271-acc7-a5762462d59e/fetchFileTemp6636578158290044544.tmp
21/03/14 15:06:51 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-b241193d-4701-49d6-9745-0610eea0448f/userFiles-c7937930-ff6d-4271-acc7-a5762462d59e/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:06:51 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpgN1JNt/file15bb07f8f6a32, range: 0-1303, partition values: [empty row]
21/03/14 15:06:51 INFO CodeGenerator: Code generated in 25.678069 ms
21/03/14 15:06:51 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1329 bytes result sent to driver
21/03/14 15:06:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 437 ms on localhost (executor driver) (1/1)
21/03/14 15:06:51 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:06:51 INFO DAGScheduler: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0) finished in 0.655 s
21/03/14 15:06:51 INFO DAGScheduler: Job 0 finished: createTable at NativeMethodAccessorImpl.java:0, took 0.849751 s
21/03/14 15:06:51 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:06:51 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:06:51 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:06:51 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:06:51 INFO CodeGenerator: Code generated in 9.781793 ms
21/03/14 15:06:51 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 284.3 KB, free 911.7 MB)
21/03/14 15:06:51 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.7 MB)
21/03/14 15:06:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:62697 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:06:51 INFO SparkContext: Created broadcast 2 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:06:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:06:52 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:52 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:52 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:52 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:52 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:52 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:52 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:52 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:52 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `default`.`mtcars` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.
21/03/14 15:06:52 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:52 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:52 INFO HiveMetaStore: 0: create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615730800, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpgN1JNt/file15bb07f8f6a32, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
21/03/14 15:06:52 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615730800, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpgN1JNt/file15bb07f8f6a32, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
21/03/14 15:06:52 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__
21/03/14 15:06:52 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:06:52 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:06:52 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:06:52 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:52 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:53 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:53 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:53 INFO CodeGenerator: Code generated in 19.869198 ms
21/03/14 15:06:53 INFO CodeGenerator: Code generated in 15.056738 ms
21/03/14 15:06:53 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:06:53 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:06:53 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:06:53 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:06:53 INFO DAGScheduler: Missing parents: List()
21/03/14 15:06:53 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135), which has no missing parents
21/03/14 15:06:53 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.5 KB, free 911.7 MB)
21/03/14 15:06:53 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 15:06:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:62697 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:06:53 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:53 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:06:53 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:06:53 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:06:53 INFO CodeGenerator: Code generated in 9.50764 ms
21/03/14 15:06:53 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 15:06:53 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on localhost (executor driver) (1/1)
21/03/14 15:06:53 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:06:53 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.045 s
21/03/14 15:06:53 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.049928 s
21/03/14 15:06:53 INFO CodeGenerator: Code generated in 16.624914 ms
21/03/14 15:06:53 INFO CodeGenerator: Code generated in 16.799645 ms
21/03/14 15:06:53 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:06:53 INFO DAGScheduler: Registering RDD 16 (count at utils.scala:135)
21/03/14 15:06:53 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:06:53 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:06:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:06:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:06:53 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135), which has no missing parents
21/03/14 15:06:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.4 KB, free 911.7 MB)
21/03/14 15:06:54 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.7 MB)
21/03/14 15:06:54 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:62697 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:06:54 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 14
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 29
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 23
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 28
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 25
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 16
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 26
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 24
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 9
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 21
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 27
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 15
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 13
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 20
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 17
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 10
21/03/14 15:06:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:54 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:06:54 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:06:54 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:06:54 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:62697 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 15:06:54 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:62697 in memory (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 7
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 6
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 12
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 30
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 11
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 18
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 22
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 19
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 8
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 15:06:54 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 15:06:54 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:06:54 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 70 ms on localhost (executor driver) (1/1)
21/03/14 15:06:54 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:06:54 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.133 s
21/03/14 15:06:54 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:06:54 INFO DAGScheduler: running: Set()
21/03/14 15:06:54 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:06:54 INFO DAGScheduler: failed: Set()
21/03/14 15:06:54 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135), which has no missing parents
21/03/14 15:06:54 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 15:06:54 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 15:06:54 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:62697 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:06:54 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:54 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:06:54 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:06:54 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:06:54 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:06:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
21/03/14 15:06:54 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:06:54 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 73 ms on localhost (executor driver) (1/1)
21/03/14 15:06:54 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:06:54 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.089 s
21/03/14 15:06:54 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.254344 s
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:54 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:06:54 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:06:54 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:06:54 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:54 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:54 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:55 INFO CodeGenerator: Code generated in 57.123131 ms
21/03/14 15:06:55 INFO CodeGenerator: Code generated in 24.663747 ms
21/03/14 15:06:55 INFO CodeGenerator: Code generated in 14.555082 ms
21/03/14 15:06:55 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:06:55 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135)
21/03/14 15:06:55 INFO DAGScheduler: Got job 3 (count at utils.scala:135) with 1 output partitions
21/03/14 15:06:55 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/03/14 15:06:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 15:06:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 15:06:55 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/03/14 15:06:55 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.9 KB, free 911.7 MB)
21/03/14 15:06:55 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.2 KB, free 911.7 MB)
21/03/14 15:06:55 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:62697 (size: 4.2 KB, free: 912.2 MB)
21/03/14 15:06:55 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:55 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:06:55 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 15:06:55 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:06:55 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1499 bytes result sent to driver
21/03/14 15:06:55 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 13 ms on localhost (executor driver) (1/1)
21/03/14 15:06:55 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:06:55 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.022 s
21/03/14 15:06:55 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:06:55 INFO DAGScheduler: running: Set()
21/03/14 15:06:55 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 15:06:55 INFO DAGScheduler: failed: Set()
21/03/14 15:06:55 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/03/14 15:06:55 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 15:06:55 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 15:06:55 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:62697 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:06:55 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:55 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:06:55 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:06:55 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:06:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:06:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:06:55 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1782 bytes result sent to driver
21/03/14 15:06:55 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 12 ms on localhost (executor driver) (1/1)
21/03/14 15:06:55 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:06:55 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.037 s
21/03/14 15:06:55 INFO DAGScheduler: Job 3 finished: count at utils.scala:135, took 0.069742 s
21/03/14 15:06:55 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:55 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:55 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:55 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:55 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:55 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:55 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:55 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:55 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:55 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:55 INFO HiveMetaStore: 0: get_table : db=default tbl=fake_table
21/03/14 15:06:55 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=fake_table	
21/03/14 15:06:55 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:55 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:55 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:55 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:55 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:55 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:55 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:06:55 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:06:55 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:06:55 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:06:56 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:56 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:56 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:56 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:56 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:56 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:06:56 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:06:56 INFO CodeGenerator: Code generated in 7.500252 ms
21/03/14 15:06:56 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 15:06:56 INFO DAGScheduler: Got job 4 (collect at utils.scala:61) with 1 output partitions
21/03/14 15:06:56 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:61)
21/03/14 15:06:56 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:06:56 INFO DAGScheduler: Missing parents: List()
21/03/14 15:06:56 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[31] at map at utils.scala:54), which has no missing parents
21/03/14 15:06:56 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 6.0 KB, free 911.6 MB)
21/03/14 15:06:56 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.4 KB, free 911.6 MB)
21/03/14 15:06:56 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:62697 (size: 3.4 KB, free: 912.2 MB)
21/03/14 15:06:56 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[31] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:56 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:06:56 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
21/03/14 15:06:56 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:06:56 INFO CodeGenerator: Code generated in 7.275505 ms
21/03/14 15:06:56 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 979 bytes result sent to driver
21/03/14 15:06:56 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 15 ms on localhost (executor driver) (1/1)
21/03/14 15:06:56 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:06:56 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:61) finished in 0.021 s
21/03/14 15:06:56 INFO DAGScheduler: Job 4 finished: collect at utils.scala:61, took 0.023443 s
21/03/14 15:06:56 INFO CodeGenerator: Code generated in 15.245708 ms
21/03/14 15:06:56 INFO CodeGenerator: Code generated in 11.932845 ms
21/03/14 15:06:56 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:06:56 INFO DAGScheduler: Got job 5 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:06:56 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:135)
21/03/14 15:06:56 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:06:56 INFO DAGScheduler: Missing parents: List()
21/03/14 15:06:56 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[35] at collect at utils.scala:135), which has no missing parents
21/03/14 15:06:56 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 6.3 KB, free 911.6 MB)
21/03/14 15:06:56 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.6 MB)
21/03/14 15:06:56 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:62697 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:06:56 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:56 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/14 15:06:56 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:06:56 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 15:06:56 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1286 bytes result sent to driver
21/03/14 15:06:56 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 11 ms on localhost (executor driver) (1/1)
21/03/14 15:06:56 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 15:06:56 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:135) finished in 0.020 s
21/03/14 15:06:56 INFO DAGScheduler: Job 5 finished: collect at utils.scala:135, took 0.023691 s
21/03/14 15:06:56 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:06:56 INFO DAGScheduler: Registering RDD 38 (count at utils.scala:135)
21/03/14 15:06:56 INFO DAGScheduler: Got job 6 (count at utils.scala:135) with 1 output partitions
21/03/14 15:06:56 INFO DAGScheduler: Final stage: ResultStage 9 (count at utils.scala:135)
21/03/14 15:06:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/03/14 15:06:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
21/03/14 15:06:56 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[38] at count at utils.scala:135), which has no missing parents
21/03/14 15:06:56 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.4 KB, free 911.6 MB)
21/03/14 15:06:56 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.6 MB)
21/03/14 15:06:56 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:62697 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:06:56 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[38] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:56 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 15:06:56 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:06:56 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/03/14 15:06:56 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1542 bytes result sent to driver
21/03/14 15:06:56 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 11 ms on localhost (executor driver) (1/1)
21/03/14 15:06:56 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 15:06:56 INFO DAGScheduler: ShuffleMapStage 8 (count at utils.scala:135) finished in 0.019 s
21/03/14 15:06:56 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:06:56 INFO DAGScheduler: running: Set()
21/03/14 15:06:56 INFO DAGScheduler: waiting: Set(ResultStage 9)
21/03/14 15:06:56 INFO DAGScheduler: failed: Set()
21/03/14 15:06:56 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[41] at count at utils.scala:135), which has no missing parents
21/03/14 15:06:56 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 15:06:56 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 15:06:56 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:62697 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:06:56 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[41] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:56 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 15:06:56 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:06:56 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/03/14 15:06:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:06:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:06:56 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1782 bytes result sent to driver
21/03/14 15:06:56 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:06:56 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 15:06:56 INFO DAGScheduler: ResultStage 9 (count at utils.scala:135) finished in 0.015 s
21/03/14 15:06:56 INFO DAGScheduler: Job 6 finished: count at utils.scala:135, took 0.040397 s
21/03/14 15:06:57 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:06:57 INFO DAGScheduler: Got job 7 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:06:57 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:135)
21/03/14 15:06:57 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:06:57 INFO DAGScheduler: Missing parents: List()
21/03/14 15:06:57 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[44] at collect at utils.scala:135), which has no missing parents
21/03/14 15:06:57 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 6.3 KB, free 911.6 MB)
21/03/14 15:06:57 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.6 MB)
21/03/14 15:06:57 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:62697 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[44] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:57 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/03/14 15:06:57 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:06:57 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/03/14 15:06:57 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1286 bytes result sent to driver
21/03/14 15:06:57 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
21/03/14 15:06:57 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/03/14 15:06:57 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:135) finished in 0.012 s
21/03/14 15:06:57 INFO DAGScheduler: Job 7 finished: collect at utils.scala:135, took 0.015315 s
21/03/14 15:06:57 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:06:57 INFO DAGScheduler: Registering RDD 47 (count at utils.scala:135)
21/03/14 15:06:57 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/03/14 15:06:57 INFO DAGScheduler: Final stage: ResultStage 12 (count at utils.scala:135)
21/03/14 15:06:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
21/03/14 15:06:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
21/03/14 15:06:57 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[47] at count at utils.scala:135), which has no missing parents
21/03/14 15:06:57 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.4 KB, free 911.6 MB)
21/03/14 15:06:57 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.6 MB)
21/03/14 15:06:57 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:62697 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[47] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:57 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/03/14 15:06:57 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:06:57 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/03/14 15:06:57 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1499 bytes result sent to driver
21/03/14 15:06:57 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 11 ms on localhost (executor driver) (1/1)
21/03/14 15:06:57 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/03/14 15:06:57 INFO DAGScheduler: ShuffleMapStage 11 (count at utils.scala:135) finished in 0.019 s
21/03/14 15:06:57 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:06:57 INFO DAGScheduler: running: Set()
21/03/14 15:06:57 INFO DAGScheduler: waiting: Set(ResultStage 12)
21/03/14 15:06:57 INFO DAGScheduler: failed: Set()
21/03/14 15:06:57 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[50] at count at utils.scala:135), which has no missing parents
21/03/14 15:06:57 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 15:06:57 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 15:06:57 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:62697 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[50] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:57 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/03/14 15:06:57 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:06:57 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/03/14 15:06:57 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:06:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:06:57 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1782 bytes result sent to driver
21/03/14 15:06:57 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:06:57 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/03/14 15:06:57 INFO DAGScheduler: ResultStage 12 (count at utils.scala:135) finished in 0.015 s
21/03/14 15:06:57 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.042107 s
21/03/14 15:06:57 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:57 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:57 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:57 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:57 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:57 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:57 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:06:57 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:06:57 INFO FileSourceStrategy: Output Data Schema: struct<>
21/03/14 15:06:57 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:06:57 INFO CodeGenerator: Code generated in 12.247531 ms
21/03/14 15:06:57 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 284.5 KB, free 911.3 MB)
21/03/14 15:06:57 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.3 MB)
21/03/14 15:06:57 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:62697 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO SparkContext: Created broadcast 15 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:06:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:06:57 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:06:57 INFO DAGScheduler: Registering RDD 53 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:06:57 INFO DAGScheduler: Got job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:06:57 INFO DAGScheduler: Final stage: ResultStage 14 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:06:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/03/14 15:06:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/03/14 15:06:57 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:06:57 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 14.2 KB, free 911.3 MB)
21/03/14 15:06:57 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.3 MB)
21/03/14 15:06:57 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:62697 (size: 8.0 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:57 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/03/14 15:06:57 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:06:57 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/03/14 15:06:57 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpgN1JNt/file15bb07f8f6a32, range: 0-1303, partition values: [empty row]
21/03/14 15:06:57 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1585 bytes result sent to driver
21/03/14 15:06:57 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 40 ms on localhost (executor driver) (1/1)
21/03/14 15:06:57 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/03/14 15:06:57 INFO DAGScheduler: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.057 s
21/03/14 15:06:57 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:06:57 INFO DAGScheduler: running: Set()
21/03/14 15:06:57 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/03/14 15:06:57 INFO DAGScheduler: failed: Set()
21/03/14 15:06:57 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:06:57 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.1 KB, free 911.2 MB)
21/03/14 15:06:57 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.2 MB)
21/03/14 15:06:57 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:62697 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:57 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/03/14 15:06:57 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:06:57 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/03/14 15:06:57 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:06:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:06:57 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1782 bytes result sent to driver
21/03/14 15:06:57 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 6 ms on localhost (executor driver) (1/1)
21/03/14 15:06:57 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/03/14 15:06:57 INFO DAGScheduler: ResultStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0.013 s
21/03/14 15:06:57 INFO DAGScheduler: Job 9 finished: count at NativeMethodAccessorImpl.java:0, took 0.075177 s
21/03/14 15:06:57 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:06:57 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:06:57 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:57 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:57 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:57 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:57 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:57 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:57 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:06:57 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 342
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 344
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 469
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 268
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 306
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 471
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 348
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 371
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 132
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 465
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 314
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 216
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 140
21/03/14 15:06:57 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:62697 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 103
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 121
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 242
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 450
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 202
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 246
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 253
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 345
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 173
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 176
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 194
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 340
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 300
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 262
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 148
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 265
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 277
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 289
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 269
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 122
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 313
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 446
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 208
21/03/14 15:06:57 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:62697 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 108
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 287
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 193
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 460
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 361
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 387
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 353
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 200
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 349
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 285
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 325
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 158
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 409
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 322
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 195
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 453
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 367
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 275
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 385
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 118
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 235
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 454
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 365
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 410
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 468
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 417
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 222
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 117
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 164
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 267
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 391
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 190
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 238
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 402
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 292
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 428
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 431
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 331
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 323
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 435
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 197
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 135
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 154
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 184
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 116
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 326
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 291
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 212
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 329
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 434
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 233
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 160
21/03/14 15:06:57 INFO ContextCleaner: Cleaned shuffle 4
21/03/14 15:06:57 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:62697 in memory (size: 3.4 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 128
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 203
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 231
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 119
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 462
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 319
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 337
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 360
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 343
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 433
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 278
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 312
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 358
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 461
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 421
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 305
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 373
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 332
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 307
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 172
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 201
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 198
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 141
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 293
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 217
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 228
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 272
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 248
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 294
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 182
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 227
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 199
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 244
21/03/14 15:06:57 INFO ContextCleaner: Cleaned shuffle 3
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 426
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 226
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 354
21/03/14 15:06:57 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:62697 in memory (size: 8.0 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 144
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 239
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 463
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 185
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 191
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 451
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 318
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 243
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 316
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 174
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 271
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 346
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 169
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 186
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 189
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 180
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 143
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 384
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 411
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 401
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 150
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 350
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 444
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 304
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 232
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 109
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 296
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 299
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 224
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 330
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 298
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 396
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 328
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 245
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 388
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 113
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 112
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 404
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 104
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 429
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 382
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 256
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 273
21/03/14 15:06:57 INFO ContextCleaner: Cleaned shuffle 1
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 290
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 259
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 466
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 283
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 107
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 383
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 120
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 397
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 390
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 258
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 416
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 369
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 393
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 159
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 389
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 457
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 432
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 133
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 470
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 218
21/03/14 15:06:57 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:62697 in memory (size: 4.2 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 352
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 395
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 356
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 320
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 473
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 211
21/03/14 15:06:57 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:62697 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 442
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 225
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 425
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 249
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 403
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 178
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 261
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 440
21/03/14 15:06:57 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:62697 in memory (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 427
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 146
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 452
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 260
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 339
21/03/14 15:06:57 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:62697 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 445
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 152
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 151
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 147
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 368
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 351
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 175
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 230
21/03/14 15:06:57 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 138
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 338
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 274
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 422
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 430
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 250
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 392
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 187
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 412
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 145
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 126
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 206
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 436
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 406
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 311
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 177
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 288
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 315
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 219
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 171
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 229
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 310
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 357
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 467
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 341
21/03/14 15:06:57 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:06:57 INFO FileSourceStrategy: Output Data Schema: struct<>
21/03/14 15:06:57 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:06:57 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:62697 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:62697 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 205
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 170
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 125
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 179
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 418
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 472
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 142
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 321
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 234
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 303
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 381
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 213
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 362
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 153
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 380
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 149
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 166
21/03/14 15:06:57 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:62697 in memory (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 386
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 327
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 215
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 413
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 441
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 183
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 464
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 415
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 252
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 110
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 420
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 379
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 168
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 139
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 359
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 400
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 456
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 264
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 309
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 407
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 363
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 282
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 376
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 210
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 336
21/03/14 15:06:57 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:62697 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 423
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 105
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 209
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 192
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 437
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 266
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 317
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 475
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 241
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 134
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 221
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 295
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 355
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 163
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 137
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 204
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 220
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 372
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 448
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 377
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 162
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 130
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 297
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 263
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 374
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 123
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 459
21/03/14 15:06:57 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:62697 in memory (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 302
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 414
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 394
21/03/14 15:06:57 INFO ContextCleaner: Cleaned shuffle 2
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 237
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 364
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 449
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 114
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 308
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 127
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 161
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 167
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 447
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 280
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 124
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 286
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 324
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 284
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 196
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 408
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 378
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 111
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 458
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 257
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 247
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 399
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 398
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 156
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 240
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 236
21/03/14 15:06:57 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:62697 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 438
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 474
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 279
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 301
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 207
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 136
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 106
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 347
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 131
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 115
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 155
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 270
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 281
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 157
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 333
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 424
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 251
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 443
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 366
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 419
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 335
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 375
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 254
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 334
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 129
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 276
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 405
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 223
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 439
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 214
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 455
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 165
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 181
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 188
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 255
21/03/14 15:06:57 INFO ContextCleaner: Cleaned accumulator 370
21/03/14 15:06:57 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 284.5 KB, free 911.4 MB)
21/03/14 15:06:58 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.4 MB)
21/03/14 15:06:58 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:62697 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:06:58 INFO SparkContext: Created broadcast 18 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:06:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:06:58 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:06:58 INFO DAGScheduler: Registering RDD 59 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:06:58 INFO DAGScheduler: Got job 10 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:06:58 INFO DAGScheduler: Final stage: ResultStage 16 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:06:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
21/03/14 15:06:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
21/03/14 15:06:58 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:06:58 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 14.2 KB, free 911.4 MB)
21/03/14 15:06:58 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.4 MB)
21/03/14 15:06:58 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:62697 (size: 8.0 KB, free: 912.2 MB)
21/03/14 15:06:58 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:58 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/03/14 15:06:58 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:06:58 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/03/14 15:06:58 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpgN1JNt/file15bb07f8f6a32, range: 0-2539, partition values: [empty row]
21/03/14 15:06:58 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1585 bytes result sent to driver
21/03/14 15:06:58 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 15 ms on localhost (executor driver) (1/1)
21/03/14 15:06:58 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/03/14 15:06:58 INFO DAGScheduler: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.026 s
21/03/14 15:06:58 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:06:58 INFO DAGScheduler: running: Set()
21/03/14 15:06:58 INFO DAGScheduler: waiting: Set(ResultStage 16)
21/03/14 15:06:58 INFO DAGScheduler: failed: Set()
21/03/14 15:06:58 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:06:58 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.1 KB, free 911.4 MB)
21/03/14 15:06:58 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.4 MB)
21/03/14 15:06:58 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:62697 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:06:58 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1161
21/03/14 15:06:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:06:58 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/03/14 15:06:58 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:06:58 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/03/14 15:06:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:06:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:06:58 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1782 bytes result sent to driver
21/03/14 15:06:58 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 6 ms on localhost (executor driver) (1/1)
21/03/14 15:06:58 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/03/14 15:06:58 INFO DAGScheduler: ResultStage 16 (count at NativeMethodAccessorImpl.java:0) finished in 0.013 s
21/03/14 15:06:58 INFO DAGScheduler: Job 10 finished: count at NativeMethodAccessorImpl.java:0, took 0.045891 s
21/03/14 15:06:58 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:06:58 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:06:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:06:58 INFO MemoryStore: MemoryStore cleared
21/03/14 15:06:58 INFO BlockManager: BlockManager stopped
21/03/14 15:06:58 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:06:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:06:58 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:06:58 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:06:58 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-8b080f9d-a79f-408c-a405-bb9bbd72c8ac
21/03/14 15:06:58 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-b241193d-4701-49d6-9745-0610eea0448f
21/03/14 15:07:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:07:02 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:07:02 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:07:02 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:07:02 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:07:02 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:07:02 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:07:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:07:02 INFO Utils: Successfully started service 'sparkDriver' on port 62798.
21/03/14 15:07:02 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:07:02 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:07:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:07:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:07:02 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-b864939f-d8f2-4485-ad0f-7d4a7309bc80
21/03/14 15:07:02 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:07:02 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:07:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:07:03 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:07:03 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:62798/jars/sparklyr-2.4-2.11.jar with timestamp 1615730823645
21/03/14 15:07:03 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:07:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62800.
21/03/14 15:07:04 INFO NettyBlockTransferService: Server created on localhost:62800
21/03/14 15:07:04 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:07:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 62800, None)
21/03/14 15:07:04 INFO BlockManagerMasterEndpoint: Registering block manager localhost:62800 with 912.3 MB RAM, BlockManagerId(driver, localhost, 62800, None)
21/03/14 15:07:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 62800, None)
21/03/14 15:07:04 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 62800, None)
21/03/14 15:07:05 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:07:05 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:07:05 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:07:05 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:07:09 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:07:10 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:07:10 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:07:10 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:07:10 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:07:12 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:07:13 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:07:13 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:07:14 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:07:14 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:07:14 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:07:14 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:07:14 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:07:14 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:07:14 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:07:14 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:07:15 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:07:15 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:07:15 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:07:15 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:07:15 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:07:15 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:07:15 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/032f7fe9-3073-475b-9b5d-04d40ce613f9_resources
21/03/14 15:07:15 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/032f7fe9-3073-475b-9b5d-04d40ce613f9
21/03/14 15:07:15 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/032f7fe9-3073-475b-9b5d-04d40ce613f9
21/03/14 15:07:15 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/032f7fe9-3073-475b-9b5d-04d40ce613f9/_tmp_space.db
21/03/14 15:07:15 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:07:15 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:07:15 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:07:15 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:07:15 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:07:15 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:07:15 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:07:15 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:07:15 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:07:15 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:07:15 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:07:15 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:07:16 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 15:07:16 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/03/14 15:07:16 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/03/14 15:07:16 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:07:16 INFO DAGScheduler: Missing parents: List()
21/03/14 15:07:16 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/03/14 15:07:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/03/14 15:07:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/03/14 15:07:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:62800 (size: 3.4 KB, free: 912.3 MB)
21/03/14 15:07:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 15:07:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 15:07:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:07:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/03/14 15:07:16 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:07:16 INFO Executor: Fetching spark://localhost:62798/jars/sparklyr-2.4-2.11.jar with timestamp 1615730823645
21/03/14 15:07:16 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:62798 after 27 ms (0 ms spent in bootstraps)
21/03/14 15:07:16 INFO Utils: Fetching spark://localhost:62798/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-36565ff1-2392-4c63-ba7c-c763ff4802f9/userFiles-1c5a3918-d6ae-4993-9d9b-fb02cee6f8b7/fetchFileTemp6361849719715722840.tmp
21/03/14 15:07:16 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-36565ff1-2392-4c63-ba7c-c763ff4802f9/userFiles-1c5a3918-d6ae-4993-9d9b-fb02cee6f8b7/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:07:17 INFO CodeGenerator: Code generated in 395.830684 ms
21/03/14 15:07:17 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
21/03/14 15:07:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 955 ms on localhost (executor driver) (1/1)
21/03/14 15:07:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:07:17 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 1.276 s
21/03/14 15:07:17 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 1.382839 s
21/03/14 15:07:17 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:62800 in memory (size: 3.4 KB, free: 912.3 MB)
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 7
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 15
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 22
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 12
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 14
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 20
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 1
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 25
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 21
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 3
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 23
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 17
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 6
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 13
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 24
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 11
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 9
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 0
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 2
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 16
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 5
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 4
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 18
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 19
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 10
21/03/14 15:07:17 INFO ContextCleaner: Cleaned accumulator 8
21/03/14 15:07:18 INFO CodeGenerator: Code generated in 127.580593 ms
21/03/14 15:07:19 INFO CodeGenerator: Code generated in 47.644814 ms
21/03/14 15:07:19 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:07:19 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:07:19 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:07:19 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:07:19 INFO DAGScheduler: Missing parents: List()
21/03/14 15:07:19 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/03/14 15:07:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 15:07:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 15:07:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:62800 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:07:19 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:07:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:07:19 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:07:19 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:07:19 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:07:19 INFO CodeGenerator: Code generated in 11.446889 ms
21/03/14 15:07:19 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 15:07:19 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 45 ms on localhost (executor driver) (1/1)
21/03/14 15:07:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:07:19 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.055 s
21/03/14 15:07:19 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.061913 s
21/03/14 15:07:19 INFO CodeGenerator: Code generated in 27.637848 ms
21/03/14 15:07:19 INFO CodeGenerator: Code generated in 34.621982 ms
21/03/14 15:07:19 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:07:19 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/03/14 15:07:19 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:07:19 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:07:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:07:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:07:19 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/03/14 15:07:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/03/14 15:07:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/03/14 15:07:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:62800 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:07:19 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 15:07:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:07:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:07:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:07:19 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:07:20 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:07:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 85 ms on localhost (executor driver) (1/1)
21/03/14 15:07:20 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:07:20 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.109 s
21/03/14 15:07:20 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:07:20 INFO DAGScheduler: running: Set()
21/03/14 15:07:20 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:07:20 INFO DAGScheduler: failed: Set()
21/03/14 15:07:20 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/03/14 15:07:20 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:07:20 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:07:20 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:62800 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:07:20 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:07:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:07:20 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:07:20 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:07:20 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:07:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:07:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 22 ms
21/03/14 15:07:20 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:07:20 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 143 ms on localhost (executor driver) (1/1)
21/03/14 15:07:20 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:07:20 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.167 s
21/03/14 15:07:20 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.320312 s
21/03/14 15:07:20 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:07:20 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:07:20 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/03/14 15:07:20 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:07:20 INFO DAGScheduler: Missing parents: List()
21/03/14 15:07:20 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135), which has no missing parents
21/03/14 15:07:20 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 15:07:20 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 15:07:20 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:62800 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:07:20 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:07:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:07:20 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:07:20 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:07:20 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:07:20 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/03/14 15:07:20 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:07:20 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:07:20 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.013 s
21/03/14 15:07:20 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.016196 s
21/03/14 15:07:20 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:07:20 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:135)
21/03/14 15:07:20 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/14 15:07:20 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/03/14 15:07:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/03/14 15:07:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/03/14 15:07:20 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/03/14 15:07:20 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/03/14 15:07:20 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/03/14 15:07:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:62800 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:07:20 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:07:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:07:20 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:07:20 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:07:20 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:07:20 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/03/14 15:07:20 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 10 ms on localhost (executor driver) (1/1)
21/03/14 15:07:20 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:07:20 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.017 s
21/03/14 15:07:20 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:07:20 INFO DAGScheduler: running: Set()
21/03/14 15:07:20 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/03/14 15:07:20 INFO DAGScheduler: failed: Set()
21/03/14 15:07:20 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/03/14 15:07:20 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 15:07:20 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 15:07:20 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:62800 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:07:20 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 15:07:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:07:20 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:07:20 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:07:20 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:07:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:07:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:07:20 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/03/14 15:07:20 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 6 ms on localhost (executor driver) (1/1)
21/03/14 15:07:20 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:07:20 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.013 s
21/03/14 15:07:20 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.035763 s
21/03/14 15:07:21 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:07:21 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:07:21 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:07:21 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:07:21 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:07:21 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:07:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:07:21 INFO MemoryStore: MemoryStore cleared
21/03/14 15:07:21 INFO BlockManager: BlockManager stopped
21/03/14 15:07:21 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:07:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:07:21 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:07:21 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:07:21 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-bf910f5f-e686-4a1f-b7e6-971e91fd66b8
21/03/14 15:07:21 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-36565ff1-2392-4c63-ba7c-c763ff4802f9
21/03/14 15:10:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:10:19 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:10:19 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:10:20 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:10:20 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:10:20 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:10:20 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:10:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:10:20 INFO Utils: Successfully started service 'sparkDriver' on port 63133.
21/03/14 15:10:20 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:10:20 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:10:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:10:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:10:20 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-1f950445-6761-4e75-a211-5e922cb7053a
21/03/14 15:10:20 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:10:20 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:10:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:10:20 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:10:20 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:63133/jars/sparklyr-2.4-2.11.jar with timestamp 1615731020558
21/03/14 15:10:20 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:10:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63134.
21/03/14 15:10:20 INFO NettyBlockTransferService: Server created on localhost:63134
21/03/14 15:10:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:10:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 63134, None)
21/03/14 15:10:20 INFO BlockManagerMasterEndpoint: Registering block manager localhost:63134 with 912.3 MB RAM, BlockManagerId(driver, localhost, 63134, None)
21/03/14 15:10:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 63134, None)
21/03/14 15:10:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 63134, None)
21/03/14 15:10:21 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:10:21 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:10:21 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:10:21 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:10:24 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:10:25 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:10:25 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:10:25 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:10:25 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:10:27 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:10:28 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:10:28 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:10:29 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:10:29 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:10:29 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:10:29 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:10:30 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:10:30 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:10:30 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:10:30 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:10:30 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:10:30 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:10:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:10:30 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:10:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:10:30 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:10:30 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/512b038e-557e-404b-b122-157a4f2ae723_resources
21/03/14 15:10:30 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/512b038e-557e-404b-b122-157a4f2ae723
21/03/14 15:10:30 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/512b038e-557e-404b-b122-157a4f2ae723
21/03/14 15:10:30 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/512b038e-557e-404b-b122-157a4f2ae723/_tmp_space.db
21/03/14 15:10:30 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:10:30 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:10:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:10:30 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:31 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:10:31 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
21/03/14 15:10:31 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:10:31 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:10:32 INFO CodeGenerator: Code generated in 343.226826 ms
21/03/14 15:10:32 INFO CodeGenerator: Code generated in 67.836667 ms
21/03/14 15:10:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 284.3 KB, free 912.0 MB)
21/03/14 15:10:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.9 KB, free 912.0 MB)
21/03/14 15:10:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:63134 (size: 23.9 KB, free: 912.3 MB)
21/03/14 15:10:33 INFO SparkContext: Created broadcast 0 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:10:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:10:34 INFO SparkContext: Starting job: createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:10:34 INFO DAGScheduler: Got job 0 (createTable at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:10:34 INFO DAGScheduler: Final stage: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0)
21/03/14 15:10:34 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:10:34 INFO DAGScheduler: Missing parents: List()
21/03/14 15:10:34 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:10:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 912.0 MB)
21/03/14 15:10:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.0 MB)
21/03/14 15:10:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:63134 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:10:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:10:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:10:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:10:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8361 bytes)
21/03/14 15:10:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:10:34 INFO Executor: Fetching spark://localhost:63133/jars/sparklyr-2.4-2.11.jar with timestamp 1615731020558
21/03/14 15:10:34 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:63133 after 26 ms (0 ms spent in bootstraps)
21/03/14 15:10:34 INFO Utils: Fetching spark://localhost:63133/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-b69556ae-6d84-4149-9ca0-648614ac085a/userFiles-9d31602a-5a3e-4717-bbec-ca8d711e075a/fetchFileTemp5159961367592898601.tmp
21/03/14 15:10:34 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-b69556ae-6d84-4149-9ca0-648614ac085a/userFiles-9d31602a-5a3e-4717-bbec-ca8d711e075a/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:10:34 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpVdrazq/file15d042b08847, range: 0-1303, partition values: [empty row]
21/03/14 15:10:34 INFO CodeGenerator: Code generated in 13.619422 ms
21/03/14 15:10:34 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1329 bytes result sent to driver
21/03/14 15:10:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 358 ms on localhost (executor driver) (1/1)
21/03/14 15:10:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:10:34 INFO DAGScheduler: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0) finished in 0.580 s
21/03/14 15:10:34 INFO DAGScheduler: Job 0 finished: createTable at NativeMethodAccessorImpl.java:0, took 0.682605 s
21/03/14 15:10:34 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:10:34 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:10:34 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:10:34 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:10:34 INFO CodeGenerator: Code generated in 14.886288 ms
21/03/14 15:10:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 284.3 KB, free 911.7 MB)
21/03/14 15:10:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.7 MB)
21/03/14 15:10:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:63134 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:10:34 INFO SparkContext: Created broadcast 2 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:10:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:10:35 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:10:35 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:10:35 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:35 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:35 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:10:35 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:10:35 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:35 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:35 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `default`.`mtcars` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.
21/03/14 15:10:35 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:10:35 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:10:35 INFO HiveMetaStore: 0: create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615731023, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpVdrazq/file15d042b08847, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
21/03/14 15:10:35 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615731023, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpVdrazq/file15d042b08847, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
21/03/14 15:10:35 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__
21/03/14 15:10:35 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:10:35 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:10:35 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:10:35 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:35 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:36 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:36 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:36 INFO CodeGenerator: Code generated in 16.773057 ms
21/03/14 15:10:36 INFO CodeGenerator: Code generated in 15.685304 ms
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 6
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 20
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 29
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 30
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 13
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 17
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 11
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 22
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 24
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 9
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 15
21/03/14 15:10:36 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:63134 in memory (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 26
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 14
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 23
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 21
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 25
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 8
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 19
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 7
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 28
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 10
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 27
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 16
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 12
21/03/14 15:10:36 INFO ContextCleaner: Cleaned accumulator 18
21/03/14 15:10:36 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:10:36 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:10:36 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:10:36 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:10:36 INFO DAGScheduler: Missing parents: List()
21/03/14 15:10:36 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135), which has no missing parents
21/03/14 15:10:36 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.5 KB, free 911.7 MB)
21/03/14 15:10:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 15:10:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:63134 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:10:36 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:10:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:10:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:10:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:10:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:10:36 INFO CodeGenerator: Code generated in 8.525949 ms
21/03/14 15:10:36 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 15:10:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 30 ms on localhost (executor driver) (1/1)
21/03/14 15:10:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:10:36 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.039 s
21/03/14 15:10:36 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.043009 s
21/03/14 15:10:37 INFO CodeGenerator: Code generated in 19.530726 ms
21/03/14 15:10:37 INFO CodeGenerator: Code generated in 17.527571 ms
21/03/14 15:10:37 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:10:37 INFO DAGScheduler: Registering RDD 16 (count at utils.scala:135)
21/03/14 15:10:37 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:10:37 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:10:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:10:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:10:37 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135), which has no missing parents
21/03/14 15:10:37 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.4 KB, free 911.7 MB)
21/03/14 15:10:37 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.7 MB)
21/03/14 15:10:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:63134 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:10:37 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:10:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:10:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:10:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:10:37 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:10:37 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:10:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 66 ms on localhost (executor driver) (1/1)
21/03/14 15:10:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:10:37 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.081 s
21/03/14 15:10:37 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:10:37 INFO DAGScheduler: running: Set()
21/03/14 15:10:37 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:10:37 INFO DAGScheduler: failed: Set()
21/03/14 15:10:37 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135), which has no missing parents
21/03/14 15:10:37 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 15:10:37 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 15:10:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:63134 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:10:37 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:10:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:10:37 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:10:37 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:10:37 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:10:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:10:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
21/03/14 15:10:37 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:10:37 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 78 ms on localhost (executor driver) (1/1)
21/03/14 15:10:37 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:10:37 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.092 s
21/03/14 15:10:37 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.201464 s
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:37 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:10:37 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:10:37 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:10:37 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:37 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:38 INFO CodeGenerator: Code generated in 34.309533 ms
21/03/14 15:10:38 INFO CodeGenerator: Code generated in 13.776013 ms
21/03/14 15:10:38 INFO CodeGenerator: Code generated in 10.940379 ms
21/03/14 15:10:38 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:10:38 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135)
21/03/14 15:10:38 INFO DAGScheduler: Got job 3 (count at utils.scala:135) with 1 output partitions
21/03/14 15:10:38 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/03/14 15:10:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 15:10:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 15:10:38 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/03/14 15:10:38 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.9 KB, free 911.7 MB)
21/03/14 15:10:38 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.2 KB, free 911.7 MB)
21/03/14 15:10:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:63134 (size: 4.2 KB, free: 912.2 MB)
21/03/14 15:10:38 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 15:10:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:10:38 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:10:38 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 15:10:38 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:10:38 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1499 bytes result sent to driver
21/03/14 15:10:38 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 12 ms on localhost (executor driver) (1/1)
21/03/14 15:10:38 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:10:38 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.021 s
21/03/14 15:10:38 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:10:38 INFO DAGScheduler: running: Set()
21/03/14 15:10:38 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 15:10:38 INFO DAGScheduler: failed: Set()
21/03/14 15:10:38 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/03/14 15:10:38 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 15:10:38 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 15:10:38 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:63134 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:10:38 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 15:10:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:10:38 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:10:38 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:10:38 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:10:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:10:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:10:38 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1782 bytes result sent to driver
21/03/14 15:10:38 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:10:38 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:10:38 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.013 s
21/03/14 15:10:38 INFO DAGScheduler: Job 3 finished: count at utils.scala:135, took 0.040273 s
21/03/14 15:10:38 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:38 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:10:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:10:38 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:38 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:38 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:38 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:10:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:10:38 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:38 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:38 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:38 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:10:38 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:10:38 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:10:38 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:10:38 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:38 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:10:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:10:38 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:10:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:10:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:10:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:10:38 INFO CodeGenerator: Code generated in 8.997276 ms
21/03/14 15:10:38 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 15:10:38 INFO DAGScheduler: Got job 4 (collect at utils.scala:61) with 1 output partitions
21/03/14 15:10:38 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:61)
21/03/14 15:10:38 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:10:38 INFO DAGScheduler: Missing parents: List()
21/03/14 15:10:38 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[31] at map at utils.scala:54), which has no missing parents
21/03/14 15:10:38 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 6.0 KB, free 911.6 MB)
21/03/14 15:10:38 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.4 KB, free 911.6 MB)
21/03/14 15:10:38 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:63134 (size: 3.4 KB, free: 912.2 MB)
21/03/14 15:10:38 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 15:10:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[31] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 15:10:38 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:10:38 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
21/03/14 15:10:38 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:10:38 INFO CodeGenerator: Code generated in 7.680412 ms
21/03/14 15:10:38 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1022 bytes result sent to driver
21/03/14 15:10:38 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 18 ms on localhost (executor driver) (1/1)
21/03/14 15:10:38 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:10:38 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:61) finished in 0.027 s
21/03/14 15:10:38 INFO DAGScheduler: Job 4 finished: collect at utils.scala:61, took 0.029790 s
21/03/14 15:10:39 INFO CodeGenerator: Code generated in 17.629897 ms
21/03/14 15:10:39 INFO CodeGenerator: Code generated in 12.255867 ms
21/03/14 15:10:39 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:10:39 INFO DAGScheduler: Got job 5 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:10:39 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:135)
21/03/14 15:10:39 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:10:39 INFO DAGScheduler: Missing parents: List()
21/03/14 15:10:39 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[35] at collect at utils.scala:135), which has no missing parents
21/03/14 15:10:39 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 6.3 KB, free 911.6 MB)
21/03/14 15:10:39 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.6 MB)
21/03/14 15:10:39 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:63134 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:10:39 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 15:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:10:39 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/14 15:10:39 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:10:39 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 15:10:39 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1286 bytes result sent to driver
21/03/14 15:10:39 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:10:39 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 15:10:39 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:135) finished in 0.013 s
21/03/14 15:10:39 INFO DAGScheduler: Job 5 finished: collect at utils.scala:135, took 0.015014 s
21/03/14 15:10:39 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:10:39 INFO DAGScheduler: Registering RDD 38 (count at utils.scala:135)
21/03/14 15:10:39 INFO DAGScheduler: Got job 6 (count at utils.scala:135) with 1 output partitions
21/03/14 15:10:39 INFO DAGScheduler: Final stage: ResultStage 9 (count at utils.scala:135)
21/03/14 15:10:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/03/14 15:10:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
21/03/14 15:10:39 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[38] at count at utils.scala:135), which has no missing parents
21/03/14 15:10:39 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.4 KB, free 911.6 MB)
21/03/14 15:10:39 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.6 MB)
21/03/14 15:10:39 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:63134 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:10:39 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 15:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[38] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:10:39 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 15:10:39 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:10:39 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/03/14 15:10:39 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1499 bytes result sent to driver
21/03/14 15:10:39 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 9 ms on localhost (executor driver) (1/1)
21/03/14 15:10:39 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 15:10:39 INFO DAGScheduler: ShuffleMapStage 8 (count at utils.scala:135) finished in 0.016 s
21/03/14 15:10:39 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:10:39 INFO DAGScheduler: running: Set()
21/03/14 15:10:39 INFO DAGScheduler: waiting: Set(ResultStage 9)
21/03/14 15:10:39 INFO DAGScheduler: failed: Set()
21/03/14 15:10:39 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[41] at count at utils.scala:135), which has no missing parents
21/03/14 15:10:39 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 15:10:39 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 15:10:39 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:63134 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:10:39 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
21/03/14 15:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[41] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:10:39 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 15:10:39 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:10:39 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/03/14 15:10:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:10:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:10:39 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1782 bytes result sent to driver
21/03/14 15:10:39 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:10:39 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 15:10:39 INFO DAGScheduler: ResultStage 9 (count at utils.scala:135) finished in 0.014 s
21/03/14 15:10:39 INFO DAGScheduler: Job 6 finished: count at utils.scala:135, took 0.037899 s
21/03/14 15:10:39 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:10:39 INFO DAGScheduler: Got job 7 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:10:39 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:135)
21/03/14 15:10:39 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:10:39 INFO DAGScheduler: Missing parents: List()
21/03/14 15:10:39 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[44] at collect at utils.scala:135), which has no missing parents
21/03/14 15:10:39 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 6.3 KB, free 911.6 MB)
21/03/14 15:10:39 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.6 MB)
21/03/14 15:10:39 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:63134 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:10:39 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 15:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[44] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:10:39 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/03/14 15:10:39 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:10:39 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/03/14 15:10:39 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1286 bytes result sent to driver
21/03/14 15:10:39 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
21/03/14 15:10:39 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/03/14 15:10:39 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:135) finished in 0.013 s
21/03/14 15:10:39 INFO DAGScheduler: Job 7 finished: collect at utils.scala:135, took 0.015082 s
21/03/14 15:10:39 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:10:39 INFO DAGScheduler: Registering RDD 47 (count at utils.scala:135)
21/03/14 15:10:39 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/03/14 15:10:39 INFO DAGScheduler: Final stage: ResultStage 12 (count at utils.scala:135)
21/03/14 15:10:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
21/03/14 15:10:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
21/03/14 15:10:39 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[47] at count at utils.scala:135), which has no missing parents
21/03/14 15:10:39 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.4 KB, free 911.6 MB)
21/03/14 15:10:39 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.6 MB)
21/03/14 15:10:39 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:63134 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:10:39 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 15:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[47] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:10:39 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/03/14 15:10:39 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:10:39 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/03/14 15:10:39 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1499 bytes result sent to driver
21/03/14 15:10:39 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 10 ms on localhost (executor driver) (1/1)
21/03/14 15:10:39 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/03/14 15:10:39 INFO DAGScheduler: ShuffleMapStage 11 (count at utils.scala:135) finished in 0.019 s
21/03/14 15:10:39 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:10:39 INFO DAGScheduler: running: Set()
21/03/14 15:10:39 INFO DAGScheduler: waiting: Set(ResultStage 12)
21/03/14 15:10:39 INFO DAGScheduler: failed: Set()
21/03/14 15:10:39 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[50] at count at utils.scala:135), which has no missing parents
21/03/14 15:10:39 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 317
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 340
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 196
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 104
21/03/14 15:10:39 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 15:10:39 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:63134 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:10:39 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
21/03/14 15:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[50] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:10:39 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/03/14 15:10:39 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:10:39 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/03/14 15:10:39 INFO ContextCleaner: Cleaned shuffle 2
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 130
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 171
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 146
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 211
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 75
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 256
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 235
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 142
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 259
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 97
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 283
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 79
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 247
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 157
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 285
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 139
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 170
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 164
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 141
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 77
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 329
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 71
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 182
21/03/14 15:10:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 122
21/03/14 15:10:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 155
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 212
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 237
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 210
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 266
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 263
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 207
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 250
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 136
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 145
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 72
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 227
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 188
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 272
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 181
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 36
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 331
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 246
21/03/14 15:10:39 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1825 bytes result sent to driver
21/03/14 15:10:39 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:63134 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:10:39 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:10:39 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/03/14 15:10:39 INFO DAGScheduler: ResultStage 12 (count at utils.scala:135) finished in 0.036 s
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 208
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 110
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 159
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 240
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 205
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 213
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 186
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 152
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 209
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 107
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 265
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 328
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 232
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 335
21/03/14 15:10:39 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.059506 s
21/03/14 15:10:39 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:63134 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 204
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 248
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 158
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 319
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 305
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 128
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 174
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 228
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 95
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 242
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 286
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 326
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 201
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 261
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 287
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 234
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 138
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 80
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 177
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 225
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 291
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 284
21/03/14 15:10:39 INFO ContextCleaner: Cleaned shuffle 0
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 299
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 301
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 73
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 118
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 219
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 135
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 78
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 108
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 325
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 224
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 175
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 254
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 282
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 124
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 117
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 167
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 290
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 91
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 236
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 106
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 125
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 308
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 307
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 144
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 120
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 318
21/03/14 15:10:39 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:63134 in memory (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 81
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 103
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 87
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 200
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 322
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 306
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 161
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 102
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 270
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 267
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 114
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 165
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 262
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 214
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 252
21/03/14 15:10:39 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:63134 in memory (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 339
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 255
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 156
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 178
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 129
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 244
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 94
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 154
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 264
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 197
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 298
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 90
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 151
21/03/14 15:10:39 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:63134 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 148
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 241
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 115
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 223
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 249
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 321
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 215
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 217
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 333
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 202
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 67
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 279
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 121
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 96
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 258
21/03/14 15:10:39 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:63134 in memory (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 334
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 220
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 269
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 163
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 74
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 76
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 309
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 221
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 149
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 297
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 289
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 330
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 179
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 112
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 296
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 203
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 169
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 147
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 274
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 185
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 323
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 98
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 189
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 281
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 166
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 324
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 243
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 173
21/03/14 15:10:39 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:63134 in memory (size: 3.4 KB, free: 912.2 MB)
21/03/14 15:10:39 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:63134 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 292
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 100
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 273
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 180
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 233
21/03/14 15:10:39 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:63134 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 304
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 278
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 64
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 68
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 126
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 312
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 294
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 84
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 187
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 143
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 239
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 191
21/03/14 15:10:39 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:63134 in memory (size: 4.2 KB, free: 912.2 MB)
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 65
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 192
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 194
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 193
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 131
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 133
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 231
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 190
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 109
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 313
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 153
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 123
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 216
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 230
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 253
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 276
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 116
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 320
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 338
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 327
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 238
21/03/14 15:10:39 INFO ContextCleaner: Cleaned shuffle 1
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 150
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 310
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 119
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 260
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 229
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 105
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 88
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 162
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 302
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 127
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 337
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 111
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 336
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 198
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 280
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 288
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 277
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 160
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 300
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 183
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 293
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 295
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 245
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 176
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 184
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 85
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 113
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 69
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 271
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 342
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 140
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 92
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 332
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 99
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 268
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 132
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 341
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 134
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 311
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 137
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 89
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 199
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 168
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 226
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 83
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 70
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 82
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 37
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 218
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 222
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 101
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 257
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 275
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 93
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 206
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 251
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 172
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 303
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 66
21/03/14 15:10:39 INFO ContextCleaner: Cleaned accumulator 86
21/03/14 15:10:39 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:39 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:40 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:40 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:40 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:10:40 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:10:40 INFO FileSourceStrategy: Output Data Schema: struct<>
21/03/14 15:10:40 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:10:40 INFO CodeGenerator: Code generated in 14.128867 ms
21/03/14 15:10:40 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 284.5 KB, free 911.4 MB)
21/03/14 15:10:40 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.4 MB)
21/03/14 15:10:40 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:63134 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:10:40 INFO SparkContext: Created broadcast 15 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:10:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:10:40 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:10:40 INFO DAGScheduler: Registering RDD 53 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:10:40 INFO DAGScheduler: Got job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:10:40 INFO DAGScheduler: Final stage: ResultStage 14 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:10:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/03/14 15:10:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/03/14 15:10:40 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:10:40 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 14.2 KB, free 911.4 MB)
21/03/14 15:10:40 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.4 MB)
21/03/14 15:10:40 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:63134 (size: 8.0 KB, free: 912.2 MB)
21/03/14 15:10:40 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1161
21/03/14 15:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:10:40 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/03/14 15:10:40 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 8350 bytes)
21/03/14 15:10:40 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/03/14 15:10:40 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpVdrazq/file15d042b08847, range: 0-1303, partition values: [empty row]
21/03/14 15:10:40 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1585 bytes result sent to driver
21/03/14 15:10:40 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 46 ms on localhost (executor driver) (1/1)
21/03/14 15:10:40 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/03/14 15:10:40 INFO DAGScheduler: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.066 s
21/03/14 15:10:40 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:10:40 INFO DAGScheduler: running: Set()
21/03/14 15:10:40 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/03/14 15:10:40 INFO DAGScheduler: failed: Set()
21/03/14 15:10:40 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:10:40 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 15:10:40 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 15:10:40 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:63134 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:10:40 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1161
21/03/14 15:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:10:40 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/03/14 15:10:40 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:10:40 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/03/14 15:10:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:10:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:10:40 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1782 bytes result sent to driver
21/03/14 15:10:40 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 9 ms on localhost (executor driver) (1/1)
21/03/14 15:10:40 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/03/14 15:10:40 INFO DAGScheduler: ResultStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0.015 s
21/03/14 15:10:40 INFO DAGScheduler: Job 9 finished: count at NativeMethodAccessorImpl.java:0, took 0.087962 s
21/03/14 15:10:40 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:10:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:10:40 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:40 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:40 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:40 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:10:40 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:10:40 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:10:40 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:10:40 INFO FileSourceStrategy: Output Data Schema: struct<>
21/03/14 15:10:40 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:10:40 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 284.5 KB, free 911.1 MB)
21/03/14 15:10:40 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.0 MB)
21/03/14 15:10:40 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:63134 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:10:40 INFO SparkContext: Created broadcast 18 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:10:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:10:40 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:10:40 INFO DAGScheduler: Registering RDD 59 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:10:40 INFO DAGScheduler: Got job 10 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:10:40 INFO DAGScheduler: Final stage: ResultStage 16 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:10:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
21/03/14 15:10:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
21/03/14 15:10:40 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:10:40 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 14.2 KB, free 911.0 MB)
21/03/14 15:10:40 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
21/03/14 15:10:40 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:63134 (size: 8.0 KB, free: 912.2 MB)
21/03/14 15:10:40 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1161
21/03/14 15:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:10:40 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/03/14 15:10:40 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8350 bytes)
21/03/14 15:10:40 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/03/14 15:10:40 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpVdrazq/file15d042b08847, range: 0-2539, partition values: [empty row]
21/03/14 15:10:40 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1585 bytes result sent to driver
21/03/14 15:10:40 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 16 ms on localhost (executor driver) (1/1)
21/03/14 15:10:40 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/03/14 15:10:40 INFO DAGScheduler: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.026 s
21/03/14 15:10:40 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:10:40 INFO DAGScheduler: running: Set()
21/03/14 15:10:40 INFO DAGScheduler: waiting: Set(ResultStage 16)
21/03/14 15:10:40 INFO DAGScheduler: failed: Set()
21/03/14 15:10:40 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:10:40 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.1 KB, free 911.0 MB)
21/03/14 15:10:40 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.0 MB)
21/03/14 15:10:40 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:63134 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:10:40 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1161
21/03/14 15:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:10:40 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/03/14 15:10:40 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:10:40 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/03/14 15:10:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:10:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:10:40 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1782 bytes result sent to driver
21/03/14 15:10:40 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 6 ms on localhost (executor driver) (1/1)
21/03/14 15:10:40 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/03/14 15:10:40 INFO DAGScheduler: ResultStage 16 (count at NativeMethodAccessorImpl.java:0) finished in 0.011 s
21/03/14 15:10:40 INFO DAGScheduler: Job 10 finished: count at NativeMethodAccessorImpl.java:0, took 0.042630 s
21/03/14 15:10:40 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:10:40 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:10:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:10:40 INFO MemoryStore: MemoryStore cleared
21/03/14 15:10:40 INFO BlockManager: BlockManager stopped
21/03/14 15:10:40 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:10:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:10:40 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:10:40 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:10:40 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-b69556ae-6d84-4149-9ca0-648614ac085a
21/03/14 15:10:40 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-27b01b86-83e5-4b9f-b854-15361017f180
21/03/14 15:15:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:15:58 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:15:58 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:15:58 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:15:58 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:15:58 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:15:58 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:15:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:15:58 INFO Utils: Successfully started service 'sparkDriver' on port 63677.
21/03/14 15:15:58 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:15:58 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:15:58 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:15:58 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:15:58 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-5f672d30-1202-4fc4-8675-a4d9373efde6
21/03/14 15:15:58 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:15:58 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:15:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:15:58 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:15:58 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:63677/jars/sparklyr-2.4-2.11.jar with timestamp 1615731358882
21/03/14 15:15:58 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:15:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63678.
21/03/14 15:15:59 INFO NettyBlockTransferService: Server created on localhost:63678
21/03/14 15:15:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:15:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 63678, None)
21/03/14 15:15:59 INFO BlockManagerMasterEndpoint: Registering block manager localhost:63678 with 912.3 MB RAM, BlockManagerId(driver, localhost, 63678, None)
21/03/14 15:15:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 63678, None)
21/03/14 15:15:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 63678, None)
21/03/14 15:15:59 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:15:59 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:15:59 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:16:00 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:16:02 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:16:03 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:16:04 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:16:04 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:16:04 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:16:05 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:16:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:16:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:16:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:16:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:16:08 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:16:08 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:16:08 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:16:08 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:16:08 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:16:08 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:16:08 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:16:08 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:16:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:16:08 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:16:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:16:08 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:16:08 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/3bb4bba6-b9ad-4f79-90f5-fc6ba20bc000_resources
21/03/14 15:16:08 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/3bb4bba6-b9ad-4f79-90f5-fc6ba20bc000
21/03/14 15:16:08 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/3bb4bba6-b9ad-4f79-90f5-fc6ba20bc000
21/03/14 15:16:08 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/3bb4bba6-b9ad-4f79-90f5-fc6ba20bc000/_tmp_space.db
21/03/14 15:16:08 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:16:08 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:16:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:16:08 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:16:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:16:08 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:16:08 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:16:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:16:08 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:16:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:16:08 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:16:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:16:09 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 15:16:09 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/03/14 15:16:09 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/03/14 15:16:09 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:16:09 INFO DAGScheduler: Missing parents: List()
21/03/14 15:16:09 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/03/14 15:16:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/03/14 15:16:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/03/14 15:16:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:63678 (size: 3.4 KB, free: 912.3 MB)
21/03/14 15:16:10 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 15:16:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 15:16:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:16:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/03/14 15:16:10 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:16:10 INFO Executor: Fetching spark://localhost:63677/jars/sparklyr-2.4-2.11.jar with timestamp 1615731358882
21/03/14 15:16:10 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:63677 after 30 ms (0 ms spent in bootstraps)
21/03/14 15:16:10 INFO Utils: Fetching spark://localhost:63677/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-2b3c46ba-ce6c-48f7-936c-097b4897190c/userFiles-e4691d19-0051-4040-8ca3-666e831fd88f/fetchFileTemp7809857532763270596.tmp
21/03/14 15:16:10 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-2b3c46ba-ce6c-48f7-936c-097b4897190c/userFiles-e4691d19-0051-4040-8ca3-666e831fd88f/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:16:10 INFO CodeGenerator: Code generated in 245.381937 ms
21/03/14 15:16:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
21/03/14 15:16:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 700 ms on localhost (executor driver) (1/1)
21/03/14 15:16:10 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:16:10 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 1.183 s
21/03/14 15:16:10 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 1.271321 s
21/03/14 15:16:11 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:63678 in memory (size: 3.4 KB, free: 912.3 MB)
21/03/14 15:16:11 INFO CodeGenerator: Code generated in 20.274969 ms
21/03/14 15:16:11 INFO CodeGenerator: Code generated in 23.391797 ms
21/03/14 15:16:11 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:16:11 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:16:11 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:16:11 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:16:11 INFO DAGScheduler: Missing parents: List()
21/03/14 15:16:11 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/03/14 15:16:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 15:16:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 15:16:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:63678 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:16:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:16:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:16:11 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:16:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:16:11 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:16:11 INFO CodeGenerator: Code generated in 8.757815 ms
21/03/14 15:16:11 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 15:16:11 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 31 ms on localhost (executor driver) (1/1)
21/03/14 15:16:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:16:11 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.041 s
21/03/14 15:16:11 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.045128 s
21/03/14 15:16:12 INFO CodeGenerator: Code generated in 16.808182 ms
21/03/14 15:16:12 INFO CodeGenerator: Code generated in 16.489614 ms
21/03/14 15:16:12 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:16:12 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/03/14 15:16:12 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:16:12 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:16:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:16:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:16:12 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/03/14 15:16:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/03/14 15:16:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/03/14 15:16:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:63678 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:16:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 15:16:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:16:12 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:16:12 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:16:12 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:16:12 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:16:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 65 ms on localhost (executor driver) (1/1)
21/03/14 15:16:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:16:12 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.081 s
21/03/14 15:16:12 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:16:12 INFO DAGScheduler: running: Set()
21/03/14 15:16:12 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:16:12 INFO DAGScheduler: failed: Set()
21/03/14 15:16:12 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/03/14 15:16:12 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:16:12 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:16:12 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:63678 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:16:12 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:16:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:16:12 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:16:12 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:16:12 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:16:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:16:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
21/03/14 15:16:12 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:16:12 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 59 ms on localhost (executor driver) (1/1)
21/03/14 15:16:12 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:16:12 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.071 s
21/03/14 15:16:12 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.184581 s
21/03/14 15:16:12 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:16:12 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:16:12 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/03/14 15:16:12 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:16:12 INFO DAGScheduler: Missing parents: List()
21/03/14 15:16:12 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135), which has no missing parents
21/03/14 15:16:12 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 15:16:12 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 15:16:12 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:63678 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:16:12 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:16:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:16:12 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:16:12 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:16:12 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:16:12 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/03/14 15:16:12 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:16:12 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:16:12 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.014 s
21/03/14 15:16:12 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.018292 s
21/03/14 15:16:12 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:16:12 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:135)
21/03/14 15:16:12 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/14 15:16:12 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/03/14 15:16:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/03/14 15:16:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/03/14 15:16:12 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/03/14 15:16:12 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/03/14 15:16:12 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/03/14 15:16:12 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:63678 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:16:12 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:16:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:16:12 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:16:12 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:16:12 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:16:12 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/03/14 15:16:12 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 12 ms on localhost (executor driver) (1/1)
21/03/14 15:16:12 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:16:12 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.022 s
21/03/14 15:16:12 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:16:12 INFO DAGScheduler: running: Set()
21/03/14 15:16:12 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/03/14 15:16:12 INFO DAGScheduler: failed: Set()
21/03/14 15:16:12 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/03/14 15:16:12 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 15:16:12 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 15:16:12 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:63678 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:16:12 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 15:16:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:16:12 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:16:12 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:16:12 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:16:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:16:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:16:12 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/03/14 15:16:12 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 11 ms on localhost (executor driver) (1/1)
21/03/14 15:16:12 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:16:12 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.022 s
21/03/14 15:16:12 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.051714 s
21/03/14 15:16:13 INFO CodeGenerator: Code generated in 40.791043 ms
21/03/14 15:16:13 INFO CodeGenerator: Code generated in 17.668456 ms
21/03/14 15:16:13 INFO CodeGenerator: Code generated in 25.201455 ms
21/03/14 15:16:13 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:16:13 INFO DAGScheduler: Registering RDD 28 (count at utils.scala:135)
21/03/14 15:16:13 INFO DAGScheduler: Got job 5 (count at utils.scala:135) with 1 output partitions
21/03/14 15:16:13 INFO DAGScheduler: Final stage: ResultStage 8 (count at utils.scala:135)
21/03/14 15:16:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
21/03/14 15:16:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
21/03/14 15:16:13 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135), which has no missing parents
21/03/14 15:16:13 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 15:16:13 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 15:16:13 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:63678 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:16:13 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 15:16:13 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/03/14 15:16:13 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
21/03/14 15:16:13 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8034 bytes)
21/03/14 15:16:13 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 8, localhost, executor driver, partition 1, PROCESS_LOCAL, 8051 bytes)
21/03/14 15:16:13 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 9, localhost, executor driver, partition 2, PROCESS_LOCAL, 8051 bytes)
21/03/14 15:16:13 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 10, localhost, executor driver, partition 3, PROCESS_LOCAL, 8051 bytes)
21/03/14 15:16:13 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 15:16:13 INFO Executor: Running task 1.0 in stage 7.0 (TID 8)
21/03/14 15:16:13 INFO Executor: Running task 3.0 in stage 7.0 (TID 10)
21/03/14 15:16:13 INFO Executor: Running task 2.0 in stage 7.0 (TID 9)
21/03/14 15:16:13 INFO Executor: Finished task 2.0 in stage 7.0 (TID 9). 1499 bytes result sent to driver
21/03/14 15:16:13 INFO Executor: Finished task 3.0 in stage 7.0 (TID 10). 1499 bytes result sent to driver
21/03/14 15:16:13 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 9) in 12 ms on localhost (executor driver) (1/4)
21/03/14 15:16:13 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1499 bytes result sent to driver
21/03/14 15:16:13 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 10) in 12 ms on localhost (executor driver) (2/4)
21/03/14 15:16:13 INFO Executor: Finished task 1.0 in stage 7.0 (TID 8). 1499 bytes result sent to driver
21/03/14 15:16:13 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 15 ms on localhost (executor driver) (3/4)
21/03/14 15:16:13 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 8) in 15 ms on localhost (executor driver) (4/4)
21/03/14 15:16:13 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 15:16:13 INFO DAGScheduler: ShuffleMapStage 7 (count at utils.scala:135) finished in 0.025 s
21/03/14 15:16:13 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:16:13 INFO DAGScheduler: running: Set()
21/03/14 15:16:13 INFO DAGScheduler: waiting: Set(ResultStage 8)
21/03/14 15:16:13 INFO DAGScheduler: failed: Set()
21/03/14 15:16:13 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135), which has no missing parents
21/03/14 15:16:13 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 15:16:13 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 15:16:13 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:63678 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:16:13 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 15:16:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:16:13 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 15:16:13 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:16:13 INFO Executor: Running task 0.0 in stage 8.0 (TID 11)
21/03/14 15:16:13 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
21/03/14 15:16:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:16:13 INFO Executor: Finished task 0.0 in stage 8.0 (TID 11). 1782 bytes result sent to driver
21/03/14 15:16:13 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 11) in 10 ms on localhost (executor driver) (1/1)
21/03/14 15:16:13 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 15:16:13 INFO DAGScheduler: ResultStage 8 (count at utils.scala:135) finished in 0.017 s
21/03/14 15:16:13 INFO DAGScheduler: Job 5 finished: count at utils.scala:135, took 0.047594 s
21/03/14 15:16:13 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:16:13 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:16:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:16:13 INFO MemoryStore: MemoryStore cleared
21/03/14 15:16:13 INFO BlockManager: BlockManager stopped
21/03/14 15:16:13 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:16:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:16:13 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:16:13 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:16:13 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-6188af10-f7a5-4757-9ffe-f24531370e78
21/03/14 15:16:13 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-2b3c46ba-ce6c-48f7-936c-097b4897190c
21/03/14 15:16:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:16:17 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:16:17 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:16:17 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:16:17 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:16:17 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:16:17 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:16:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:16:17 INFO Utils: Successfully started service 'sparkDriver' on port 63778.
21/03/14 15:16:17 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:16:17 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:16:17 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:16:17 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:16:17 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-6954634d-3877-42a4-bc3c-f1e903ca1739
21/03/14 15:16:17 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:16:17 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:16:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:16:18 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:16:18 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:63778/jars/sparklyr-2.4-2.11.jar with timestamp 1615731378191
21/03/14 15:16:18 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:16:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63781.
21/03/14 15:16:18 INFO NettyBlockTransferService: Server created on localhost:63781
21/03/14 15:16:18 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:16:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 63781, None)
21/03/14 15:16:18 INFO BlockManagerMasterEndpoint: Registering block manager localhost:63781 with 912.3 MB RAM, BlockManagerId(driver, localhost, 63781, None)
21/03/14 15:16:18 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 63781, None)
21/03/14 15:16:18 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 63781, None)
21/03/14 15:16:18 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:16:18 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:16:18 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:16:19 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:16:21 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:16:22 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:16:22 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:16:22 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:16:22 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:16:24 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:16:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:16:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:16:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:16:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:16:26 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:16:26 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:16:26 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:16:27 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:16:27 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:16:27 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:16:27 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:16:27 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:16:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:16:27 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:16:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:16:27 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:16:27 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/416575e5-af33-465a-bddb-47b6e851dc84_resources
21/03/14 15:16:27 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/416575e5-af33-465a-bddb-47b6e851dc84
21/03/14 15:16:27 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/416575e5-af33-465a-bddb-47b6e851dc84
21/03/14 15:16:27 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/416575e5-af33-465a-bddb-47b6e851dc84/_tmp_space.db
21/03/14 15:16:27 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:16:27 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:16:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:16:27 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:16:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:16:27 INFO HiveMetaStore: 0: get_database: fake_database
21/03/14 15:16:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: fake_database	
21/03/14 15:16:27 WARN ObjectStore: Failed to get database fake_database, returning NoSuchObjectException
21/03/14 15:16:27 INFO HiveMetaStore: 0: get_databases: *
21/03/14 15:16:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_databases: *	
21/03/14 15:16:27 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:16:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:16:27 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:16:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:16:28 INFO CodeGenerator: Code generated in 330.741741 ms
21/03/14 15:16:29 INFO CodeGenerator: Code generated in 23.736901 ms
21/03/14 15:16:29 INFO CodeGenerator: Code generated in 17.035582 ms
21/03/14 15:16:29 INFO ContextCleaner: Cleaned accumulator 1
21/03/14 15:16:29 INFO CodeGenerator: Code generated in 23.913149 ms
21/03/14 15:16:29 INFO CodeGenerator: Code generated in 15.212982 ms
21/03/14 15:16:29 INFO CodeGenerator: Code generated in 11.647329 ms
21/03/14 15:16:30 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:16:30 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:135)
21/03/14 15:16:30 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/03/14 15:16:30 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/03/14 15:16:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/03/14 15:16:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/03/14 15:16:30 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135), which has no missing parents
21/03/14 15:16:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 15:16:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 15:16:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:63781 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:16:30 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 15:16:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:16:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:16:30 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 15:16:30 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:16:30 INFO Executor: Fetching spark://localhost:63778/jars/sparklyr-2.4-2.11.jar with timestamp 1615731378191
21/03/14 15:16:30 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:63778 after 29 ms (0 ms spent in bootstraps)
21/03/14 15:16:30 INFO Utils: Fetching spark://localhost:63778/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-b8bc50a9-ec12-4498-b995-640321b73907/userFiles-01709692-21b9-400a-acaa-7b1a49179f05/fetchFileTemp2389022403779247953.tmp
21/03/14 15:16:30 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-b8bc50a9-ec12-4498-b995-640321b73907/userFiles-01709692-21b9-400a-acaa-7b1a49179f05/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:16:31 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1585 bytes result sent to driver
21/03/14 15:16:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 548 ms on localhost (executor driver) (1/1)
21/03/14 15:16:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:16:31 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:135) finished in 0.975 s
21/03/14 15:16:31 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:16:31 INFO DAGScheduler: running: Set()
21/03/14 15:16:31 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/03/14 15:16:31 INFO DAGScheduler: failed: Set()
21/03/14 15:16:31 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135), which has no missing parents
21/03/14 15:16:31 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:16:31 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:16:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:63781 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:16:31 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:16:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:16:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:16:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:16:31 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:16:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:16:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
21/03/14 15:16:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1825 bytes result sent to driver
21/03/14 15:16:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 77 ms on localhost (executor driver) (1/1)
21/03/14 15:16:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:16:31 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.099 s
21/03/14 15:16:31 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 1.169109 s
21/03/14 15:16:31 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:16:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:16:31 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:16:31 INFO HiveMetaStore: 0: create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})
21/03/14 15:16:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})	
21/03/14 15:16:31 WARN ObjectStore: Failed to get database catalog_test_database_db, returning NoSuchObjectException
21/03/14 15:16:31 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 15:16:31 INFO CodeGenerator: Code generated in 9.877117 ms
21/03/14 15:16:31 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:16:31 INFO DAGScheduler: Registering RDD 10 (count at utils.scala:135)
21/03/14 15:16:31 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/03/14 15:16:31 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:16:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:16:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:16:31 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[10] at count at utils.scala:135), which has no missing parents
21/03/14 15:16:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 15:16:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 15:16:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:63781 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:16:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 15:16:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[10] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:16:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:16:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 15:16:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:16:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1499 bytes result sent to driver
21/03/14 15:16:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 13 ms on localhost (executor driver) (1/1)
21/03/14 15:16:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:16:31 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.023 s
21/03/14 15:16:31 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:16:31 INFO DAGScheduler: running: Set()
21/03/14 15:16:31 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:16:31 INFO DAGScheduler: failed: Set()
21/03/14 15:16:31 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[13] at count at utils.scala:135), which has no missing parents
21/03/14 15:16:31 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:16:31 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:16:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:63781 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:16:31 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:16:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:16:31 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:16:31 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:16:31 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:16:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:16:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:16:31 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1775 bytes result sent to driver
21/03/14 15:16:31 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 11 ms on localhost (executor driver) (1/1)
21/03/14 15:16:31 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:16:31 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.021 s
21/03/14 15:16:31 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.052921 s
21/03/14 15:16:31 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 15:16:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 15:16:31 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 15:16:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 15:16:31 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 15:16:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 15:16:31 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:16:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:16:31 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:16:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:16:31 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:16:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:16:31 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 15:16:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 15:16:31 INFO HiveMetaStore: 0: drop_database: catalog_test_database_db
21/03/14 15:16:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=drop_database: catalog_test_database_db	
21/03/14 15:16:31 INFO HiveMetaStore: 0: get_all_tables: db=catalog_test_database_db
21/03/14 15:16:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_tables: db=catalog_test_database_db	
21/03/14 15:16:32 INFO HiveMetaStore: 0: get_functions: db=catalog_test_database_db pat=*
21/03/14 15:16:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=catalog_test_database_db pat=*	
21/03/14 15:16:32 INFO ObjectStore: Dropping database catalog_test_database_db along with all tables
21/03/14 15:16:32 INFO hivemetastoressimpl: deleting  file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 15:16:32 INFO deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
21/03/14 15:16:32 INFO TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
21/03/14 15:16:32 INFO hivemetastoressimpl: Deleted the diretory file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 15:16:32 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:16:32 INFO DAGScheduler: Registering RDD 17 (count at utils.scala:135)
21/03/14 15:16:32 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:16:32 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/03/14 15:16:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 15:16:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 15:16:32 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at count at utils.scala:135), which has no missing parents
21/03/14 15:16:32 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 15:16:32 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 15:16:32 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:63781 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:16:32 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:16:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:16:32 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:16:32 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 15:16:32 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:16:32 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1499 bytes result sent to driver
21/03/14 15:16:32 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 10 ms on localhost (executor driver) (1/1)
21/03/14 15:16:32 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:16:32 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.019 s
21/03/14 15:16:32 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:16:32 INFO DAGScheduler: running: Set()
21/03/14 15:16:32 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 15:16:32 INFO DAGScheduler: failed: Set()
21/03/14 15:16:32 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[20] at count at utils.scala:135), which has no missing parents
21/03/14 15:16:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 15:16:32 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 15:16:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:63781 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:16:32 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:16:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:16:32 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:16:32 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:16:32 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:16:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:16:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:16:32 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1775 bytes result sent to driver
21/03/14 15:16:32 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:16:32 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:16:32 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.017 s
21/03/14 15:16:32 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.043551 s
21/03/14 15:16:32 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:16:32 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:16:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:16:32 INFO MemoryStore: MemoryStore cleared
21/03/14 15:16:32 INFO BlockManager: BlockManager stopped
21/03/14 15:16:32 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:16:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:16:32 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:16:32 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:16:32 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-b8bc50a9-ec12-4498-b995-640321b73907
21/03/14 15:16:32 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-8fb69dc4-9450-45c5-a8d3-cf8c0f14e66f
21/03/14 15:16:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:16:36 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:16:36 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:16:36 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:16:36 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:16:36 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:16:36 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:16:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:16:36 INFO Utils: Successfully started service 'sparkDriver' on port 63877.
21/03/14 15:16:36 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:16:36 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:16:36 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:16:36 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:16:36 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-1b72edb8-6987-45bb-994e-6efdca88d66e
21/03/14 15:16:36 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:16:36 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:16:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:16:36 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:16:36 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:63877/jars/sparklyr-2.4-2.11.jar with timestamp 1615731396639
21/03/14 15:16:36 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:16:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63878.
21/03/14 15:16:36 INFO NettyBlockTransferService: Server created on localhost:63878
21/03/14 15:16:36 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:16:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 63878, None)
21/03/14 15:16:36 INFO BlockManagerMasterEndpoint: Registering block manager localhost:63878 with 912.3 MB RAM, BlockManagerId(driver, localhost, 63878, None)
21/03/14 15:16:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 63878, None)
21/03/14 15:16:36 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 63878, None)
21/03/14 15:16:37 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:16:37 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:16:37 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:16:37 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:16:40 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:16:40 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:16:40 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:16:41 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:16:41 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:16:42 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:16:43 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:16:43 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:16:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:16:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:16:45 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:16:45 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:16:45 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:16:45 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:16:45 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:16:45 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:16:45 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:16:45 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:16:45 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:16:45 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:16:45 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:16:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:16:45 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/f46cea3c-ac25-478f-9a8a-bb8c747c9a24_resources
21/03/14 15:16:45 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/f46cea3c-ac25-478f-9a8a-bb8c747c9a24
21/03/14 15:16:45 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/f46cea3c-ac25-478f-9a8a-bb8c747c9a24
21/03/14 15:16:45 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/f46cea3c-ac25-478f-9a8a-bb8c747c9a24/_tmp_space.db
21/03/14 15:16:45 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:16:45 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:16:45 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:16:45 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:16:45 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:16:45 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:16:45 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:16:45 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:16:45 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:16:45 INFO HiveMetaStore: 0: get_function: default.catalog_fake_function
21/03/14 15:16:45 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_function: default.catalog_fake_function	
21/03/14 15:16:46 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:16:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:16:46 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:16:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:16:46 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:16:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:16:46 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:16:46 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:16:47 INFO CodeGenerator: Code generated in 364.092545 ms
21/03/14 15:16:47 INFO CodeGenerator: Code generated in 22.772245 ms
21/03/14 15:16:47 INFO CodeGenerator: Code generated in 23.838145 ms
21/03/14 15:16:48 INFO CodeGenerator: Code generated in 19.164002 ms
21/03/14 15:16:48 INFO CodeGenerator: Code generated in 18.717898 ms
21/03/14 15:16:48 INFO CodeGenerator: Code generated in 8.662413 ms
21/03/14 15:16:48 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:16:48 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:135)
21/03/14 15:16:48 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/03/14 15:16:48 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/03/14 15:16:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/03/14 15:16:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/03/14 15:16:48 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135), which has no missing parents
21/03/14 15:16:48 INFO ContextCleaner: Cleaned accumulator 1
21/03/14 15:16:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 15:16:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 15:16:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:63878 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:16:49 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 15:16:49 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/03/14 15:16:49 INFO TaskSchedulerImpl: Adding task set 0.0 with 4 tasks
21/03/14 15:16:49 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 9258 bytes)
21/03/14 15:16:49 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 9275 bytes)
21/03/14 15:16:49 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 9258 bytes)
21/03/14 15:16:49 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 9275 bytes)
21/03/14 15:16:49 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
21/03/14 15:16:49 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
21/03/14 15:16:49 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
21/03/14 15:16:49 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:16:49 INFO Executor: Fetching spark://localhost:63877/jars/sparklyr-2.4-2.11.jar with timestamp 1615731396639
21/03/14 15:16:49 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:63877 after 31 ms (0 ms spent in bootstraps)
21/03/14 15:16:49 INFO Utils: Fetching spark://localhost:63877/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-5537d609-771a-412b-9ce7-c134e03996d3/userFiles-bdb36348-61fb-4236-9457-d2fa68face45/fetchFileTemp1179204636568879394.tmp
21/03/14 15:16:49 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-5537d609-771a-412b-9ce7-c134e03996d3/userFiles-bdb36348-61fb-4236-9457-d2fa68face45/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:16:49 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1542 bytes result sent to driver
21/03/14 15:16:49 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1542 bytes result sent to driver
21/03/14 15:16:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1542 bytes result sent to driver
21/03/14 15:16:49 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:16:49 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 350 ms on localhost (executor driver) (1/4)
21/03/14 15:16:49 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 356 ms on localhost (executor driver) (2/4)
21/03/14 15:16:49 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 356 ms on localhost (executor driver) (3/4)
21/03/14 15:16:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 379 ms on localhost (executor driver) (4/4)
21/03/14 15:16:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:16:49 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:135) finished in 0.811 s
21/03/14 15:16:49 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:16:49 INFO DAGScheduler: running: Set()
21/03/14 15:16:49 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/03/14 15:16:49 INFO DAGScheduler: failed: Set()
21/03/14 15:16:49 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135), which has no missing parents
21/03/14 15:16:49 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:16:49 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:16:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:63878 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:16:49 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:16:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:16:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:16:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:16:49 INFO Executor: Running task 0.0 in stage 1.0 (TID 4)
21/03/14 15:16:49 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
21/03/14 15:16:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
21/03/14 15:16:49 INFO Executor: Finished task 0.0 in stage 1.0 (TID 4). 1825 bytes result sent to driver
21/03/14 15:16:49 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 4) in 69 ms on localhost (executor driver) (1/1)
21/03/14 15:16:49 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:16:49 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.086 s
21/03/14 15:16:49 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.983326 s
21/03/14 15:16:49 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:16:49 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:16:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:16:49 INFO MemoryStore: MemoryStore cleared
21/03/14 15:16:49 INFO BlockManager: BlockManager stopped
21/03/14 15:16:49 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:16:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:16:49 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:16:49 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:16:49 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-5537d609-771a-412b-9ce7-c134e03996d3
21/03/14 15:16:49 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-cdddbbd5-d0a0-4c97-93cc-f6e34ec4dd47
21/03/14 15:16:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:16:53 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:16:53 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:16:53 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:16:53 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:16:53 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:16:53 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:16:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:16:53 INFO Utils: Successfully started service 'sparkDriver' on port 63975.
21/03/14 15:16:53 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:16:53 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:16:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:16:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:16:53 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-739680b6-1b43-479f-a70e-ecfa42bee078
21/03/14 15:16:53 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:16:53 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:16:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:16:54 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:16:54 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:63975/jars/sparklyr-2.4-2.11.jar with timestamp 1615731414222
21/03/14 15:16:54 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:16:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63976.
21/03/14 15:16:54 INFO NettyBlockTransferService: Server created on localhost:63976
21/03/14 15:16:54 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:16:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 63976, None)
21/03/14 15:16:54 INFO BlockManagerMasterEndpoint: Registering block manager localhost:63976 with 912.3 MB RAM, BlockManagerId(driver, localhost, 63976, None)
21/03/14 15:16:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 63976, None)
21/03/14 15:16:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 63976, None)
21/03/14 15:16:54 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:16:54 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:16:54 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:16:55 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:16:58 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:16:59 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:16:59 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:16:59 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:16:59 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:17:01 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:17:02 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:17:02 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:17:02 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:17:02 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:17:02 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:17:02 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:17:02 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:17:02 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:17:03 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:17:03 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:17:03 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:17:03 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:17:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:17:03 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:17:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:17:03 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:17:03 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/72db4ee5-d1ac-46d8-83b7-75f56c516fd4_resources
21/03/14 15:17:03 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/72db4ee5-d1ac-46d8-83b7-75f56c516fd4
21/03/14 15:17:03 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/72db4ee5-d1ac-46d8-83b7-75f56c516fd4
21/03/14 15:17:03 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/72db4ee5-d1ac-46d8-83b7-75f56c516fd4/_tmp_space.db
21/03/14 15:17:03 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:17:03 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:17:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:17:03 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:04 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:17:04 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
21/03/14 15:17:04 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:17:04 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:17:04 INFO CodeGenerator: Code generated in 258.91272 ms
21/03/14 15:17:04 INFO CodeGenerator: Code generated in 20.986864 ms
21/03/14 15:17:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 284.3 KB, free 912.0 MB)
21/03/14 15:17:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.9 KB, free 912.0 MB)
21/03/14 15:17:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:63976 (size: 23.9 KB, free: 912.3 MB)
21/03/14 15:17:05 INFO SparkContext: Created broadcast 0 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:17:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:17:05 INFO SparkContext: Starting job: createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:17:05 INFO DAGScheduler: Got job 0 (createTable at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:17:05 INFO DAGScheduler: Final stage: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0)
21/03/14 15:17:05 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:17:05 INFO DAGScheduler: Missing parents: List()
21/03/14 15:17:05 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:17:05 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 912.0 MB)
21/03/14 15:17:05 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.0 MB)
21/03/14 15:17:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:63976 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:17:05 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:05 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:17:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8362 bytes)
21/03/14 15:17:05 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:17:05 INFO Executor: Fetching spark://localhost:63975/jars/sparklyr-2.4-2.11.jar with timestamp 1615731414222
21/03/14 15:17:05 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:63975 after 30 ms (0 ms spent in bootstraps)
21/03/14 15:17:05 INFO Utils: Fetching spark://localhost:63975/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-d925651c-d6d4-452b-bdd2-ea644f4bb03c/userFiles-ec643725-3b30-4234-a782-2f81b2a7142c/fetchFileTemp992285348144699816.tmp
21/03/14 15:17:05 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-d925651c-d6d4-452b-bdd2-ea644f4bb03c/userFiles-ec643725-3b30-4234-a782-2f81b2a7142c/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:17:05 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpWTCUuF/file15f5f15a1528f, range: 0-1303, partition values: [empty row]
21/03/14 15:17:05 INFO CodeGenerator: Code generated in 14.496332 ms
21/03/14 15:17:05 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1329 bytes result sent to driver
21/03/14 15:17:05 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 377 ms on localhost (executor driver) (1/1)
21/03/14 15:17:05 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:17:05 INFO DAGScheduler: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0) finished in 0.568 s
21/03/14 15:17:06 INFO DAGScheduler: Job 0 finished: createTable at NativeMethodAccessorImpl.java:0, took 0.711141 s
21/03/14 15:17:06 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:17:06 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:17:06 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:17:06 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:17:06 INFO CodeGenerator: Code generated in 16.534028 ms
21/03/14 15:17:06 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 284.3 KB, free 911.7 MB)
21/03/14 15:17:06 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.7 MB)
21/03/14 15:17:06 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:63976 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:17:06 INFO SparkContext: Created broadcast 2 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:17:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:17:06 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:17:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:17:06 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:06 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:17:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:17:06 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:06 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `default`.`mtcars` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.
21/03/14 15:17:06 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:17:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:17:06 INFO HiveMetaStore: 0: create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615731417, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpWTCUuF/file15f5f15a1528f, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
21/03/14 15:17:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615731417, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpWTCUuF/file15f5f15a1528f, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
21/03/14 15:17:06 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__
21/03/14 15:17:06 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:17:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:17:06 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:17:06 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:06 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:07 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:07 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:07 INFO CodeGenerator: Code generated in 18.798044 ms
21/03/14 15:17:07 INFO CodeGenerator: Code generated in 15.682453 ms
21/03/14 15:17:07 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:17:07 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:17:07 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:17:07 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:17:07 INFO DAGScheduler: Missing parents: List()
21/03/14 15:17:07 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135), which has no missing parents
21/03/14 15:17:07 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.5 KB, free 911.7 MB)
21/03/14 15:17:07 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 15:17:07 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:63976 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:17:07 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:07 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:17:07 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:17:07 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:17:07 INFO CodeGenerator: Code generated in 8.507712 ms
21/03/14 15:17:07 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 15:17:07 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 31 ms on localhost (executor driver) (1/1)
21/03/14 15:17:07 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:17:07 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.041 s
21/03/14 15:17:07 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.048111 s
21/03/14 15:17:07 INFO CodeGenerator: Code generated in 18.816302 ms
21/03/14 15:17:07 INFO CodeGenerator: Code generated in 18.650239 ms
21/03/14 15:17:07 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:17:07 INFO DAGScheduler: Registering RDD 16 (count at utils.scala:135)
21/03/14 15:17:07 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:17:07 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:17:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:17:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:17:07 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135), which has no missing parents
21/03/14 15:17:07 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.4 KB, free 911.7 MB)
21/03/14 15:17:07 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.7 MB)
21/03/14 15:17:07 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:63976 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:17:07 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:17:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:17:07 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:17:07 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:17:07 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 66 ms on localhost (executor driver) (1/1)
21/03/14 15:17:07 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:17:07 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.084 s
21/03/14 15:17:07 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:17:07 INFO DAGScheduler: running: Set()
21/03/14 15:17:07 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:17:07 INFO DAGScheduler: failed: Set()
21/03/14 15:17:07 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135), which has no missing parents
21/03/14 15:17:07 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 15:17:07 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 15:17:07 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:63976 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:17:07 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:07 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:17:07 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:17:07 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:17:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:17:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
21/03/14 15:17:08 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:17:08 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 73 ms on localhost (executor driver) (1/1)
21/03/14 15:17:08 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:17:08 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.085 s
21/03/14 15:17:08 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.203059 s
21/03/14 15:17:08 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:08 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:08 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:08 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:17:08 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:17:08 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:17:08 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:17:08 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:08 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:08 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 284.5 KB, free 911.4 MB)
21/03/14 15:17:08 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.4 MB)
21/03/14 15:17:08 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:63976 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:17:08 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:17:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:17:08 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:17:08 INFO DAGScheduler: Registering RDD 27 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:17:08 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:17:08 INFO DAGScheduler: Final stage: ResultStage 5 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:17:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 15:17:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 15:17:08 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:17:08 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 911.3 MB)
21/03/14 15:17:08 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 12.2 KB, free 911.3 MB)
21/03/14 15:17:08 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:63976 (size: 12.2 KB, free: 912.2 MB)
21/03/14 15:17:08 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:08 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:17:08 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:17:08 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:17:08 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpWTCUuF/file15f5f15a1528f, range: 0-1303, partition values: [empty row]
21/03/14 15:17:08 INFO CodeGenerator: Code generated in 22.019569 ms
21/03/14 15:17:08 INFO MemoryStore: Block rdd_22_0 stored as values in memory (estimated size 4.1 KB, free 911.3 MB)
21/03/14 15:17:08 INFO BlockManagerInfo: Added rdd_22_0 in memory on localhost:63976 (size: 4.1 KB, free: 912.2 MB)
21/03/14 15:17:08 INFO CodeGenerator: Code generated in 8.171295 ms
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 114
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 118
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 28
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 108
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 36
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 117
21/03/14 15:17:08 INFO CodeGenerator: Code generated in 99.683801 ms
21/03/14 15:17:08 INFO ContextCleaner: Cleaned shuffle 0
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 80
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 113
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 72
21/03/14 15:17:08 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1914 bytes result sent to driver
21/03/14 15:17:08 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:63976 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:17:08 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 312 ms on localhost (executor driver) (1/1)
21/03/14 15:17:08 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:17:08 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.353 s
21/03/14 15:17:08 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:17:08 INFO DAGScheduler: running: Set()
21/03/14 15:17:08 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 15:17:08 INFO DAGScheduler: failed: Set()
21/03/14 15:17:08 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 12
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 121
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 70
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 91
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 73
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 120
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 94
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 111
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 122
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 97
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 101
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 29
21/03/14 15:17:08 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 15:17:08 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:63976 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:17:08 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 9
21/03/14 15:17:08 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:63976 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 87
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 6
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 104
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 81
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 82
21/03/14 15:17:08 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 124
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 67
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 96
21/03/14 15:17:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:08 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:17:08 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:63976 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:17:08 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:17:08 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 85
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 95
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 10
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 71
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 19
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 66
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 83
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 13
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 37
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 65
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 76
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 105
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 27
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 125
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 86
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 14
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 89
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 90
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 23
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 99
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 21
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 16
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 84
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 30
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 129
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 26
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 20
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 15
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 8
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 88
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 7
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 64
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 78
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 68
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 107
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 69
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 77
21/03/14 15:17:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:17:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:17:08 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:63976 in memory (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:17:08 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1782 bytes result sent to driver
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 92
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 98
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 127
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 115
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 75
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 100
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 79
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 112
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 116
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 15:17:08 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 22
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 110
21/03/14 15:17:08 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 11
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 24
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 109
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 74
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 123
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 126
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 106
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 18
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 17
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 93
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 119
21/03/14 15:17:08 INFO DAGScheduler: ResultStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.016 s
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 25
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 102
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 103
21/03/14 15:17:08 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 15:17:08 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.379351 s
21/03/14 15:17:08 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:08 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:09 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:17:09 INFO DAGScheduler: Registering RDD 35 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:17:09 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:17:09 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:17:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
21/03/14 15:17:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
21/03/14 15:17:09 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:17:09 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 25.9 KB, free 911.3 MB)
21/03/14 15:17:09 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.1 KB, free 911.3 MB)
21/03/14 15:17:09 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:63976 (size: 12.1 KB, free: 912.2 MB)
21/03/14 15:17:09 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:09 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:17:09 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:17:09 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:17:09 INFO BlockManager: Found block rdd_22_0 locally
21/03/14 15:17:09 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1871 bytes result sent to driver
21/03/14 15:17:09 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 17 ms on localhost (executor driver) (1/1)
21/03/14 15:17:09 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:17:09 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.031 s
21/03/14 15:17:09 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:17:09 INFO DAGScheduler: running: Set()
21/03/14 15:17:09 INFO DAGScheduler: waiting: Set(ResultStage 7)
21/03/14 15:17:09 INFO DAGScheduler: failed: Set()
21/03/14 15:17:09 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:17:09 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 15:17:09 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 15:17:09 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:63976 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:17:09 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:09 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/14 15:17:09 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:17:09 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 15:17:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:17:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:17:09 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1782 bytes result sent to driver
21/03/14 15:17:09 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:17:09 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 15:17:09 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.015 s
21/03/14 15:17:09 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.052619 s
21/03/14 15:17:09 INFO MapPartitionsRDD: Removing RDD 22 from persistence list
21/03/14 15:17:09 INFO BlockManager: Removing RDD 22
21/03/14 15:17:09 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:17:09 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:17:09 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:17:09 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:17:09 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:09 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:09 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 284.5 KB, free 911.0 MB)
21/03/14 15:17:09 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.0 MB)
21/03/14 15:17:09 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:63976 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:17:09 INFO SparkContext: Created broadcast 11 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:17:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:17:09 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:17:09 INFO DAGScheduler: Registering RDD 46 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:17:09 INFO DAGScheduler: Got job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:17:09 INFO DAGScheduler: Final stage: ResultStage 9 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:17:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/03/14 15:17:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
21/03/14 15:17:09 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:17:09 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 25.9 KB, free 911.0 MB)
21/03/14 15:17:09 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 12.2 KB, free 911.0 MB)
21/03/14 15:17:09 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:63976 (size: 12.2 KB, free: 912.2 MB)
21/03/14 15:17:09 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:09 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 15:17:09 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:17:09 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/03/14 15:17:09 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpWTCUuF/file15f5f15a1528f, range: 0-2539, partition values: [empty row]
21/03/14 15:17:09 INFO MemoryStore: Block rdd_41_0 stored as values in memory (estimated size 4.9 KB, free 911.0 MB)
21/03/14 15:17:09 INFO BlockManagerInfo: Added rdd_41_0 in memory on localhost:63976 (size: 4.9 KB, free: 912.2 MB)
21/03/14 15:17:09 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1871 bytes result sent to driver
21/03/14 15:17:09 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 45 ms on localhost (executor driver) (1/1)
21/03/14 15:17:09 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 15:17:09 INFO DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.057 s
21/03/14 15:17:09 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:17:09 INFO DAGScheduler: running: Set()
21/03/14 15:17:09 INFO DAGScheduler: waiting: Set(ResultStage 9)
21/03/14 15:17:09 INFO DAGScheduler: failed: Set()
21/03/14 15:17:09 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[49] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:17:09 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.1 KB, free 911.0 MB)
21/03/14 15:17:09 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.8 KB, free 910.9 MB)
21/03/14 15:17:09 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:63976 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:17:09 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[49] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:09 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 15:17:09 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:17:09 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/03/14 15:17:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:17:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:17:09 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1782 bytes result sent to driver
21/03/14 15:17:09 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:17:09 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 15:17:09 INFO DAGScheduler: ResultStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.014 s
21/03/14 15:17:09 INFO DAGScheduler: Job 5 finished: count at NativeMethodAccessorImpl.java:0, took 0.077550 s
21/03/14 15:17:09 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:17:09 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:17:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:17:09 INFO MemoryStore: MemoryStore cleared
21/03/14 15:17:09 INFO BlockManager: BlockManager stopped
21/03/14 15:17:09 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:17:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:17:09 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:17:09 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:17:09 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-d925651c-d6d4-452b-bdd2-ea644f4bb03c
21/03/14 15:17:09 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-f979b3be-a6de-4377-b22e-e90fb4225adc
21/03/14 15:17:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:17:13 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:17:13 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:17:13 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:17:13 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:17:13 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:17:13 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:17:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:17:13 INFO Utils: Successfully started service 'sparkDriver' on port 64076.
21/03/14 15:17:13 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:17:13 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:17:13 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:17:13 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:17:13 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-3e19c985-ce99-4333-83c0-2c2a43c8fe3c
21/03/14 15:17:13 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:17:13 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:17:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:17:13 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:17:13 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:64076/jars/sparklyr-2.4-2.11.jar with timestamp 1615731433923
21/03/14 15:17:14 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:17:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64077.
21/03/14 15:17:14 INFO NettyBlockTransferService: Server created on localhost:64077
21/03/14 15:17:14 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:17:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 64077, None)
21/03/14 15:17:14 INFO BlockManagerMasterEndpoint: Registering block manager localhost:64077 with 912.3 MB RAM, BlockManagerId(driver, localhost, 64077, None)
21/03/14 15:17:14 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 64077, None)
21/03/14 15:17:14 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 64077, None)
21/03/14 15:17:14 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:17:14 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:17:14 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:17:15 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:17:18 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:17:19 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:17:19 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:17:19 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:17:19 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:17:20 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:17:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:17:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:17:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:17:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:17:23 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:17:23 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:17:23 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:17:23 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:17:23 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:17:23 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:17:23 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:17:23 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:17:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:17:23 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:17:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:17:23 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:17:23 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/530b0656-4398-482a-966a-7246c4e354b6_resources
21/03/14 15:17:23 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/530b0656-4398-482a-966a-7246c4e354b6
21/03/14 15:17:23 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/530b0656-4398-482a-966a-7246c4e354b6
21/03/14 15:17:23 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/530b0656-4398-482a-966a-7246c4e354b6/_tmp_space.db
21/03/14 15:17:23 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:17:23 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:17:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:17:23 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:24 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:17:24 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
21/03/14 15:17:24 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:17:24 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:17:25 INFO CodeGenerator: Code generated in 381.81408 ms
21/03/14 15:17:25 INFO CodeGenerator: Code generated in 20.885097 ms
21/03/14 15:17:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 284.3 KB, free 912.0 MB)
21/03/14 15:17:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.9 KB, free 912.0 MB)
21/03/14 15:17:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:64077 (size: 23.9 KB, free: 912.3 MB)
21/03/14 15:17:25 INFO SparkContext: Created broadcast 0 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:17:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:17:25 INFO SparkContext: Starting job: createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:17:25 INFO DAGScheduler: Got job 0 (createTable at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:17:25 INFO DAGScheduler: Final stage: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0)
21/03/14 15:17:25 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:17:25 INFO DAGScheduler: Missing parents: List()
21/03/14 15:17:26 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:17:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 912.0 MB)
21/03/14 15:17:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.0 MB)
21/03/14 15:17:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:64077 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:17:26 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:17:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8362 bytes)
21/03/14 15:17:26 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:17:26 INFO Executor: Fetching spark://localhost:64076/jars/sparklyr-2.4-2.11.jar with timestamp 1615731433923
21/03/14 15:17:26 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:64076 after 27 ms (0 ms spent in bootstraps)
21/03/14 15:17:26 INFO Utils: Fetching spark://localhost:64076/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-2f4b141c-4b96-4da2-bb29-ccc8814ccbf9/userFiles-757a79cf-d7df-4b50-9a5f-3b4c1503e36f/fetchFileTemp6967301380696442521.tmp
21/03/14 15:17:26 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-2f4b141c-4b96-4da2-bb29-ccc8814ccbf9/userFiles-757a79cf-d7df-4b50-9a5f-3b4c1503e36f/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:17:26 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpWTCUuF/file15f5f6b5cf10b, range: 0-1303, partition values: [empty row]
21/03/14 15:17:26 INFO CodeGenerator: Code generated in 23.161314 ms
21/03/14 15:17:26 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1372 bytes result sent to driver
21/03/14 15:17:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 390 ms on localhost (executor driver) (1/1)
21/03/14 15:17:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:17:26 INFO DAGScheduler: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0) finished in 0.568 s
21/03/14 15:17:26 INFO DAGScheduler: Job 0 finished: createTable at NativeMethodAccessorImpl.java:0, took 0.911829 s
21/03/14 15:17:26 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:17:26 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:17:26 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:17:26 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:17:26 INFO CodeGenerator: Code generated in 12.814573 ms
21/03/14 15:17:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 284.3 KB, free 911.7 MB)
21/03/14 15:17:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.7 MB)
21/03/14 15:17:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:64077 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:17:26 INFO SparkContext: Created broadcast 2 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:17:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:17:26 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:17:26 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:17:26 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:26 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:26 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:17:26 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:17:26 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:26 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:26 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `default`.`mtcars` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.
21/03/14 15:17:26 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:17:26 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:17:27 INFO HiveMetaStore: 0: create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615731437, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpWTCUuF/file15f5f6b5cf10b, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
21/03/14 15:17:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615731437, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpWTCUuF/file15f5f6b5cf10b, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
21/03/14 15:17:27 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__
21/03/14 15:17:27 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:17:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:17:27 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:17:27 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:27 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:28 INFO CodeGenerator: Code generated in 24.170273 ms
21/03/14 15:17:28 INFO CodeGenerator: Code generated in 15.915814 ms
21/03/14 15:17:28 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:17:28 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:17:28 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:17:28 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:17:28 INFO DAGScheduler: Missing parents: List()
21/03/14 15:17:28 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135), which has no missing parents
21/03/14 15:17:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.5 KB, free 911.7 MB)
21/03/14 15:17:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 15:17:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:64077 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:17:28 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:17:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:17:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:17:28 INFO CodeGenerator: Code generated in 9.855445 ms
21/03/14 15:17:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 15:17:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 35 ms on localhost (executor driver) (1/1)
21/03/14 15:17:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:17:28 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.044 s
21/03/14 15:17:28 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.049661 s
21/03/14 15:17:28 INFO CodeGenerator: Code generated in 19.831299 ms
21/03/14 15:17:28 INFO CodeGenerator: Code generated in 16.029125 ms
21/03/14 15:17:28 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:17:28 INFO DAGScheduler: Registering RDD 16 (count at utils.scala:135)
21/03/14 15:17:28 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:17:28 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:17:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:17:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:17:28 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135), which has no missing parents
21/03/14 15:17:28 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.4 KB, free 911.7 MB)
21/03/14 15:17:28 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.7 MB)
21/03/14 15:17:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:64077 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:17:28 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:28 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:17:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:17:28 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:17:28 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:17:28 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 60 ms on localhost (executor driver) (1/1)
21/03/14 15:17:28 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:17:28 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.079 s
21/03/14 15:17:28 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:17:28 INFO DAGScheduler: running: Set()
21/03/14 15:17:28 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:17:28 INFO DAGScheduler: failed: Set()
21/03/14 15:17:28 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135), which has no missing parents
21/03/14 15:17:28 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 15:17:28 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 15:17:28 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:64077 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:17:28 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:28 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:17:28 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:17:28 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:17:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:17:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
21/03/14 15:17:28 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:17:28 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 53 ms on localhost (executor driver) (1/1)
21/03/14 15:17:28 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:17:28 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.065 s
21/03/14 15:17:28 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.178231 s
21/03/14 15:17:28 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:28 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:28 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:28 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:28 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:29 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:17:29 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:17:29 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:17:29 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:29 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:29 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:29 INFO CodeGenerator: Code generated in 48.502494 ms
21/03/14 15:17:29 INFO CodeGenerator: Code generated in 14.47556 ms
21/03/14 15:17:29 INFO CodeGenerator: Code generated in 13.983789 ms
21/03/14 15:17:29 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:17:29 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135)
21/03/14 15:17:29 INFO DAGScheduler: Got job 3 (count at utils.scala:135) with 1 output partitions
21/03/14 15:17:29 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/03/14 15:17:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 15:17:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 15:17:29 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/03/14 15:17:29 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.9 KB, free 911.6 MB)
21/03/14 15:17:29 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.2 KB, free 911.6 MB)
21/03/14 15:17:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:64077 (size: 4.2 KB, free: 912.2 MB)
21/03/14 15:17:29 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:29 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:17:29 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 15:17:29 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:17:29 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1499 bytes result sent to driver
21/03/14 15:17:29 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 11 ms on localhost (executor driver) (1/1)
21/03/14 15:17:29 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:17:29 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.020 s
21/03/14 15:17:29 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:17:29 INFO DAGScheduler: running: Set()
21/03/14 15:17:29 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 15:17:29 INFO DAGScheduler: failed: Set()
21/03/14 15:17:29 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/03/14 15:17:29 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 15:17:29 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 15:17:29 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:64077 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:17:29 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:29 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:17:29 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:17:29 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:17:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:17:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:17:29 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1782 bytes result sent to driver
21/03/14 15:17:29 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 6 ms on localhost (executor driver) (1/1)
21/03/14 15:17:29 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:17:29 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.014 s
21/03/14 15:17:29 INFO DAGScheduler: Job 3 finished: count at utils.scala:135, took 0.040607 s
21/03/14 15:17:30 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:30 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:17:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:17:30 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:30 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:30 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:30 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:17:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:17:30 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:30 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:30 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:30 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:17:30 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:17:30 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:17:30 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:17:30 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:30 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:17:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:17:30 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:17:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:17:30 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:17:30 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:17:30 INFO CodeGenerator: Code generated in 8.300049 ms
21/03/14 15:17:30 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 15:17:30 INFO DAGScheduler: Got job 4 (collect at utils.scala:61) with 1 output partitions
21/03/14 15:17:30 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:61)
21/03/14 15:17:30 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:17:30 INFO DAGScheduler: Missing parents: List()
21/03/14 15:17:30 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[31] at map at utils.scala:54), which has no missing parents
21/03/14 15:17:30 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 6.0 KB, free 911.6 MB)
21/03/14 15:17:30 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.4 KB, free 911.6 MB)
21/03/14 15:17:30 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:64077 (size: 3.4 KB, free: 912.2 MB)
21/03/14 15:17:30 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[31] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:30 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:17:30 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
21/03/14 15:17:30 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:17:30 INFO CodeGenerator: Code generated in 8.624115 ms
21/03/14 15:17:30 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 979 bytes result sent to driver
21/03/14 15:17:30 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 19 ms on localhost (executor driver) (1/1)
21/03/14 15:17:30 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:17:30 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:61) finished in 0.026 s
21/03/14 15:17:30 INFO DAGScheduler: Job 4 finished: collect at utils.scala:61, took 0.029534 s
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 95
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 121
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 178
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 119
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 191
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 147
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 92
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 198
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 148
21/03/14 15:17:30 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:64077 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 177
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 188
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 172
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 209
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 208
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 136
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 128
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 189
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 163
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 183
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 152
21/03/14 15:17:30 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:64077 in memory (size: 3.4 KB, free: 912.2 MB)
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 109
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 181
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 174
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 139
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 160
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 134
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 212
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 77
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 144
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 37
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 74
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 137
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 184
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 36
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 221
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 165
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 150
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 73
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 194
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 171
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 72
21/03/14 15:17:30 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:64077 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 118
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 210
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 102
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 197
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 203
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 214
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 220
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 108
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 146
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 78
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 192
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 138
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 66
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 64
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 114
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 202
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 153
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 93
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 170
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 115
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 122
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 111
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 186
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 159
21/03/14 15:17:30 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:64077 in memory (size: 4.2 KB, free: 912.2 MB)
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 71
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 158
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 149
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 207
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 215
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 117
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 129
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 96
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 85
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 82
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 180
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 104
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 132
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 89
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 76
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 69
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 175
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 205
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 70
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 15:17:30 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:64077 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 101
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 133
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 143
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 190
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 213
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 79
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 154
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 142
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 201
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 116
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 110
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 98
21/03/14 15:17:30 INFO ContextCleaner: Cleaned shuffle 1
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 130
21/03/14 15:17:30 INFO ContextCleaner: Cleaned shuffle 0
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 81
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 91
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 125
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 176
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 182
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 173
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 97
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 127
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 67
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 126
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 113
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 219
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 86
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 206
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 196
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 68
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 131
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 211
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 80
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 162
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 156
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 141
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 193
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 120
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 200
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 155
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 168
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 140
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 107
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 187
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 161
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 164
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 105
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 65
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 75
21/03/14 15:17:30 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:64077 in memory (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 217
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 204
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 90
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 185
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 151
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 218
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 83
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 124
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 123
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 167
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 112
21/03/14 15:17:30 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:64077 in memory (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 103
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 145
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 199
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 100
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 99
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 87
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 216
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 166
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 88
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 106
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 169
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 84
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 179
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 94
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 135
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 15:17:30 INFO ContextCleaner: Cleaned accumulator 157
21/03/14 15:17:30 INFO CodeGenerator: Code generated in 11.10213 ms
21/03/14 15:17:30 INFO CodeGenerator: Code generated in 8.856535 ms
21/03/14 15:17:30 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:17:30 INFO DAGScheduler: Got job 5 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:17:30 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:135)
21/03/14 15:17:30 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:17:30 INFO DAGScheduler: Missing parents: List()
21/03/14 15:17:30 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[35] at collect at utils.scala:135), which has no missing parents
21/03/14 15:17:30 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 6.3 KB, free 911.7 MB)
21/03/14 15:17:30 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 15:17:30 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:64077 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:17:30 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:30 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/14 15:17:30 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:17:30 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 15:17:30 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1286 bytes result sent to driver
21/03/14 15:17:30 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:17:30 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 15:17:30 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:135) finished in 0.016 s
21/03/14 15:17:30 INFO DAGScheduler: Job 5 finished: collect at utils.scala:135, took 0.018933 s
21/03/14 15:17:30 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:17:30 INFO DAGScheduler: Registering RDD 38 (count at utils.scala:135)
21/03/14 15:17:30 INFO DAGScheduler: Got job 6 (count at utils.scala:135) with 1 output partitions
21/03/14 15:17:30 INFO DAGScheduler: Final stage: ResultStage 9 (count at utils.scala:135)
21/03/14 15:17:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/03/14 15:17:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
21/03/14 15:17:30 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[38] at count at utils.scala:135), which has no missing parents
21/03/14 15:17:30 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.4 KB, free 911.7 MB)
21/03/14 15:17:30 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.7 MB)
21/03/14 15:17:30 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:64077 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:17:30 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[38] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:30 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 15:17:30 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:17:30 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/03/14 15:17:30 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1542 bytes result sent to driver
21/03/14 15:17:30 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 13 ms on localhost (executor driver) (1/1)
21/03/14 15:17:30 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 15:17:30 INFO DAGScheduler: ShuffleMapStage 8 (count at utils.scala:135) finished in 0.021 s
21/03/14 15:17:30 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:17:30 INFO DAGScheduler: running: Set()
21/03/14 15:17:30 INFO DAGScheduler: waiting: Set(ResultStage 9)
21/03/14 15:17:30 INFO DAGScheduler: failed: Set()
21/03/14 15:17:30 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[41] at count at utils.scala:135), which has no missing parents
21/03/14 15:17:30 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 15:17:30 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 15:17:30 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:64077 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:17:30 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[41] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:30 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 15:17:30 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:17:30 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/03/14 15:17:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:17:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:17:30 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1782 bytes result sent to driver
21/03/14 15:17:30 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:17:30 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 15:17:30 INFO DAGScheduler: ResultStage 9 (count at utils.scala:135) finished in 0.015 s
21/03/14 15:17:30 INFO DAGScheduler: Job 6 finished: count at utils.scala:135, took 0.041779 s
21/03/14 15:17:31 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:17:31 INFO DAGScheduler: Got job 7 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:17:31 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:135)
21/03/14 15:17:31 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:17:31 INFO DAGScheduler: Missing parents: List()
21/03/14 15:17:31 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[44] at collect at utils.scala:135), which has no missing parents
21/03/14 15:17:31 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 6.3 KB, free 911.7 MB)
21/03/14 15:17:31 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 15:17:31 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:64077 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:17:31 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[44] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:31 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/03/14 15:17:31 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:17:31 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/03/14 15:17:31 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1286 bytes result sent to driver
21/03/14 15:17:31 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
21/03/14 15:17:31 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/03/14 15:17:31 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:135) finished in 0.013 s
21/03/14 15:17:31 INFO DAGScheduler: Job 7 finished: collect at utils.scala:135, took 0.018670 s
21/03/14 15:17:31 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:17:31 INFO DAGScheduler: Registering RDD 47 (count at utils.scala:135)
21/03/14 15:17:31 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/03/14 15:17:31 INFO DAGScheduler: Final stage: ResultStage 12 (count at utils.scala:135)
21/03/14 15:17:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
21/03/14 15:17:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
21/03/14 15:17:31 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[47] at count at utils.scala:135), which has no missing parents
21/03/14 15:17:31 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.4 KB, free 911.6 MB)
21/03/14 15:17:31 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.6 MB)
21/03/14 15:17:31 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:64077 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:17:31 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[47] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:31 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/03/14 15:17:31 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:17:31 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/03/14 15:17:31 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1499 bytes result sent to driver
21/03/14 15:17:31 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 9 ms on localhost (executor driver) (1/1)
21/03/14 15:17:31 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/03/14 15:17:31 INFO DAGScheduler: ShuffleMapStage 11 (count at utils.scala:135) finished in 0.030 s
21/03/14 15:17:31 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:17:31 INFO DAGScheduler: running: Set()
21/03/14 15:17:31 INFO DAGScheduler: waiting: Set(ResultStage 12)
21/03/14 15:17:31 INFO DAGScheduler: failed: Set()
21/03/14 15:17:31 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[50] at count at utils.scala:135), which has no missing parents
21/03/14 15:17:31 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 15:17:31 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 15:17:31 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:64077 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:17:31 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[50] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:31 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/03/14 15:17:31 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:17:31 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/03/14 15:17:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:17:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:17:31 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1782 bytes result sent to driver
21/03/14 15:17:31 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 6 ms on localhost (executor driver) (1/1)
21/03/14 15:17:31 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/03/14 15:17:31 INFO DAGScheduler: ResultStage 12 (count at utils.scala:135) finished in 0.013 s
21/03/14 15:17:31 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.047773 s
21/03/14 15:17:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:31 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:17:31 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:17:31 INFO FileSourceStrategy: Output Data Schema: struct<>
21/03/14 15:17:31 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:17:31 INFO CodeGenerator: Code generated in 15.094694 ms
21/03/14 15:17:31 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 284.5 KB, free 911.4 MB)
21/03/14 15:17:31 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.3 MB)
21/03/14 15:17:31 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:64077 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:17:31 INFO SparkContext: Created broadcast 15 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:17:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:17:31 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:17:31 INFO DAGScheduler: Registering RDD 53 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:17:31 INFO DAGScheduler: Got job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:17:31 INFO DAGScheduler: Final stage: ResultStage 14 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:17:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/03/14 15:17:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/03/14 15:17:31 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:17:31 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 14.2 KB, free 911.3 MB)
21/03/14 15:17:31 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.3 MB)
21/03/14 15:17:31 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:64077 (size: 8.0 KB, free: 912.2 MB)
21/03/14 15:17:31 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:31 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/03/14 15:17:31 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:17:31 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/03/14 15:17:31 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpWTCUuF/file15f5f6b5cf10b, range: 0-1303, partition values: [empty row]
21/03/14 15:17:31 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1585 bytes result sent to driver
21/03/14 15:17:31 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 39 ms on localhost (executor driver) (1/1)
21/03/14 15:17:31 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/03/14 15:17:31 INFO DAGScheduler: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.058 s
21/03/14 15:17:31 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:17:31 INFO DAGScheduler: running: Set()
21/03/14 15:17:31 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/03/14 15:17:31 INFO DAGScheduler: failed: Set()
21/03/14 15:17:31 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:17:31 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 15:17:31 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 15:17:31 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:64077 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:17:31 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:31 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/03/14 15:17:31 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:17:31 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/03/14 15:17:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:17:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:17:31 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1782 bytes result sent to driver
21/03/14 15:17:31 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:17:31 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/03/14 15:17:31 INFO DAGScheduler: ResultStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0.013 s
21/03/14 15:17:31 INFO DAGScheduler: Job 9 finished: count at NativeMethodAccessorImpl.java:0, took 0.076176 s
21/03/14 15:17:31 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:17:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:17:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:31 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:31 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:32 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:32 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:17:32 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:17:32 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:17:32 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:17:32 INFO FileSourceStrategy: Output Data Schema: struct<>
21/03/14 15:17:32 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:17:32 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 284.5 KB, free 911.0 MB)
21/03/14 15:17:32 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.0 MB)
21/03/14 15:17:32 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:64077 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:17:32 INFO SparkContext: Created broadcast 18 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:17:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:17:32 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:17:32 INFO DAGScheduler: Registering RDD 59 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:17:32 INFO DAGScheduler: Got job 10 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:17:32 INFO DAGScheduler: Final stage: ResultStage 16 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:17:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
21/03/14 15:17:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
21/03/14 15:17:32 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:17:32 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 14.2 KB, free 911.0 MB)
21/03/14 15:17:32 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
21/03/14 15:17:32 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:64077 (size: 8.0 KB, free: 912.2 MB)
21/03/14 15:17:32 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:32 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/03/14 15:17:32 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:17:32 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/03/14 15:17:32 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpWTCUuF/file15f5f6b5cf10b, range: 0-2539, partition values: [empty row]
21/03/14 15:17:32 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1628 bytes result sent to driver
21/03/14 15:17:32 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 16 ms on localhost (executor driver) (1/1)
21/03/14 15:17:32 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/03/14 15:17:32 INFO DAGScheduler: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.031 s
21/03/14 15:17:32 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:17:32 INFO DAGScheduler: running: Set()
21/03/14 15:17:32 INFO DAGScheduler: waiting: Set(ResultStage 16)
21/03/14 15:17:32 INFO DAGScheduler: failed: Set()
21/03/14 15:17:32 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:17:32 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.1 KB, free 911.0 MB)
21/03/14 15:17:32 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.0 MB)
21/03/14 15:17:32 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:64077 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:17:32 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1161
21/03/14 15:17:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:17:32 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/03/14 15:17:32 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:17:32 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/03/14 15:17:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:17:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:17:32 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1782 bytes result sent to driver
21/03/14 15:17:32 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 6 ms on localhost (executor driver) (1/1)
21/03/14 15:17:32 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/03/14 15:17:32 INFO DAGScheduler: ResultStage 16 (count at NativeMethodAccessorImpl.java:0) finished in 0.014 s
21/03/14 15:17:32 INFO DAGScheduler: Job 10 finished: count at NativeMethodAccessorImpl.java:0, took 0.049740 s
21/03/14 15:17:32 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:17:32 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:17:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:17:32 INFO MemoryStore: MemoryStore cleared
21/03/14 15:17:32 INFO BlockManager: BlockManager stopped
21/03/14 15:17:32 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:17:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:17:32 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:17:32 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:17:32 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-2f4b141c-4b96-4da2-bb29-ccc8814ccbf9
21/03/14 15:17:32 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-0a9d8f63-01b1-48a6-80d5-513490064ea1
21/03/14 15:18:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:18:12 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:18:12 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:18:12 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:18:12 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:18:12 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:18:12 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:18:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:18:12 INFO Utils: Successfully started service 'sparkDriver' on port 64193.
21/03/14 15:18:12 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:18:12 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:18:12 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:18:12 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:18:12 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-cca9e091-e3d1-4f28-b905-80d153c01f53
21/03/14 15:18:12 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:18:12 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:18:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:18:12 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:18:12 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:64193/jars/sparklyr-2.4-2.11.jar with timestamp 1615731492770
21/03/14 15:18:12 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:18:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64194.
21/03/14 15:18:12 INFO NettyBlockTransferService: Server created on localhost:64194
21/03/14 15:18:12 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:18:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 64194, None)
21/03/14 15:18:13 INFO BlockManagerMasterEndpoint: Registering block manager localhost:64194 with 912.3 MB RAM, BlockManagerId(driver, localhost, 64194, None)
21/03/14 15:18:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 64194, None)
21/03/14 15:18:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 64194, None)
21/03/14 15:18:13 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:18:13 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:18:13 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:18:14 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:18:18 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:18:19 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:18:19 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:18:19 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:18:19 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:18:20 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:18:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:18:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:18:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:18:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:18:22 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:18:22 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:18:22 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:18:22 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:18:22 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:18:22 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:18:23 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:18:23 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:18:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:18:23 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:18:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:18:23 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:18:23 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/e9a1592e-79ae-4ce2-b6a8-f5d77cf205b4_resources
21/03/14 15:18:23 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/e9a1592e-79ae-4ce2-b6a8-f5d77cf205b4
21/03/14 15:18:23 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/e9a1592e-79ae-4ce2-b6a8-f5d77cf205b4
21/03/14 15:18:23 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/e9a1592e-79ae-4ce2-b6a8-f5d77cf205b4/_tmp_space.db
21/03/14 15:18:23 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:18:23 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:18:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:18:23 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:18:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:18:23 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:18:23 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:18:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:18:23 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:18:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:18:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:18:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:18:24 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 15:18:24 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/03/14 15:18:24 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/03/14 15:18:24 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:18:24 INFO DAGScheduler: Missing parents: List()
21/03/14 15:18:24 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/03/14 15:18:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/03/14 15:18:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/03/14 15:18:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:64194 (size: 3.4 KB, free: 912.3 MB)
21/03/14 15:18:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 15:18:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 15:18:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:18:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/03/14 15:18:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:18:24 INFO Executor: Fetching spark://localhost:64193/jars/sparklyr-2.4-2.11.jar with timestamp 1615731492770
21/03/14 15:18:24 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:64193 after 27 ms (0 ms spent in bootstraps)
21/03/14 15:18:24 INFO Utils: Fetching spark://localhost:64193/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-6a40ac7a-a0e1-462e-ab1e-4bdc493bcc6f/userFiles-f9f39537-e1a9-4f47-bf0f-c5d6510856fc/fetchFileTemp3580107065849553440.tmp
21/03/14 15:18:24 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-6a40ac7a-a0e1-462e-ab1e-4bdc493bcc6f/userFiles-f9f39537-e1a9-4f47-bf0f-c5d6510856fc/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:18:25 INFO CodeGenerator: Code generated in 268.284397 ms
21/03/14 15:18:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1056 bytes result sent to driver
21/03/14 15:18:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 753 ms on localhost (executor driver) (1/1)
21/03/14 15:18:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:18:25 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 1.108 s
21/03/14 15:18:25 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 1.191202 s
21/03/14 15:18:25 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:64194 in memory (size: 3.4 KB, free: 912.3 MB)
21/03/14 15:18:26 INFO CodeGenerator: Code generated in 19.447872 ms
21/03/14 15:18:26 INFO CodeGenerator: Code generated in 29.856479 ms
21/03/14 15:18:26 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:18:26 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:18:26 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:18:26 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:18:26 INFO DAGScheduler: Missing parents: List()
21/03/14 15:18:26 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/03/14 15:18:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 15:18:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 15:18:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:64194 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:18:26 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:18:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:18:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:18:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:18:26 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:18:26 INFO CodeGenerator: Code generated in 11.239212 ms
21/03/14 15:18:26 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1286 bytes result sent to driver
21/03/14 15:18:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on localhost (executor driver) (1/1)
21/03/14 15:18:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:18:26 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.045 s
21/03/14 15:18:26 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.048867 s
21/03/14 15:18:26 INFO CodeGenerator: Code generated in 20.812836 ms
21/03/14 15:18:26 INFO CodeGenerator: Code generated in 14.994837 ms
21/03/14 15:18:26 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:18:26 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/03/14 15:18:26 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:18:26 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:18:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:18:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:18:26 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/03/14 15:18:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/03/14 15:18:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/03/14 15:18:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:64194 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:18:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 15:18:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:18:26 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:18:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:18:26 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:18:26 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:18:26 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 62 ms on localhost (executor driver) (1/1)
21/03/14 15:18:26 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:18:26 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.079 s
21/03/14 15:18:26 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:18:26 INFO DAGScheduler: running: Set()
21/03/14 15:18:26 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:18:26 INFO DAGScheduler: failed: Set()
21/03/14 15:18:26 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/03/14 15:18:26 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:18:26 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:18:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:64194 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:18:26 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:18:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:18:26 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:18:26 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:18:26 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:18:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:18:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
21/03/14 15:18:26 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:18:26 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 63 ms on localhost (executor driver) (1/1)
21/03/14 15:18:26 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:18:26 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.076 s
21/03/14 15:18:26 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.191859 s
21/03/14 15:18:27 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:18:27 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:18:27 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/03/14 15:18:27 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:18:27 INFO DAGScheduler: Missing parents: List()
21/03/14 15:18:27 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135), which has no missing parents
21/03/14 15:18:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 15:18:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 15:18:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:64194 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:18:27 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:18:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:18:27 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:18:27 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:18:27 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:18:27 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1329 bytes result sent to driver
21/03/14 15:18:27 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:18:27 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:18:27 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.016 s
21/03/14 15:18:27 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.019308 s
21/03/14 15:18:27 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:18:27 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:135)
21/03/14 15:18:27 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/14 15:18:27 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/03/14 15:18:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/03/14 15:18:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/03/14 15:18:27 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/03/14 15:18:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/03/14 15:18:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/03/14 15:18:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:64194 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:18:27 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:18:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:18:27 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:18:27 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:18:27 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:18:27 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/03/14 15:18:27 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 12 ms on localhost (executor driver) (1/1)
21/03/14 15:18:27 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:18:27 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.020 s
21/03/14 15:18:27 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:18:27 INFO DAGScheduler: running: Set()
21/03/14 15:18:27 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/03/14 15:18:27 INFO DAGScheduler: failed: Set()
21/03/14 15:18:27 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/03/14 15:18:27 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 15:18:27 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 15:18:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:64194 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:18:27 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 15:18:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:18:27 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:18:27 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:18:27 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:18:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:18:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:18:27 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/03/14 15:18:27 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:18:27 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:18:27 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.016 s
21/03/14 15:18:27 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.042039 s
21/03/14 15:18:27 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:18:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:18:27 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:18:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:18:27 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:18:27 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:18:27 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:18:27 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:18:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:18:27 INFO MemoryStore: MemoryStore cleared
21/03/14 15:18:27 INFO BlockManager: BlockManager stopped
21/03/14 15:18:27 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:18:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:18:27 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:18:27 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:18:27 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-94a31bd2-c7fc-4003-b005-64641b8fa4c0
21/03/14 15:18:27 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-6a40ac7a-a0e1-462e-ab1e-4bdc493bcc6f
21/03/14 15:18:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:18:51 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:18:51 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:18:51 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:18:51 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:18:51 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:18:51 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:18:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:18:51 INFO Utils: Successfully started service 'sparkDriver' on port 64298.
21/03/14 15:18:51 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:18:51 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:18:51 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:18:51 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:18:51 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-db3a5ade-3bbe-43d5-a189-a9468a912ca5
21/03/14 15:18:51 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:18:51 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:18:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:18:51 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:18:51 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:64298/jars/sparklyr-2.4-2.11.jar with timestamp 1615731531870
21/03/14 15:18:51 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:18:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64299.
21/03/14 15:18:52 INFO NettyBlockTransferService: Server created on localhost:64299
21/03/14 15:18:52 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:18:52 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 64299, None)
21/03/14 15:18:52 INFO BlockManagerMasterEndpoint: Registering block manager localhost:64299 with 912.3 MB RAM, BlockManagerId(driver, localhost, 64299, None)
21/03/14 15:18:52 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 64299, None)
21/03/14 15:18:52 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 64299, None)
21/03/14 15:18:52 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:18:52 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:18:52 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:18:53 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:18:55 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:18:56 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:18:56 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:18:56 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:18:56 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:18:58 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:18:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:18:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:00 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:00 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:00 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:19:00 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:19:01 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:19:01 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:19:01 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:19:01 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:19:01 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:19:01 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:19:01 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:19:01 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:19:01 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:19:01 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:01 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/92467d2a-8fc3-4c86-b717-8945d13e96de_resources
21/03/14 15:19:01 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/92467d2a-8fc3-4c86-b717-8945d13e96de
21/03/14 15:19:01 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/92467d2a-8fc3-4c86-b717-8945d13e96de
21/03/14 15:19:01 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/92467d2a-8fc3-4c86-b717-8945d13e96de/_tmp_space.db
21/03/14 15:19:01 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:19:01 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:01 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:01 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:19:01 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:19:01 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:19:01 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:01 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:01 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:01 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:19:01 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:19:02 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 15:19:02 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/03/14 15:19:02 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/03/14 15:19:02 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:19:02 INFO DAGScheduler: Missing parents: List()
21/03/14 15:19:02 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/03/14 15:19:02 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/03/14 15:19:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/03/14 15:19:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:64299 (size: 3.4 KB, free: 912.3 MB)
21/03/14 15:19:03 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 15:19:03 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:19:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/03/14 15:19:03 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:19:03 INFO Executor: Fetching spark://localhost:64298/jars/sparklyr-2.4-2.11.jar with timestamp 1615731531870
21/03/14 15:19:03 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:64298 after 29 ms (0 ms spent in bootstraps)
21/03/14 15:19:03 INFO Utils: Fetching spark://localhost:64298/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-8a9f7244-7995-439e-85d1-5748a6f9d9bd/userFiles-e1d5d1f2-d343-4724-877e-59bc2c87a988/fetchFileTemp2459388119063177494.tmp
21/03/14 15:19:03 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-8a9f7244-7995-439e-85d1-5748a6f9d9bd/userFiles-e1d5d1f2-d343-4724-877e-59bc2c87a988/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:19:03 INFO CodeGenerator: Code generated in 261.330905 ms
21/03/14 15:19:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
21/03/14 15:19:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 765 ms on localhost (executor driver) (1/1)
21/03/14 15:19:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:19:03 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 1.112 s
21/03/14 15:19:03 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 1.209016 s
21/03/14 15:19:04 INFO ContextCleaner: Cleaned accumulator 0
21/03/14 15:19:04 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:64299 in memory (size: 3.4 KB, free: 912.3 MB)
21/03/14 15:19:04 INFO CodeGenerator: Code generated in 21.722872 ms
21/03/14 15:19:04 INFO CodeGenerator: Code generated in 21.786083 ms
21/03/14 15:19:04 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:19:04 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:19:04 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:19:04 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:19:04 INFO DAGScheduler: Missing parents: List()
21/03/14 15:19:04 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/03/14 15:19:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 15:19:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 15:19:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:64299 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:19:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:19:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:19:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:19:04 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:19:04 INFO CodeGenerator: Code generated in 9.248567 ms
21/03/14 15:19:04 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 15:19:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on localhost (executor driver) (1/1)
21/03/14 15:19:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:19:04 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.044 s
21/03/14 15:19:04 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.048169 s
21/03/14 15:19:05 INFO CodeGenerator: Code generated in 16.256116 ms
21/03/14 15:19:05 INFO CodeGenerator: Code generated in 11.099911 ms
21/03/14 15:19:05 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:19:05 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/03/14 15:19:05 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:19:05 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:19:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:19:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:19:05 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/03/14 15:19:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/03/14 15:19:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/03/14 15:19:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:64299 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:19:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:19:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:19:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:19:05 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:19:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:19:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 60 ms on localhost (executor driver) (1/1)
21/03/14 15:19:05 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:19:05 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.076 s
21/03/14 15:19:05 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:19:05 INFO DAGScheduler: running: Set()
21/03/14 15:19:05 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:19:05 INFO DAGScheduler: failed: Set()
21/03/14 15:19:05 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/03/14 15:19:05 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:19:05 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:19:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:64299 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:19:05 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:19:05 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:19:05 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:19:05 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:19:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:19:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
21/03/14 15:19:05 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:19:05 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 61 ms on localhost (executor driver) (1/1)
21/03/14 15:19:05 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:19:05 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.074 s
21/03/14 15:19:05 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.180572 s
21/03/14 15:19:05 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:19:05 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:19:05 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/03/14 15:19:05 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:19:05 INFO DAGScheduler: Missing parents: List()
21/03/14 15:19:05 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135), which has no missing parents
21/03/14 15:19:05 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 15:19:05 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 15:19:05 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:64299 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:19:05 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:19:05 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:19:05 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:19:05 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:19:05 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/03/14 15:19:05 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:19:05 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:19:05 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.017 s
21/03/14 15:19:05 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.020748 s
21/03/14 15:19:05 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:19:05 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:135)
21/03/14 15:19:05 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/14 15:19:05 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/03/14 15:19:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/03/14 15:19:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/03/14 15:19:05 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/03/14 15:19:05 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/03/14 15:19:05 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/03/14 15:19:05 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:64299 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:19:05 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:19:05 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:19:05 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:19:05 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:19:05 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/03/14 15:19:05 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 12 ms on localhost (executor driver) (1/1)
21/03/14 15:19:05 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:19:05 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.021 s
21/03/14 15:19:05 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:19:05 INFO DAGScheduler: running: Set()
21/03/14 15:19:05 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/03/14 15:19:05 INFO DAGScheduler: failed: Set()
21/03/14 15:19:05 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/03/14 15:19:05 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 15:19:05 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 15:19:05 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:64299 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:19:05 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:19:05 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:19:05 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:19:05 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:19:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:19:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:19:05 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/03/14 15:19:05 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:19:05 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:19:05 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.015 s
21/03/14 15:19:05 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.043078 s
21/03/14 15:19:06 INFO CodeGenerator: Code generated in 36.596687 ms
21/03/14 15:19:06 INFO CodeGenerator: Code generated in 16.456701 ms
21/03/14 15:19:06 INFO CodeGenerator: Code generated in 13.52143 ms
21/03/14 15:19:06 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:19:06 INFO DAGScheduler: Registering RDD 28 (count at utils.scala:135)
21/03/14 15:19:06 INFO DAGScheduler: Got job 5 (count at utils.scala:135) with 1 output partitions
21/03/14 15:19:06 INFO DAGScheduler: Final stage: ResultStage 8 (count at utils.scala:135)
21/03/14 15:19:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
21/03/14 15:19:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
21/03/14 15:19:06 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135), which has no missing parents
21/03/14 15:19:06 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 15:19:06 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 15:19:06 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:64299 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:19:06 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:06 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/03/14 15:19:06 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
21/03/14 15:19:06 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8034 bytes)
21/03/14 15:19:06 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 8, localhost, executor driver, partition 1, PROCESS_LOCAL, 8051 bytes)
21/03/14 15:19:06 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 9, localhost, executor driver, partition 2, PROCESS_LOCAL, 8051 bytes)
21/03/14 15:19:06 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 10, localhost, executor driver, partition 3, PROCESS_LOCAL, 8051 bytes)
21/03/14 15:19:06 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 15:19:06 INFO Executor: Running task 1.0 in stage 7.0 (TID 8)
21/03/14 15:19:06 INFO Executor: Running task 2.0 in stage 7.0 (TID 9)
21/03/14 15:19:06 INFO Executor: Running task 3.0 in stage 7.0 (TID 10)
21/03/14 15:19:06 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1542 bytes result sent to driver
21/03/14 15:19:06 INFO Executor: Finished task 1.0 in stage 7.0 (TID 8). 1499 bytes result sent to driver
21/03/14 15:19:06 INFO Executor: Finished task 3.0 in stage 7.0 (TID 10). 1499 bytes result sent to driver
21/03/14 15:19:06 INFO Executor: Finished task 2.0 in stage 7.0 (TID 9). 1499 bytes result sent to driver
21/03/14 15:19:06 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 21 ms on localhost (executor driver) (1/4)
21/03/14 15:19:06 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 10) in 20 ms on localhost (executor driver) (2/4)
21/03/14 15:19:06 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 9) in 20 ms on localhost (executor driver) (3/4)
21/03/14 15:19:06 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 8) in 22 ms on localhost (executor driver) (4/4)
21/03/14 15:19:06 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 15:19:06 INFO DAGScheduler: ShuffleMapStage 7 (count at utils.scala:135) finished in 0.033 s
21/03/14 15:19:06 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:19:06 INFO DAGScheduler: running: Set()
21/03/14 15:19:06 INFO DAGScheduler: waiting: Set(ResultStage 8)
21/03/14 15:19:06 INFO DAGScheduler: failed: Set()
21/03/14 15:19:06 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135), which has no missing parents
21/03/14 15:19:06 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 15:19:06 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 15:19:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:64299 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:19:06 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[31] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:19:06 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 15:19:06 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:19:06 INFO Executor: Running task 0.0 in stage 8.0 (TID 11)
21/03/14 15:19:06 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
21/03/14 15:19:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:19:06 INFO Executor: Finished task 0.0 in stage 8.0 (TID 11). 1782 bytes result sent to driver
21/03/14 15:19:06 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 11) in 10 ms on localhost (executor driver) (1/1)
21/03/14 15:19:06 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 15:19:06 INFO DAGScheduler: ResultStage 8 (count at utils.scala:135) finished in 0.020 s
21/03/14 15:19:06 INFO DAGScheduler: Job 5 finished: count at utils.scala:135, took 0.059149 s
21/03/14 15:19:06 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:19:06 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:19:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:19:06 INFO MemoryStore: MemoryStore cleared
21/03/14 15:19:06 INFO BlockManager: BlockManager stopped
21/03/14 15:19:06 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:19:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:19:06 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:19:06 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:19:06 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-8a9f7244-7995-439e-85d1-5748a6f9d9bd
21/03/14 15:19:06 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-25f19acb-852e-467f-b857-597d3cc78262
21/03/14 15:19:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:19:10 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:19:10 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:19:10 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:19:10 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:19:10 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:19:10 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:19:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:19:10 INFO Utils: Successfully started service 'sparkDriver' on port 64320.
21/03/14 15:19:10 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:19:10 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:19:10 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:19:10 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:19:10 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-5a898098-6d4d-4017-990e-af75f0880e1b
21/03/14 15:19:10 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:19:10 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:19:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:19:11 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:19:11 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:64320/jars/sparklyr-2.4-2.11.jar with timestamp 1615731551056
21/03/14 15:19:11 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:19:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64321.
21/03/14 15:19:11 INFO NettyBlockTransferService: Server created on localhost:64321
21/03/14 15:19:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:19:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 64321, None)
21/03/14 15:19:11 INFO BlockManagerMasterEndpoint: Registering block manager localhost:64321 with 912.3 MB RAM, BlockManagerId(driver, localhost, 64321, None)
21/03/14 15:19:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 64321, None)
21/03/14 15:19:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 64321, None)
21/03/14 15:19:11 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:19:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:19:11 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:19:12 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:19:14 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:19:15 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:19:15 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:19:15 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:19:15 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:19:17 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:19:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:19 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:19 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:19 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:19:19 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:19:19 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:19:20 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:19:20 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:19:20 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:19:20 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:19:20 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:19:20 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:19:20 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:19:20 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:19:20 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:20 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/06133334-09e6-433b-b376-164fb9497d2a_resources
21/03/14 15:19:20 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/06133334-09e6-433b-b376-164fb9497d2a
21/03/14 15:19:20 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/06133334-09e6-433b-b376-164fb9497d2a
21/03/14 15:19:20 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/06133334-09e6-433b-b376-164fb9497d2a/_tmp_space.db
21/03/14 15:19:20 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:19:20 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:20 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:20 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:20 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:20 INFO HiveMetaStore: 0: get_database: fake_database
21/03/14 15:19:20 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: fake_database	
21/03/14 15:19:20 WARN ObjectStore: Failed to get database fake_database, returning NoSuchObjectException
21/03/14 15:19:20 INFO HiveMetaStore: 0: get_databases: *
21/03/14 15:19:20 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_databases: *	
21/03/14 15:19:20 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:20 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:20 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:20 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:21 INFO CodeGenerator: Code generated in 271.927136 ms
21/03/14 15:19:22 INFO CodeGenerator: Code generated in 17.190174 ms
21/03/14 15:19:22 INFO CodeGenerator: Code generated in 13.241369 ms
21/03/14 15:19:22 INFO CodeGenerator: Code generated in 23.666536 ms
21/03/14 15:19:22 INFO CodeGenerator: Code generated in 29.504504 ms
21/03/14 15:19:22 INFO CodeGenerator: Code generated in 12.586453 ms
21/03/14 15:19:22 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:19:22 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:135)
21/03/14 15:19:22 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/03/14 15:19:22 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/03/14 15:19:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/03/14 15:19:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/03/14 15:19:22 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135), which has no missing parents
21/03/14 15:19:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 15:19:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 15:19:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:64321 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:19:23 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:19:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:19:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 15:19:23 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:19:23 INFO Executor: Fetching spark://localhost:64320/jars/sparklyr-2.4-2.11.jar with timestamp 1615731551056
21/03/14 15:19:23 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:64320 after 29 ms (0 ms spent in bootstraps)
21/03/14 15:19:23 INFO Utils: Fetching spark://localhost:64320/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-e81346eb-fc96-4c23-ba03-753324bd4536/userFiles-685a2f4f-edc4-4936-9470-98e8b80a16e6/fetchFileTemp4968724270051918262.tmp
21/03/14 15:19:23 INFO ContextCleaner: Cleaned accumulator 1
21/03/14 15:19:23 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-e81346eb-fc96-4c23-ba03-753324bd4536/userFiles-685a2f4f-edc4-4936-9470-98e8b80a16e6/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:19:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1585 bytes result sent to driver
21/03/14 15:19:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 519 ms on localhost (executor driver) (1/1)
21/03/14 15:19:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:19:23 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:135) finished in 0.756 s
21/03/14 15:19:23 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:19:23 INFO DAGScheduler: running: Set()
21/03/14 15:19:23 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/03/14 15:19:23 INFO DAGScheduler: failed: Set()
21/03/14 15:19:23 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135), which has no missing parents
21/03/14 15:19:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:19:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:19:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:64321 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:19:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:19:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:19:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:19:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:19:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:19:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
21/03/14 15:19:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1825 bytes result sent to driver
21/03/14 15:19:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 71 ms on localhost (executor driver) (1/1)
21/03/14 15:19:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:19:23 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.087 s
21/03/14 15:19:23 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.932775 s
21/03/14 15:19:24 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:19:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:19:24 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:19:24 INFO HiveMetaStore: 0: create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})
21/03/14 15:19:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_database: Database(name:catalog_test_database_db, description:, locationUri:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db, parameters:{})	
21/03/14 15:19:24 WARN ObjectStore: Failed to get database catalog_test_database_db, returning NoSuchObjectException
21/03/14 15:19:24 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 15:19:24 INFO CodeGenerator: Code generated in 16.969564 ms
21/03/14 15:19:24 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:19:24 INFO DAGScheduler: Registering RDD 10 (count at utils.scala:135)
21/03/14 15:19:24 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/03/14 15:19:24 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:19:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:19:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:19:24 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[10] at count at utils.scala:135), which has no missing parents
21/03/14 15:19:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 15:19:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 15:19:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:64321 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:19:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[10] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:19:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:19:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 15:19:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:19:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1499 bytes result sent to driver
21/03/14 15:19:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 11 ms on localhost (executor driver) (1/1)
21/03/14 15:19:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:19:24 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.021 s
21/03/14 15:19:24 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:19:24 INFO DAGScheduler: running: Set()
21/03/14 15:19:24 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:19:24 INFO DAGScheduler: failed: Set()
21/03/14 15:19:24 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[13] at count at utils.scala:135), which has no missing parents
21/03/14 15:19:24 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:19:24 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:19:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:64321 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:19:24 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:19:24 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:19:24 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:19:24 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:19:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:19:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:19:24 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1775 bytes result sent to driver
21/03/14 15:19:24 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 11 ms on localhost (executor driver) (1/1)
21/03/14 15:19:24 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:19:24 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.021 s
21/03/14 15:19:24 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.049310 s
21/03/14 15:19:24 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 15:19:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 15:19:24 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 15:19:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 15:19:24 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 15:19:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 15:19:24 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:24 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:24 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:24 INFO HiveMetaStore: 0: get_database: catalog_test_database_db
21/03/14 15:19:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: catalog_test_database_db	
21/03/14 15:19:24 INFO HiveMetaStore: 0: drop_database: catalog_test_database_db
21/03/14 15:19:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=drop_database: catalog_test_database_db	
21/03/14 15:19:24 INFO HiveMetaStore: 0: get_all_tables: db=catalog_test_database_db
21/03/14 15:19:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_tables: db=catalog_test_database_db	
21/03/14 15:19:24 INFO HiveMetaStore: 0: get_functions: db=catalog_test_database_db pat=*
21/03/14 15:19:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=catalog_test_database_db pat=*	
21/03/14 15:19:24 INFO ObjectStore: Dropping database catalog_test_database_db along with all tables
21/03/14 15:19:24 INFO hivemetastoressimpl: deleting  file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 15:19:24 INFO deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
21/03/14 15:19:24 INFO TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
21/03/14 15:19:24 INFO hivemetastoressimpl: Deleted the diretory file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/catalog_test_database_db.db
21/03/14 15:19:24 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:19:24 INFO DAGScheduler: Registering RDD 17 (count at utils.scala:135)
21/03/14 15:19:24 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:19:24 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/03/14 15:19:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 15:19:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 15:19:24 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at count at utils.scala:135), which has no missing parents
21/03/14 15:19:24 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.9 KB, free 912.2 MB)
21/03/14 15:19:24 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.2 MB)
21/03/14 15:19:24 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:64321 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:19:24 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:19:24 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:19:24 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7882 bytes)
21/03/14 15:19:24 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:19:25 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1499 bytes result sent to driver
21/03/14 15:19:25 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 10 ms on localhost (executor driver) (1/1)
21/03/14 15:19:25 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:19:25 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.019 s
21/03/14 15:19:25 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:19:25 INFO DAGScheduler: running: Set()
21/03/14 15:19:25 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 15:19:25 INFO DAGScheduler: failed: Set()
21/03/14 15:19:25 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[20] at count at utils.scala:135), which has no missing parents
21/03/14 15:19:25 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 15:19:25 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 15:19:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:64321 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:19:25 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:19:25 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:19:25 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:19:25 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:19:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:19:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:19:25 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1818 bytes result sent to driver
21/03/14 15:19:25 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:19:25 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:19:25 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.017 s
21/03/14 15:19:25 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.043389 s
21/03/14 15:19:25 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:19:25 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:19:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:19:25 INFO MemoryStore: MemoryStore cleared
21/03/14 15:19:25 INFO BlockManager: BlockManager stopped
21/03/14 15:19:25 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:19:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:19:25 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:19:25 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:19:25 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-75773b6e-f792-4056-b1fb-dfe1d53e80f7
21/03/14 15:19:25 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-e81346eb-fc96-4c23-ba03-753324bd4536
21/03/14 15:19:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:19:28 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:19:28 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:19:28 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:19:28 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:19:28 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:19:28 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:19:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:19:29 INFO Utils: Successfully started service 'sparkDriver' on port 64342.
21/03/14 15:19:29 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:19:29 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:19:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:19:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:19:29 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-a358027b-6e9f-4a18-b19f-6863e0347dc7
21/03/14 15:19:29 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:19:29 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:19:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:19:29 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:19:29 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:64342/jars/sparklyr-2.4-2.11.jar with timestamp 1615731569578
21/03/14 15:19:29 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:19:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64343.
21/03/14 15:19:29 INFO NettyBlockTransferService: Server created on localhost:64343
21/03/14 15:19:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:19:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 64343, None)
21/03/14 15:19:29 INFO BlockManagerMasterEndpoint: Registering block manager localhost:64343 with 912.3 MB RAM, BlockManagerId(driver, localhost, 64343, None)
21/03/14 15:19:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 64343, None)
21/03/14 15:19:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 64343, None)
21/03/14 15:19:30 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:19:30 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:19:30 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:19:30 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:19:32 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:19:33 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:19:33 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:19:33 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:19:33 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:19:35 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:19:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:37 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:19:37 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:19:37 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:19:37 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:19:37 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:19:37 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:19:37 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:19:37 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:19:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:19:37 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:19:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:19:37 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:37 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/fa6c1d1b-9dfe-4e25-8f5f-bf8ea15cc3d7_resources
21/03/14 15:19:37 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/fa6c1d1b-9dfe-4e25-8f5f-bf8ea15cc3d7
21/03/14 15:19:37 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/fa6c1d1b-9dfe-4e25-8f5f-bf8ea15cc3d7
21/03/14 15:19:37 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/fa6c1d1b-9dfe-4e25-8f5f-bf8ea15cc3d7/_tmp_space.db
21/03/14 15:19:37 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:19:37 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:37 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:37 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:37 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:37 INFO HiveMetaStore: 0: get_function: default.catalog_fake_function
21/03/14 15:19:37 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_function: default.catalog_fake_function	
21/03/14 15:19:38 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:38 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:38 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:38 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:19:38 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:19:39 INFO CodeGenerator: Code generated in 373.208439 ms
21/03/14 15:19:40 INFO CodeGenerator: Code generated in 26.130333 ms
21/03/14 15:19:40 INFO CodeGenerator: Code generated in 25.448561 ms
21/03/14 15:19:40 INFO CodeGenerator: Code generated in 22.991327 ms
21/03/14 15:19:40 INFO CodeGenerator: Code generated in 11.963468 ms
21/03/14 15:19:40 INFO CodeGenerator: Code generated in 9.538203 ms
21/03/14 15:19:41 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:19:41 INFO DAGScheduler: Registering RDD 3 (count at utils.scala:135)
21/03/14 15:19:41 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/03/14 15:19:41 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/03/14 15:19:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/03/14 15:19:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/03/14 15:19:41 INFO ContextCleaner: Cleaned accumulator 1
21/03/14 15:19:41 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135), which has no missing parents
21/03/14 15:19:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 912.3 MB)
21/03/14 15:19:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.3 MB)
21/03/14 15:19:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:64343 (size: 4.2 KB, free: 912.3 MB)
21/03/14 15:19:41 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:41 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/03/14 15:19:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 4 tasks
21/03/14 15:19:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 9258 bytes)
21/03/14 15:19:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 9275 bytes)
21/03/14 15:19:41 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 9258 bytes)
21/03/14 15:19:41 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 9275 bytes)
21/03/14 15:19:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
21/03/14 15:19:41 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
21/03/14 15:19:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:19:41 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
21/03/14 15:19:41 INFO Executor: Fetching spark://localhost:64342/jars/sparklyr-2.4-2.11.jar with timestamp 1615731569578
21/03/14 15:19:41 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:64342 after 28 ms (0 ms spent in bootstraps)
21/03/14 15:19:41 INFO Utils: Fetching spark://localhost:64342/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-846bbc08-36c5-4bf3-bd4b-537e82a796cd/userFiles-5f08e8e2-f6a4-4830-8163-cca426e6861c/fetchFileTemp9156267435542974603.tmp
21/03/14 15:19:41 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-846bbc08-36c5-4bf3-bd4b-537e82a796cd/userFiles-5f08e8e2-f6a4-4830-8163-cca426e6861c/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:19:42 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:19:42 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1542 bytes result sent to driver
21/03/14 15:19:42 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1542 bytes result sent to driver
21/03/14 15:19:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1542 bytes result sent to driver
21/03/14 15:19:42 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 360 ms on localhost (executor driver) (1/4)
21/03/14 15:19:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 395 ms on localhost (executor driver) (2/4)
21/03/14 15:19:42 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 369 ms on localhost (executor driver) (3/4)
21/03/14 15:19:42 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 368 ms on localhost (executor driver) (4/4)
21/03/14 15:19:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:19:42 INFO DAGScheduler: ShuffleMapStage 0 (count at utils.scala:135) finished in 0.896 s
21/03/14 15:19:42 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:19:42 INFO DAGScheduler: running: Set()
21/03/14 15:19:42 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/03/14 15:19:42 INFO DAGScheduler: failed: Set()
21/03/14 15:19:42 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135), which has no missing parents
21/03/14 15:19:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:19:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:19:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:64343 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:19:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:19:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:19:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:19:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 4)
21/03/14 15:19:42 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
21/03/14 15:19:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
21/03/14 15:19:42 INFO Executor: Finished task 0.0 in stage 1.0 (TID 4). 1825 bytes result sent to driver
21/03/14 15:19:42 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 4) in 73 ms on localhost (executor driver) (1/1)
21/03/14 15:19:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:19:42 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.087 s
21/03/14 15:19:42 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 1.111536 s
21/03/14 15:19:42 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:19:42 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:19:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:19:42 INFO MemoryStore: MemoryStore cleared
21/03/14 15:19:42 INFO BlockManager: BlockManager stopped
21/03/14 15:19:42 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:19:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:19:42 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:19:42 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:19:42 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-467794ce-7295-4075-b67c-d763a5b82d81
21/03/14 15:19:42 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-846bbc08-36c5-4bf3-bd4b-537e82a796cd
21/03/14 15:19:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:19:45 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:19:45 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:19:46 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:19:46 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:19:46 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:19:46 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:19:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:19:46 INFO Utils: Successfully started service 'sparkDriver' on port 64367.
21/03/14 15:19:46 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:19:46 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:19:46 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:19:46 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:19:46 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-e7748257-8acf-4193-bf3c-0cb3fc856da1
21/03/14 15:19:46 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:19:46 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:19:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:19:46 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:19:46 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:64367/jars/sparklyr-2.4-2.11.jar with timestamp 1615731586643
21/03/14 15:19:46 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:19:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64368.
21/03/14 15:19:46 INFO NettyBlockTransferService: Server created on localhost:64368
21/03/14 15:19:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:19:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 64368, None)
21/03/14 15:19:46 INFO BlockManagerMasterEndpoint: Registering block manager localhost:64368 with 912.3 MB RAM, BlockManagerId(driver, localhost, 64368, None)
21/03/14 15:19:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 64368, None)
21/03/14 15:19:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 64368, None)
21/03/14 15:19:47 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:19:47 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:19:47 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:19:47 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:19:51 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:19:51 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:19:52 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:19:52 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:19:52 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:19:53 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:19:55 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:55 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:56 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:19:56 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:19:56 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:19:56 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:19:56 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:19:56 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:19:56 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:19:57 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:19:57 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:19:57 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:19:57 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:19:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:19:57 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/8f6699b4-867f-45c8-818f-7c38e9636793_resources
21/03/14 15:19:57 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/8f6699b4-867f-45c8-818f-7c38e9636793
21/03/14 15:19:57 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/8f6699b4-867f-45c8-818f-7c38e9636793
21/03/14 15:19:57 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/8f6699b4-867f-45c8-818f-7c38e9636793/_tmp_space.db
21/03/14 15:19:57 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:19:57 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:19:57 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:19:57 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:19:57 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:19:58 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:19:58 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
21/03/14 15:19:58 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:19:58 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:19:58 INFO CodeGenerator: Code generated in 393.885156 ms
21/03/14 15:19:58 INFO CodeGenerator: Code generated in 22.989286 ms
21/03/14 15:19:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 284.3 KB, free 912.0 MB)
21/03/14 15:19:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.9 KB, free 912.0 MB)
21/03/14 15:19:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:64368 (size: 23.9 KB, free: 912.3 MB)
21/03/14 15:19:59 INFO SparkContext: Created broadcast 0 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:19:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:19:59 INFO SparkContext: Starting job: createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:19:59 INFO DAGScheduler: Got job 0 (createTable at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:19:59 INFO DAGScheduler: Final stage: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0)
21/03/14 15:19:59 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:19:59 INFO DAGScheduler: Missing parents: List()
21/03/14 15:19:59 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:19:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 912.0 MB)
21/03/14 15:19:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.0 MB)
21/03/14 15:19:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:64368 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:19:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:19:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:19:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:19:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8362 bytes)
21/03/14 15:19:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:19:59 INFO Executor: Fetching spark://localhost:64367/jars/sparklyr-2.4-2.11.jar with timestamp 1615731586643
21/03/14 15:19:59 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:64367 after 39 ms (0 ms spent in bootstraps)
21/03/14 15:19:59 INFO Utils: Fetching spark://localhost:64367/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-d4e80cfa-5e26-4bea-8296-067ddfb409b1/userFiles-fbe54ba9-2fe4-4de8-b6bb-b1eaeaee730b/fetchFileTemp6975218613753944124.tmp
21/03/14 15:19:59 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-d4e80cfa-5e26-4bea-8296-067ddfb409b1/userFiles-fbe54ba9-2fe4-4de8-b6bb-b1eaeaee730b/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:20:00 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpK7Na3E/file1612121ada030, range: 0-1303, partition values: [empty row]
21/03/14 15:20:00 INFO CodeGenerator: Code generated in 24.240247 ms
21/03/14 15:20:00 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1329 bytes result sent to driver
21/03/14 15:20:00 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 522 ms on localhost (executor driver) (1/1)
21/03/14 15:20:00 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:20:00 INFO DAGScheduler: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0) finished in 0.660 s
21/03/14 15:20:00 INFO DAGScheduler: Job 0 finished: createTable at NativeMethodAccessorImpl.java:0, took 0.718051 s
21/03/14 15:20:00 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:20:00 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:20:00 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:20:00 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:20:00 INFO CodeGenerator: Code generated in 9.347618 ms
21/03/14 15:20:00 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 284.3 KB, free 911.7 MB)
21/03/14 15:20:00 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.7 MB)
21/03/14 15:20:00 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:64368 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:20:00 INFO SparkContext: Created broadcast 2 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:20:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:20:00 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:20:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:20:00 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:00 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:20:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:20:00 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:00 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `default`.`mtcars` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.
21/03/14 15:20:00 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:20:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:20:00 INFO HiveMetaStore: 0: create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615731590, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpK7Na3E/file1612121ada030, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
21/03/14 15:20:00 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615731590, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpK7Na3E/file1612121ada030, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
21/03/14 15:20:00 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__
21/03/14 15:20:01 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:20:01 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:20:01 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:20:01 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:01 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:01 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:01 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:01 INFO CodeGenerator: Code generated in 18.311268 ms
21/03/14 15:20:01 INFO CodeGenerator: Code generated in 29.13907 ms
21/03/14 15:20:01 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:20:01 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:20:01 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:20:01 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:20:01 INFO DAGScheduler: Missing parents: List()
21/03/14 15:20:01 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135), which has no missing parents
21/03/14 15:20:01 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.5 KB, free 911.7 MB)
21/03/14 15:20:01 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 15:20:01 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:64368 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:20:01 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:20:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:20:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:20:01 INFO CodeGenerator: Code generated in 8.912012 ms
21/03/14 15:20:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 15:20:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 32 ms on localhost (executor driver) (1/1)
21/03/14 15:20:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:20:01 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.043 s
21/03/14 15:20:01 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.048372 s
21/03/14 15:20:02 INFO CodeGenerator: Code generated in 20.113263 ms
21/03/14 15:20:02 INFO CodeGenerator: Code generated in 19.503983 ms
21/03/14 15:20:02 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:20:02 INFO DAGScheduler: Registering RDD 16 (count at utils.scala:135)
21/03/14 15:20:02 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:20:02 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:20:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:20:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:20:02 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135), which has no missing parents
21/03/14 15:20:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.4 KB, free 911.7 MB)
21/03/14 15:20:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.7 MB)
21/03/14 15:20:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:64368 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:20:02 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:20:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:20:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:20:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:20:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 61 ms on localhost (executor driver) (1/1)
21/03/14 15:20:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:20:02 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.076 s
21/03/14 15:20:02 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:20:02 INFO DAGScheduler: running: Set()
21/03/14 15:20:02 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:20:02 INFO DAGScheduler: failed: Set()
21/03/14 15:20:02 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135), which has no missing parents
21/03/14 15:20:02 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 15:20:02 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 15:20:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:64368 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:20:02 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:02 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:20:02 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:20:02 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:20:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:20:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
21/03/14 15:20:02 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:20:02 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 50 ms on localhost (executor driver) (1/1)
21/03/14 15:20:02 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:20:02 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.061 s
21/03/14 15:20:02 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.169335 s
21/03/14 15:20:02 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:02 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:02 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:02 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:20:02 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:20:02 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:20:02 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:20:02 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:02 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:02 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:02 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 284.5 KB, free 911.4 MB)
21/03/14 15:20:02 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.4 MB)
21/03/14 15:20:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:64368 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:20:02 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:20:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:20:02 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:20:02 INFO DAGScheduler: Registering RDD 27 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:20:02 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:20:02 INFO DAGScheduler: Final stage: ResultStage 5 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:20:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 15:20:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 15:20:03 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:20:03 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 911.3 MB)
21/03/14 15:20:03 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 12.2 KB, free 911.3 MB)
21/03/14 15:20:03 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:64368 (size: 12.2 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:03 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:20:03 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:20:03 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:20:03 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpK7Na3E/file1612121ada030, range: 0-1303, partition values: [empty row]
21/03/14 15:20:03 INFO CodeGenerator: Code generated in 23.999271 ms
21/03/14 15:20:03 INFO MemoryStore: Block rdd_22_0 stored as values in memory (estimated size 4.1 KB, free 911.3 MB)
21/03/14 15:20:03 INFO BlockManagerInfo: Added rdd_22_0 in memory on localhost:64368 (size: 4.1 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO CodeGenerator: Code generated in 10.038796 ms
21/03/14 15:20:03 INFO CodeGenerator: Code generated in 25.013585 ms
21/03/14 15:20:03 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1871 bytes result sent to driver
21/03/14 15:20:03 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 234 ms on localhost (executor driver) (1/1)
21/03/14 15:20:03 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:20:03 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.294 s
21/03/14 15:20:03 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:20:03 INFO DAGScheduler: running: Set()
21/03/14 15:20:03 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 15:20:03 INFO DAGScheduler: failed: Set()
21/03/14 15:20:03 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:20:03 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 15:20:03 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 15:20:03 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:64368 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:03 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:20:03 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:20:03 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:20:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:20:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:20:03 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1782 bytes result sent to driver
21/03/14 15:20:03 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:20:03 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:20:03 INFO DAGScheduler: ResultStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.021 s
21/03/14 15:20:03 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.328321 s
21/03/14 15:20:03 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:03 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:20:03 INFO DAGScheduler: Registering RDD 35 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:20:03 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:20:03 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:20:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
21/03/14 15:20:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
21/03/14 15:20:03 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:20:03 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 25.9 KB, free 911.3 MB)
21/03/14 15:20:03 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.1 KB, free 911.3 MB)
21/03/14 15:20:03 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:64368 (size: 12.1 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:03 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:20:03 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:20:03 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:20:03 INFO BlockManager: Found block rdd_22_0 locally
21/03/14 15:20:03 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1871 bytes result sent to driver
21/03/14 15:20:03 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 16 ms on localhost (executor driver) (1/1)
21/03/14 15:20:03 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:20:03 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.033 s
21/03/14 15:20:03 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:20:03 INFO DAGScheduler: running: Set()
21/03/14 15:20:03 INFO DAGScheduler: waiting: Set(ResultStage 7)
21/03/14 15:20:03 INFO DAGScheduler: failed: Set()
21/03/14 15:20:03 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:20:03 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 15:20:03 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 15:20:03 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:64368 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:03 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/14 15:20:03 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:20:03 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 15:20:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:20:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:20:03 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1782 bytes result sent to driver
21/03/14 15:20:03 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:20:03 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 15:20:03 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.016 s
21/03/14 15:20:03 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.056474 s
21/03/14 15:20:03 INFO MapPartitionsRDD: Removing RDD 22 from persistence list
21/03/14 15:20:03 INFO BlockManager: Removing RDD 22
21/03/14 15:20:03 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:20:03 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:20:03 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:20:03 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:20:03 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:03 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 247
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 116
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 130
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 206
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 15:20:03 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:64368 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 235
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 162
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 256
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 261
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 126
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 70
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 90
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 155
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 104
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 101
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 140
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 201
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 118
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 75
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 205
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 245
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 6
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 12
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 202
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 231
21/03/14 15:20:03 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:64368 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 65
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 148
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 124
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 112
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 225
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 222
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 239
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 234
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 146
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 257
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 81
21/03/14 15:20:03 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:64368 in memory (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 67
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 223
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 258
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 179
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 246
21/03/14 15:20:03 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:64368 in memory (size: 12.2 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 284.5 KB, free 911.0 MB)
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 228
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 213
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 150
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 115
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 263
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 105
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 127
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 218
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 69
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 232
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 82
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 149
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 73
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 252
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 139
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 77
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 11
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 191
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 151
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 97
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 129
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 157
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 9
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 64
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 158
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 125
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 159
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 233
21/03/14 15:20:03 INFO ContextCleaner: Cleaned shuffle 0
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 240
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 110
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 10
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 238
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 7
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 27
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 107
21/03/14 15:20:03 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:64368 in memory (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 8
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 29
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 192
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 180
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 99
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 96
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 236
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 178
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 14
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 188
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 241
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 134
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 15:20:03 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:64368 in memory (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 88
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 172
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 30
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 193
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 250
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 37
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 244
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 174
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 211
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 196
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 248
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 177
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 68
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 74
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 111
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 22
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 95
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 187
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 21
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 226
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 17
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 251
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 208
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 114
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 36
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 144
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 260
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 122
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 106
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 26
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 19
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 230
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 86
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 93
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 100
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 253
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 154
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 98
21/03/14 15:20:03 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:64368 in memory (size: 12.1 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 255
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 136
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 141
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 259
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 28
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 171
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 103
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 169
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 166
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 135
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 220
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 76
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 182
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 121
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 84
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 221
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 83
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 132
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 165
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 237
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 143
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 204
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 102
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 210
21/03/14 15:20:03 INFO BlockManager: Removing RDD 22
21/03/14 15:20:03 INFO ContextCleaner: Cleaned RDD 22
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 262
21/03/14 15:20:03 INFO ContextCleaner: Cleaned shuffle 1
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 109
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 163
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 264
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 212
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 197
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 216
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 185
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 254
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 137
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 128
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 24
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 215
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 25
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 78
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 94
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 198
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 190
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 243
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 15
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 156
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 120
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 242
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 72
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 209
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 224
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 181
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 265
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 123
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 189
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 168
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 195
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 92
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 229
21/03/14 15:20:03 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.4 MB)
21/03/14 15:20:03 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:64368 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:64368 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 167
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 117
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 194
21/03/14 15:20:03 INFO SparkContext: Created broadcast 11 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 217
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 207
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 161
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 147
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 200
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 79
21/03/14 15:20:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:20:03 INFO ContextCleaner: Cleaned shuffle 2
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 183
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 66
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 85
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 20
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 89
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 16
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 160
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 199
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 108
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 131
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 152
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 18
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 214
21/03/14 15:20:03 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:64368 in memory (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 173
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 23
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 186
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 113
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 145
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 203
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 153
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 13
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 176
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 80
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 249
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 170
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 227
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 175
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 87
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 219
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 91
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 164
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 184
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 142
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 71
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 119
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 133
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 138
21/03/14 15:20:03 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 15:20:03 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:20:03 INFO DAGScheduler: Registering RDD 46 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:20:03 INFO DAGScheduler: Got job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:20:03 INFO DAGScheduler: Final stage: ResultStage 9 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:20:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/03/14 15:20:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
21/03/14 15:20:03 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:20:03 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 25.9 KB, free 911.4 MB)
21/03/14 15:20:03 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 12.1 KB, free 911.4 MB)
21/03/14 15:20:03 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:64368 (size: 12.1 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:03 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 15:20:03 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:20:03 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/03/14 15:20:03 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpK7Na3E/file1612121ada030, range: 0-2539, partition values: [empty row]
21/03/14 15:20:03 INFO MemoryStore: Block rdd_41_0 stored as values in memory (estimated size 4.9 KB, free 911.4 MB)
21/03/14 15:20:03 INFO BlockManagerInfo: Added rdd_41_0 in memory on localhost:64368 (size: 4.9 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1871 bytes result sent to driver
21/03/14 15:20:03 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 44 ms on localhost (executor driver) (1/1)
21/03/14 15:20:03 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 15:20:03 INFO DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.057 s
21/03/14 15:20:03 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:20:03 INFO DAGScheduler: running: Set()
21/03/14 15:20:03 INFO DAGScheduler: waiting: Set(ResultStage 9)
21/03/14 15:20:03 INFO DAGScheduler: failed: Set()
21/03/14 15:20:03 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[49] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:20:03 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.1 KB, free 911.3 MB)
21/03/14 15:20:03 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.3 MB)
21/03/14 15:20:03 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:64368 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:20:03 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[49] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:03 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 15:20:03 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:20:03 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/03/14 15:20:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:20:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:20:03 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1782 bytes result sent to driver
21/03/14 15:20:03 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:20:03 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 15:20:03 INFO DAGScheduler: ResultStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.014 s
21/03/14 15:20:03 INFO DAGScheduler: Job 5 finished: count at NativeMethodAccessorImpl.java:0, took 0.077394 s
21/03/14 15:20:03 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:20:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:20:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:20:03 INFO MemoryStore: MemoryStore cleared
21/03/14 15:20:03 INFO BlockManager: BlockManager stopped
21/03/14 15:20:03 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:20:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:20:03 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:20:03 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:20:03 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-d4e80cfa-5e26-4bea-8296-067ddfb409b1
21/03/14 15:20:04 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-eed6a764-a2cd-4d7d-bd81-34367a87b197
21/03/14 15:20:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:20:07 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:20:07 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:20:07 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:20:07 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:20:07 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:20:07 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:20:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:20:07 INFO Utils: Successfully started service 'sparkDriver' on port 64390.
21/03/14 15:20:07 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:20:07 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:20:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:20:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:20:07 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-efd42375-30bb-4b53-9772-7feca08ca333
21/03/14 15:20:07 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:20:07 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:20:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:20:08 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:20:08 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:64390/jars/sparklyr-2.4-2.11.jar with timestamp 1615731608259
21/03/14 15:20:08 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:20:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64391.
21/03/14 15:20:08 INFO NettyBlockTransferService: Server created on localhost:64391
21/03/14 15:20:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:20:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 64391, None)
21/03/14 15:20:08 INFO BlockManagerMasterEndpoint: Registering block manager localhost:64391 with 912.3 MB RAM, BlockManagerId(driver, localhost, 64391, None)
21/03/14 15:20:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 64391, None)
21/03/14 15:20:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 64391, None)
21/03/14 15:20:08 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:20:08 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:20:08 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:20:09 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:20:12 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:20:13 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:20:13 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:20:13 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:20:13 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:20:15 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:20:16 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:20:16 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:20:17 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:20:17 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:20:17 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:20:17 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:20:17 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:20:18 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:20:18 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:20:18 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:20:18 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:20:18 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:20:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:20:18 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:20:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:20:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:20:18 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/2946e0c4-88d8-4580-b04f-2ab61200f68c_resources
21/03/14 15:20:18 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/2946e0c4-88d8-4580-b04f-2ab61200f68c
21/03/14 15:20:18 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/2946e0c4-88d8-4580-b04f-2ab61200f68c
21/03/14 15:20:18 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/2946e0c4-88d8-4580-b04f-2ab61200f68c/_tmp_space.db
21/03/14 15:20:18 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:20:18 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:20:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:20:18 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:18 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:19 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:20:19 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
21/03/14 15:20:19 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:20:19 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:20:19 INFO CodeGenerator: Code generated in 252.107647 ms
21/03/14 15:20:20 INFO CodeGenerator: Code generated in 20.285064 ms
21/03/14 15:20:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 284.3 KB, free 912.0 MB)
21/03/14 15:20:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.9 KB, free 912.0 MB)
21/03/14 15:20:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:64391 (size: 23.9 KB, free: 912.3 MB)
21/03/14 15:20:20 INFO SparkContext: Created broadcast 0 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:20:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:20:20 INFO SparkContext: Starting job: createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:20:20 INFO DAGScheduler: Got job 0 (createTable at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:20:20 INFO DAGScheduler: Final stage: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0)
21/03/14 15:20:20 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:20:20 INFO DAGScheduler: Missing parents: List()
21/03/14 15:20:20 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:20:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 912.0 MB)
21/03/14 15:20:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.0 MB)
21/03/14 15:20:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:64391 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:20:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at createTable at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:20:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8362 bytes)
21/03/14 15:20:21 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:20:21 INFO Executor: Fetching spark://localhost:64390/jars/sparklyr-2.4-2.11.jar with timestamp 1615731608259
21/03/14 15:20:21 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:64390 after 29 ms (0 ms spent in bootstraps)
21/03/14 15:20:21 INFO Utils: Fetching spark://localhost:64390/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-60048d42-99b6-418d-a3f2-ce80ab710c35/userFiles-2983c349-1fe8-4d0c-bff8-f8ac8c97b54b/fetchFileTemp3648541771490585564.tmp
21/03/14 15:20:21 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-60048d42-99b6-418d-a3f2-ce80ab710c35/userFiles-2983c349-1fe8-4d0c-bff8-f8ac8c97b54b/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:20:21 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpK7Na3E/file161215b60d72d, range: 0-1303, partition values: [empty row]
21/03/14 15:20:21 INFO CodeGenerator: Code generated in 15.400611 ms
21/03/14 15:20:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1329 bytes result sent to driver
21/03/14 15:20:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 354 ms on localhost (executor driver) (1/1)
21/03/14 15:20:21 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:20:21 INFO DAGScheduler: ResultStage 0 (createTable at NativeMethodAccessorImpl.java:0) finished in 0.502 s
21/03/14 15:20:21 INFO DAGScheduler: Job 0 finished: createTable at NativeMethodAccessorImpl.java:0, took 0.572931 s
21/03/14 15:20:21 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:20:21 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:20:21 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/03/14 15:20:21 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:20:21 INFO CodeGenerator: Code generated in 9.935287 ms
21/03/14 15:20:21 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 284.3 KB, free 911.7 MB)
21/03/14 15:20:21 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.7 MB)
21/03/14 15:20:21 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:64391 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:20:21 INFO SparkContext: Created broadcast 2 from createTable at NativeMethodAccessorImpl.java:0
21/03/14 15:20:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:20:21 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:20:21 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:20:21 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:21 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:21 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:20:21 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:20:21 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:21 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:21 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `default`.`mtcars` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.
21/03/14 15:20:21 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:20:21 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:20:22 INFO HiveMetaStore: 0: create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615731611, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpK7Na3E/file161215b60d72d, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))
21/03/14 15:20:22 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=create_table: Table(tableName:mtcars, dbName:default, owner:nathan, createTime:1615731611, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:array<string>, comment:from deserializer)], location:file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{path=file:/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpK7Na3E/file161215b60d72d, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}},{"name":"_c2","type":"string","nullable":true,"metadata":{}},{"name":"_c3","type":"string","nullable":true,"metadata":{}},{"name":"_c4","type":"string","nullable":true,"metadata":{}},{"name":"_c5","type":"string","nullable":true,"metadata":{}},{"name":"_c6","type":"string","nullable":true,"metadata":{}},{"name":"_c7","type":"string","nullable":true,"metadata":{}},{"name":"_c8","type":"string","nullable":true,"metadata":{}},{"name":"_c9","type":"string","nullable":true,"metadata":{}},{"name":"_c10","type":"string","nullable":true,"metadata":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.sources.provider=csv, spark.sql.create.version=2.4.3}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))	
21/03/14 15:20:22 INFO FileUtils: Creating directory if it doesn't exist: file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse/mtcars-__PLACEHOLDER__
21/03/14 15:20:22 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:20:22 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:20:22 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:20:22 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:22 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:22 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:22 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:22 INFO CodeGenerator: Code generated in 14.116411 ms
21/03/14 15:20:22 INFO CodeGenerator: Code generated in 10.307101 ms
21/03/14 15:20:22 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:20:22 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:20:22 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:20:22 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:20:22 INFO DAGScheduler: Missing parents: List()
21/03/14 15:20:22 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135), which has no missing parents
21/03/14 15:20:22 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.5 KB, free 911.7 MB)
21/03/14 15:20:22 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.7 MB)
21/03/14 15:20:22 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:64391 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:20:22 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:20:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:20:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:20:22 INFO CodeGenerator: Code generated in 6.625049 ms
21/03/14 15:20:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1286 bytes result sent to driver
21/03/14 15:20:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 24 ms on localhost (executor driver) (1/1)
21/03/14 15:20:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:20:22 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.029 s
21/03/14 15:20:22 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.033096 s
21/03/14 15:20:22 INFO CodeGenerator: Code generated in 19.853165 ms
21/03/14 15:20:22 INFO CodeGenerator: Code generated in 17.927377 ms
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 63
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 50
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 60
21/03/14 15:20:23 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:64391 in memory (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 18
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 9
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 27
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 47
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 62
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 38
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 40
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 21
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 6
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 43
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 59
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 16
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 29
21/03/14 15:20:23 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:64391 in memory (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 28
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 8
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 42
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 10
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 26
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 19
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 48
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 44
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 52
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 13
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 53
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 51
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 7
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 49
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 41
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 54
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 12
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 11
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 24
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 14
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 17
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 45
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 30
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 58
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 61
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 25
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 56
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 15
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 46
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 23
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 20
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 22
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 57
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 39
21/03/14 15:20:23 INFO ContextCleaner: Cleaned accumulator 55
21/03/14 15:20:23 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:20:23 INFO DAGScheduler: Registering RDD 16 (count at utils.scala:135)
21/03/14 15:20:23 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:20:23 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:20:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:20:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:20:23 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135), which has no missing parents
21/03/14 15:20:23 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.4 KB, free 911.7 MB)
21/03/14 15:20:23 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.7 MB)
21/03/14 15:20:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:64391 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:20:23 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:20:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:20:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:20:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:20:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 56 ms on localhost (executor driver) (1/1)
21/03/14 15:20:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:20:23 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.071 s
21/03/14 15:20:23 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:20:23 INFO DAGScheduler: running: Set()
21/03/14 15:20:23 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:20:23 INFO DAGScheduler: failed: Set()
21/03/14 15:20:23 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135), which has no missing parents
21/03/14 15:20:23 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 15:20:23 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 15:20:23 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:64391 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:20:23 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:23 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:20:23 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:20:23 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:20:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:20:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
21/03/14 15:20:23 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:20:23 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 55 ms on localhost (executor driver) (1/1)
21/03/14 15:20:23 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:20:23 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.067 s
21/03/14 15:20:23 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.166031 s
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:23 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:20:23 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:20:23 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:20:23 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:23 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:23 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:23 INFO CodeGenerator: Code generated in 26.32978 ms
21/03/14 15:20:24 INFO CodeGenerator: Code generated in 21.484898 ms
21/03/14 15:20:24 INFO CodeGenerator: Code generated in 9.14645 ms
21/03/14 15:20:24 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:20:24 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135)
21/03/14 15:20:24 INFO DAGScheduler: Got job 3 (count at utils.scala:135) with 1 output partitions
21/03/14 15:20:24 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/03/14 15:20:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/03/14 15:20:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/03/14 15:20:24 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/03/14 15:20:24 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.9 KB, free 911.7 MB)
21/03/14 15:20:24 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.2 KB, free 911.7 MB)
21/03/14 15:20:24 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:64391 (size: 4.2 KB, free: 912.2 MB)
21/03/14 15:20:24 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:24 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:20:24 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/03/14 15:20:24 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:20:24 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1499 bytes result sent to driver
21/03/14 15:20:24 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 9 ms on localhost (executor driver) (1/1)
21/03/14 15:20:24 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:20:24 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.021 s
21/03/14 15:20:24 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:20:24 INFO DAGScheduler: running: Set()
21/03/14 15:20:24 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/03/14 15:20:24 INFO DAGScheduler: failed: Set()
21/03/14 15:20:24 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/03/14 15:20:24 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.1 KB, free 911.7 MB)
21/03/14 15:20:24 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.7 MB)
21/03/14 15:20:24 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:64391 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:20:24 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:24 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:20:24 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:20:24 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:20:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:20:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:20:24 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1782 bytes result sent to driver
21/03/14 15:20:24 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 6 ms on localhost (executor driver) (1/1)
21/03/14 15:20:24 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:20:24 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.011 s
21/03/14 15:20:24 INFO DAGScheduler: Job 3 finished: count at utils.scala:135, took 0.036323 s
21/03/14 15:20:24 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:24 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:20:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:20:24 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:24 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:24 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:24 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:20:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:20:24 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:24 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:24 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:24 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:20:24 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:20:24 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 9 more fields>
21/03/14 15:20:24 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:20:24 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:24 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:20:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:20:24 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:20:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:20:24 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:20:24 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:20:24 INFO CodeGenerator: Code generated in 6.681172 ms
21/03/14 15:20:24 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 15:20:24 INFO DAGScheduler: Got job 4 (collect at utils.scala:61) with 1 output partitions
21/03/14 15:20:24 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:61)
21/03/14 15:20:24 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:20:24 INFO DAGScheduler: Missing parents: List()
21/03/14 15:20:24 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[31] at map at utils.scala:54), which has no missing parents
21/03/14 15:20:24 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 6.0 KB, free 911.6 MB)
21/03/14 15:20:24 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.4 KB, free 911.6 MB)
21/03/14 15:20:24 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:64391 (size: 3.4 KB, free: 912.2 MB)
21/03/14 15:20:24 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[31] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:24 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:20:24 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
21/03/14 15:20:24 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:20:24 INFO CodeGenerator: Code generated in 6.558846 ms
21/03/14 15:20:24 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 979 bytes result sent to driver
21/03/14 15:20:24 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 14 ms on localhost (executor driver) (1/1)
21/03/14 15:20:24 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:20:24 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:61) finished in 0.020 s
21/03/14 15:20:24 INFO DAGScheduler: Job 4 finished: collect at utils.scala:61, took 0.022219 s
21/03/14 15:20:24 INFO CodeGenerator: Code generated in 8.84942 ms
21/03/14 15:20:24 INFO CodeGenerator: Code generated in 6.325773 ms
21/03/14 15:20:24 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:20:24 INFO DAGScheduler: Got job 5 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:20:24 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:135)
21/03/14 15:20:24 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:20:24 INFO DAGScheduler: Missing parents: List()
21/03/14 15:20:24 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[35] at collect at utils.scala:135), which has no missing parents
21/03/14 15:20:24 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 6.3 KB, free 911.6 MB)
21/03/14 15:20:24 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.6 MB)
21/03/14 15:20:24 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:64391 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:20:24 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:24 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/03/14 15:20:24 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:20:24 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/03/14 15:20:24 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1286 bytes result sent to driver
21/03/14 15:20:24 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 6 ms on localhost (executor driver) (1/1)
21/03/14 15:20:24 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/03/14 15:20:24 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:135) finished in 0.013 s
21/03/14 15:20:24 INFO DAGScheduler: Job 5 finished: collect at utils.scala:135, took 0.015442 s
21/03/14 15:20:24 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:20:24 INFO DAGScheduler: Registering RDD 38 (count at utils.scala:135)
21/03/14 15:20:24 INFO DAGScheduler: Got job 6 (count at utils.scala:135) with 1 output partitions
21/03/14 15:20:24 INFO DAGScheduler: Final stage: ResultStage 9 (count at utils.scala:135)
21/03/14 15:20:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
21/03/14 15:20:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
21/03/14 15:20:24 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[38] at count at utils.scala:135), which has no missing parents
21/03/14 15:20:24 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.4 KB, free 911.6 MB)
21/03/14 15:20:24 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.6 MB)
21/03/14 15:20:24 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:64391 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:20:24 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[38] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:24 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/03/14 15:20:24 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:20:24 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/03/14 15:20:24 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1542 bytes result sent to driver
21/03/14 15:20:24 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 9 ms on localhost (executor driver) (1/1)
21/03/14 15:20:24 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/03/14 15:20:24 INFO DAGScheduler: ShuffleMapStage 8 (count at utils.scala:135) finished in 0.016 s
21/03/14 15:20:24 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:20:24 INFO DAGScheduler: running: Set()
21/03/14 15:20:24 INFO DAGScheduler: waiting: Set(ResultStage 9)
21/03/14 15:20:24 INFO DAGScheduler: failed: Set()
21/03/14 15:20:24 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[41] at count at utils.scala:135), which has no missing parents
21/03/14 15:20:24 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 15:20:24 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 15:20:24 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:64391 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:20:24 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[41] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:24 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/03/14 15:20:24 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:20:24 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/03/14 15:20:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:20:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:20:24 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1782 bytes result sent to driver
21/03/14 15:20:24 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 6 ms on localhost (executor driver) (1/1)
21/03/14 15:20:24 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/03/14 15:20:24 INFO DAGScheduler: ResultStage 9 (count at utils.scala:135) finished in 0.013 s
21/03/14 15:20:24 INFO DAGScheduler: Job 6 finished: count at utils.scala:135, took 0.033609 s
21/03/14 15:20:25 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:20:25 INFO DAGScheduler: Got job 7 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:20:25 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:135)
21/03/14 15:20:25 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:20:25 INFO DAGScheduler: Missing parents: List()
21/03/14 15:20:25 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[44] at collect at utils.scala:135), which has no missing parents
21/03/14 15:20:25 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 6.3 KB, free 911.6 MB)
21/03/14 15:20:25 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.6 MB)
21/03/14 15:20:25 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:64391 (size: 3.3 KB, free: 912.2 MB)
21/03/14 15:20:25 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[44] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:25 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/03/14 15:20:25 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:20:25 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/03/14 15:20:25 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1286 bytes result sent to driver
21/03/14 15:20:25 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 5 ms on localhost (executor driver) (1/1)
21/03/14 15:20:25 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/03/14 15:20:25 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:135) finished in 0.010 s
21/03/14 15:20:25 INFO DAGScheduler: Job 7 finished: collect at utils.scala:135, took 0.012173 s
21/03/14 15:20:25 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:20:25 INFO DAGScheduler: Registering RDD 47 (count at utils.scala:135)
21/03/14 15:20:25 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/03/14 15:20:25 INFO DAGScheduler: Final stage: ResultStage 12 (count at utils.scala:135)
21/03/14 15:20:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
21/03/14 15:20:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
21/03/14 15:20:25 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[47] at count at utils.scala:135), which has no missing parents
21/03/14 15:20:25 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.4 KB, free 911.6 MB)
21/03/14 15:20:25 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.6 MB)
21/03/14 15:20:25 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:64391 (size: 4.5 KB, free: 912.2 MB)
21/03/14 15:20:25 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[47] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:25 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/03/14 15:20:25 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:20:25 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/03/14 15:20:25 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1499 bytes result sent to driver
21/03/14 15:20:25 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 9 ms on localhost (executor driver) (1/1)
21/03/14 15:20:25 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/03/14 15:20:25 INFO DAGScheduler: ShuffleMapStage 11 (count at utils.scala:135) finished in 0.016 s
21/03/14 15:20:25 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:20:25 INFO DAGScheduler: running: Set()
21/03/14 15:20:25 INFO DAGScheduler: waiting: Set(ResultStage 12)
21/03/14 15:20:25 INFO DAGScheduler: failed: Set()
21/03/14 15:20:25 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[50] at count at utils.scala:135), which has no missing parents
21/03/14 15:20:25 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/03/14 15:20:25 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/03/14 15:20:25 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:64391 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:20:25 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[50] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:25 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/03/14 15:20:25 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:20:25 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/03/14 15:20:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:20:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/14 15:20:25 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1782 bytes result sent to driver
21/03/14 15:20:25 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 5 ms on localhost (executor driver) (1/1)
21/03/14 15:20:25 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/03/14 15:20:25 INFO DAGScheduler: ResultStage 12 (count at utils.scala:135) finished in 0.011 s
21/03/14 15:20:25 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.031580 s
21/03/14 15:20:25 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:25 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:25 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:25 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:25 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:25 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:25 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:20:25 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:20:25 INFO FileSourceStrategy: Output Data Schema: struct<>
21/03/14 15:20:25 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:20:25 INFO CodeGenerator: Code generated in 13.32804 ms
21/03/14 15:20:25 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 284.5 KB, free 911.3 MB)
21/03/14 15:20:25 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.9 KB, free 911.3 MB)
21/03/14 15:20:25 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:64391 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:20:25 INFO SparkContext: Created broadcast 15 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:20:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:20:25 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:20:25 INFO DAGScheduler: Registering RDD 53 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:20:25 INFO DAGScheduler: Got job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:20:25 INFO DAGScheduler: Final stage: ResultStage 14 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:20:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/03/14 15:20:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/03/14 15:20:25 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:20:25 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 14.2 KB, free 911.3 MB)
21/03/14 15:20:25 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.3 MB)
21/03/14 15:20:25 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:64391 (size: 8.0 KB, free: 912.2 MB)
21/03/14 15:20:25 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:25 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/03/14 15:20:25 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:20:25 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/03/14 15:20:25 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpK7Na3E/file161215b60d72d, range: 0-1303, partition values: [empty row]
21/03/14 15:20:25 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1585 bytes result sent to driver
21/03/14 15:20:25 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 42 ms on localhost (executor driver) (1/1)
21/03/14 15:20:25 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/03/14 15:20:25 INFO DAGScheduler: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.061 s
21/03/14 15:20:25 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:20:25 INFO DAGScheduler: running: Set()
21/03/14 15:20:25 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/03/14 15:20:25 INFO DAGScheduler: failed: Set()
21/03/14 15:20:25 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:20:25 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.1 KB, free 911.2 MB)
21/03/14 15:20:25 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.2 MB)
21/03/14 15:20:25 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:64391 (size: 3.8 KB, free: 912.2 MB)
21/03/14 15:20:25 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:25 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/03/14 15:20:25 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:20:25 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/03/14 15:20:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:20:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:20:25 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1782 bytes result sent to driver
21/03/14 15:20:25 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:20:25 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/03/14 15:20:25 INFO DAGScheduler: ResultStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0.017 s
21/03/14 15:20:25 INFO DAGScheduler: Job 9 finished: count at NativeMethodAccessorImpl.java:0, took 0.083795 s
21/03/14 15:20:25 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:20:25 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:20:25 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:25 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:25 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:25 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:25 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:25 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:25 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:25 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:25 INFO FileSourceStrategy: Pruning directories with: 
21/03/14 15:20:25 INFO FileSourceStrategy: Post-Scan Filters: 
21/03/14 15:20:25 INFO FileSourceStrategy: Output Data Schema: struct<>
21/03/14 15:20:25 INFO FileSourceScanExec: Pushed Filters: 
21/03/14 15:20:25 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 284.5 KB, free 911.0 MB)
21/03/14 15:20:25 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.9 KB, free 910.9 MB)
21/03/14 15:20:25 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:64391 (size: 23.9 KB, free: 912.2 MB)
21/03/14 15:20:25 INFO SparkContext: Created broadcast 18 from count at NativeMethodAccessorImpl.java:0
21/03/14 15:20:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/03/14 15:20:26 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
21/03/14 15:20:26 INFO DAGScheduler: Registering RDD 59 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:20:26 INFO DAGScheduler: Got job 10 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/03/14 15:20:26 INFO DAGScheduler: Final stage: ResultStage 16 (count at NativeMethodAccessorImpl.java:0)
21/03/14 15:20:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
21/03/14 15:20:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
21/03/14 15:20:26 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:20:26 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 14.2 KB, free 910.9 MB)
21/03/14 15:20:26 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.9 MB)
21/03/14 15:20:26 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:64391 (size: 8.0 KB, free: 912.1 MB)
21/03/14 15:20:26 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:26 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/03/14 15:20:26 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8351 bytes)
21/03/14 15:20:26 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/03/14 15:20:26 INFO FileScanRDD: Reading File path: file:///var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/RtmpK7Na3E/file161215b60d72d, range: 0-2539, partition values: [empty row]
21/03/14 15:20:26 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1585 bytes result sent to driver
21/03/14 15:20:26 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 20 ms on localhost (executor driver) (1/1)
21/03/14 15:20:26 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/03/14 15:20:26 INFO DAGScheduler: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.035 s
21/03/14 15:20:26 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:20:26 INFO DAGScheduler: running: Set()
21/03/14 15:20:26 INFO DAGScheduler: waiting: Set(ResultStage 16)
21/03/14 15:20:26 INFO DAGScheduler: failed: Set()
21/03/14 15:20:26 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
21/03/14 15:20:26 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.1 KB, free 910.9 MB)
21/03/14 15:20:26 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.8 KB, free 910.9 MB)
21/03/14 15:20:26 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:64391 (size: 3.8 KB, free: 912.1 MB)
21/03/14 15:20:26 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:26 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/03/14 15:20:26 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:20:26 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/03/14 15:20:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:20:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:20:26 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1782 bytes result sent to driver
21/03/14 15:20:26 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:20:26 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/03/14 15:20:26 INFO DAGScheduler: ResultStage 16 (count at NativeMethodAccessorImpl.java:0) finished in 0.016 s
21/03/14 15:20:26 INFO DAGScheduler: Job 10 finished: count at NativeMethodAccessorImpl.java:0, took 0.057021 s
21/03/14 15:20:26 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:20:26 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:20:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:20:26 INFO MemoryStore: MemoryStore cleared
21/03/14 15:20:26 INFO BlockManager: BlockManager stopped
21/03/14 15:20:26 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:20:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:20:26 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:20:26 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:20:26 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-60048d42-99b6-418d-a3f2-ce80ab710c35
21/03/14 15:20:26 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-e2ff52ef-1225-4289-a80e-a957195fc6d0
21/03/14 15:20:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/14 15:20:29 INFO SparkContext: Running Spark version 2.4.3
21/03/14 15:20:29 INFO SparkContext: Submitted application: sparklyr
21/03/14 15:20:30 INFO SecurityManager: Changing view acls to: nathan
21/03/14 15:20:30 INFO SecurityManager: Changing modify acls to: nathan
21/03/14 15:20:30 INFO SecurityManager: Changing view acls groups to: 
21/03/14 15:20:30 INFO SecurityManager: Changing modify acls groups to: 
21/03/14 15:20:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nathan); groups with view permissions: Set(); users  with modify permissions: Set(nathan); groups with modify permissions: Set()
21/03/14 15:20:30 INFO Utils: Successfully started service 'sparkDriver' on port 64412.
21/03/14 15:20:30 INFO SparkEnv: Registering MapOutputTracker
21/03/14 15:20:30 INFO SparkEnv: Registering BlockManagerMaster
21/03/14 15:20:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/14 15:20:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/14 15:20:30 INFO DiskBlockManager: Created local directory at /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/blockmgr-0b74e725-c200-44b8-861d-347d0f51ce0a
21/03/14 15:20:30 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/03/14 15:20:30 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/14 15:20:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/14 15:20:30 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/03/14 15:20:30 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:64412/jars/sparklyr-2.4-2.11.jar with timestamp 1615731630789
21/03/14 15:20:30 INFO Executor: Starting executor ID driver on host localhost
21/03/14 15:20:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64414.
21/03/14 15:20:31 INFO NettyBlockTransferService: Server created on localhost:64414
21/03/14 15:20:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/14 15:20:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 64414, None)
21/03/14 15:20:31 INFO BlockManagerMasterEndpoint: Registering block manager localhost:64414 with 912.3 MB RAM, BlockManagerId(driver, localhost, 64414, None)
21/03/14 15:20:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 64414, None)
21/03/14 15:20:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 64414, None)
21/03/14 15:20:31 INFO SharedState: loading hive config file: file:/Users/nathan/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
21/03/14 15:20:31 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse').
21/03/14 15:20:31 INFO SharedState: Warehouse path is 'file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse'.
21/03/14 15:20:32 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/03/14 15:20:35 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/03/14 15:20:36 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/03/14 15:20:36 INFO ObjectStore: ObjectStore, initialize called
21/03/14 15:20:36 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/03/14 15:20:36 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/03/14 15:20:38 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/03/14 15:20:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:20:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:20:40 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:20:40 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:20:40 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/03/14 15:20:40 INFO ObjectStore: Initialized ObjectStore
21/03/14 15:20:40 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/03/14 15:20:41 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/03/14 15:20:41 INFO HiveMetaStore: Added admin role in metastore
21/03/14 15:20:41 INFO HiveMetaStore: Added public role in metastore
21/03/14 15:20:41 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/03/14 15:20:41 INFO HiveMetaStore: 0: get_all_databases
21/03/14 15:20:41 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_all_databases	
21/03/14 15:20:41 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/03/14 15:20:41 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/03/14 15:20:41 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/03/14 15:20:41 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/ab98037a-e319-42b9-8a61-4b47281c717a_resources
21/03/14 15:20:41 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/ab98037a-e319-42b9-8a61-4b47281c717a
21/03/14 15:20:41 INFO SessionState: Created local directory: /var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/nathan/ab98037a-e319-42b9-8a61-4b47281c717a
21/03/14 15:20:41 INFO SessionState: Created HDFS directory: /tmp/hive/nathan/ab98037a-e319-42b9-8a61-4b47281c717a/_tmp_space.db
21/03/14 15:20:41 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/nathan/Documents/work/NE%20Data%20Ltd/projects/catalog/inst/tinytest/spark-warehouse
21/03/14 15:20:41 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:20:41 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:20:41 INFO HiveMetaStore: 0: get_database: global_temp
21/03/14 15:20:41 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/03/14 15:20:41 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/03/14 15:20:41 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:20:41 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:20:41 INFO HiveMetaStore: 0: get_database: default
21/03/14 15:20:41 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_database: default	
21/03/14 15:20:41 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/03/14 15:20:41 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/03/14 15:20:42 INFO SparkContext: Starting job: collect at utils.scala:61
21/03/14 15:20:42 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/03/14 15:20:42 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/03/14 15:20:42 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:20:42 INFO DAGScheduler: Missing parents: List()
21/03/14 15:20:42 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/03/14 15:20:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/03/14 15:20:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/03/14 15:20:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:64414 (size: 3.4 KB, free: 912.3 MB)
21/03/14 15:20:42 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/03/14 15:20:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/03/14 15:20:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/14 15:20:42 INFO Executor: Fetching spark://localhost:64412/jars/sparklyr-2.4-2.11.jar with timestamp 1615731630789
21/03/14 15:20:42 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:64412 after 24 ms (0 ms spent in bootstraps)
21/03/14 15:20:42 INFO Utils: Fetching spark://localhost:64412/jars/sparklyr-2.4-2.11.jar to /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-f0db9acd-da0b-4113-8f39-12822cdd38ab/userFiles-6c58d392-e47c-410a-968f-3a958c942b97/fetchFileTemp6011113575851461315.tmp
21/03/14 15:20:42 INFO Executor: Adding file:/private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-f0db9acd-da0b-4113-8f39-12822cdd38ab/userFiles-6c58d392-e47c-410a-968f-3a958c942b97/sparklyr-2.4-2.11.jar to class loader
21/03/14 15:20:43 INFO CodeGenerator: Code generated in 236.913297 ms
21/03/14 15:20:43 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
21/03/14 15:20:43 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 680 ms on localhost (executor driver) (1/1)
21/03/14 15:20:43 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/14 15:20:43 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 0.964 s
21/03/14 15:20:43 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 1.030957 s
21/03/14 15:20:43 INFO ContextCleaner: Cleaned accumulator 0
21/03/14 15:20:43 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:64414 in memory (size: 3.4 KB, free: 912.3 MB)
21/03/14 15:20:44 INFO CodeGenerator: Code generated in 21.669696 ms
21/03/14 15:20:44 INFO CodeGenerator: Code generated in 24.064832 ms
21/03/14 15:20:44 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:20:44 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:20:44 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/03/14 15:20:44 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:20:44 INFO DAGScheduler: Missing parents: List()
21/03/14 15:20:44 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/03/14 15:20:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 15:20:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 15:20:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:64414 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:20:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:44 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/03/14 15:20:44 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:20:44 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/03/14 15:20:44 INFO CodeGenerator: Code generated in 9.876871 ms
21/03/14 15:20:44 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/03/14 15:20:44 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 38 ms on localhost (executor driver) (1/1)
21/03/14 15:20:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/14 15:20:44 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.050 s
21/03/14 15:20:44 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.054763 s
21/03/14 15:20:44 INFO CodeGenerator: Code generated in 17.856428 ms
21/03/14 15:20:44 INFO CodeGenerator: Code generated in 14.287442 ms
21/03/14 15:20:44 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:20:44 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/03/14 15:20:44 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/03/14 15:20:44 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/03/14 15:20:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/03/14 15:20:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/03/14 15:20:44 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/03/14 15:20:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/03/14 15:20:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/03/14 15:20:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:64414 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:20:44 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:44 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/03/14 15:20:44 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:20:44 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/03/14 15:20:44 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/03/14 15:20:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 62 ms on localhost (executor driver) (1/1)
21/03/14 15:20:44 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/14 15:20:44 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.078 s
21/03/14 15:20:44 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:20:44 INFO DAGScheduler: running: Set()
21/03/14 15:20:44 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/03/14 15:20:44 INFO DAGScheduler: failed: Set()
21/03/14 15:20:44 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/03/14 15:20:44 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/03/14 15:20:44 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/03/14 15:20:44 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:64414 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:20:44 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:44 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/03/14 15:20:44 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:20:44 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/03/14 15:20:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:20:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
21/03/14 15:20:44 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/03/14 15:20:44 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 59 ms on localhost (executor driver) (1/1)
21/03/14 15:20:44 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/03/14 15:20:44 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.071 s
21/03/14 15:20:44 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.178768 s
21/03/14 15:20:45 INFO SparkContext: Starting job: collect at utils.scala:135
21/03/14 15:20:45 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/03/14 15:20:45 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/03/14 15:20:45 INFO DAGScheduler: Parents of final stage: List()
21/03/14 15:20:45 INFO DAGScheduler: Missing parents: List()
21/03/14 15:20:45 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135), which has no missing parents
21/03/14 15:20:45 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/03/14 15:20:45 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/03/14 15:20:45 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:64414 (size: 3.3 KB, free: 912.3 MB)
21/03/14 15:20:45 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:45 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/03/14 15:20:45 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/03/14 15:20:45 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/03/14 15:20:45 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/03/14 15:20:45 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
21/03/14 15:20:45 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/03/14 15:20:45 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.016 s
21/03/14 15:20:45 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.020036 s
21/03/14 15:20:45 INFO SparkContext: Starting job: count at utils.scala:135
21/03/14 15:20:45 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:135)
21/03/14 15:20:45 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/03/14 15:20:45 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/03/14 15:20:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/03/14 15:20:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/03/14 15:20:45 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/03/14 15:20:45 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/03/14 15:20:45 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/03/14 15:20:45 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:64414 (size: 4.5 KB, free: 912.3 MB)
21/03/14 15:20:45 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:45 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/03/14 15:20:45 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/03/14 15:20:45 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/03/14 15:20:45 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/03/14 15:20:45 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 10 ms on localhost (executor driver) (1/1)
21/03/14 15:20:45 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/03/14 15:20:45 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.020 s
21/03/14 15:20:45 INFO DAGScheduler: looking for newly runnable stages
21/03/14 15:20:45 INFO DAGScheduler: running: Set()
21/03/14 15:20:45 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/03/14 15:20:45 INFO DAGScheduler: failed: Set()
21/03/14 15:20:45 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/03/14 15:20:45 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/03/14 15:20:45 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/03/14 15:20:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:64414 (size: 3.8 KB, free: 912.3 MB)
21/03/14 15:20:45 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/03/14 15:20:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/03/14 15:20:45 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/03/14 15:20:45 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/03/14 15:20:45 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/03/14 15:20:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/03/14 15:20:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/14 15:20:45 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/03/14 15:20:45 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 8 ms on localhost (executor driver) (1/1)
21/03/14 15:20:45 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/03/14 15:20:45 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.017 s
21/03/14 15:20:45 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.042378 s
21/03/14 15:20:45 INFO HiveMetaStore: 0: get_table : db=default tbl=mtcars
21/03/14 15:20:45 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mtcars	
21/03/14 15:20:45 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:20:45 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:20:45 INFO HiveMetaStore: 0: get_table : db=default tbl=catalog_fake_table
21/03/14 15:20:45 INFO audit: ugi=nathan	ip=unknown-ip-addr	cmd=get_table : db=default tbl=catalog_fake_table	
21/03/14 15:20:45 INFO SparkContext: Invoking stop() from shutdown hook
21/03/14 15:20:45 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/03/14 15:20:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/14 15:20:45 INFO MemoryStore: MemoryStore cleared
21/03/14 15:20:45 INFO BlockManager: BlockManager stopped
21/03/14 15:20:45 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/14 15:20:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/14 15:20:45 INFO SparkContext: Successfully stopped SparkContext
21/03/14 15:20:45 INFO ShutdownHookManager: Shutdown hook called
21/03/14 15:20:45 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-f0db9acd-da0b-4113-8f39-12822cdd38ab
21/03/14 15:20:45 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-f074b0cd-10c2-4bf2-b0ea-fffe72870632
21/03/14 18:13:59 INFO ShutdownHookManager: Shutdown hook called
21/03/14 18:13:59 INFO ShutdownHookManager: Deleting directory /private/var/folders/x3/lznkklbd17n2ljvwmyg8g1vc0000gn/T/spark-c723dad5-9aba-4539-bed3-b67fe598f081
